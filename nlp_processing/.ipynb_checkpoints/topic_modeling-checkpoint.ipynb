{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferpodracky/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "chat_file = pd.read_csv('all-posts-public-main-chatroom/freecodecamp_casual_chatroom.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = chat_file.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_tokenized = []\n",
    "# preprocessing - WILL TAKE 30+ MINS\n",
    "\n",
    "for chat in chats:\n",
    "    tokens = prepare_text_for_lda(str(chat))\n",
    "    chats_tokenized.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-10 mins\n",
    "dictionary = corpora.Dictionary(chats_tokenized)\n",
    "corpus = [dictionary.doc2bow(text) for text in chats_tokenized]\n",
    "\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = load_from_text('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.031*\"think\" + 0.028*\"would\" + 0.022*\"thanks\" + 0.021*\"really\"')\n",
      "(1, '0.401*\"SCREEN_NAME\" + 0.023*\"function\" + 0.019*\"return\" + 0.016*\"star2\"')\n",
      "(2, '0.019*\"though\" + 0.016*\"something\" + 0.015*\"maybe\" + 0.014*\"try\"')\n",
      "(3, '0.129*\"SCREEN_NAME\" + 0.051*\"sparkle\" + 0.037*\"point\" + 0.026*\"thumbsup\"')\n",
      "(4, '0.024*\"stuff\" + 0.019*\"going\" + 0.019*\"people\" + 0.018*\"thing\"')\n"
     ]
    }
   ],
   "source": [
    "# WILL TAKE A WHILE\n",
    "# took 1-2 hours\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=5)\n",
    "ldamodel.save('model5t_5p_4w.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.144*\"really\" + 0.105*\"going\" + 0.090*\"start\" + 0.074*\"cookie\"')\n",
      "(1, '0.105*\"though\" + 0.076*\"first\" + 0.075*\"learn\" + 0.047*\"course\"')\n",
      "(2, '0.085*\"thanks\" + 0.082*\"function\" + 0.068*\"return\" + 0.056*\"never\"')\n",
      "(3, '0.058*\"image\" + 0.051*\"everyone\" + 0.051*\"enough\" + 0.038*\"style\"')\n",
      "(4, '0.172*\"sparkle\" + 0.090*\"thumbsup\" + 0.089*\"brownie\" + 0.085*\"send\"')\n",
      "(5, '0.860*\"SCREEN_NAME\" + 0.025*\"star2\" + 0.013*\"error\" + 0.011*\"thank\"')\n",
      "(6, '0.084*\"better\" + 0.074*\"look\" + 0.052*\"seem\" + 0.046*\"sorry\"')\n",
      "(7, '0.109*\"people\" + 0.067*\"project\" + 0.066*\"freecodecamp\" + 0.035*\"create\"')\n",
      "(8, '0.133*\"point\" + 0.083*\"right\" + 0.060*\"actually\" + 0.034*\"coffee\"')\n",
      "(9, '0.060*\"using\" + 0.058*\"maybe\" + 0.045*\"pretty\" + 0.043*\"problem\"')\n",
      "(10, '0.147*\"think\" + 0.137*\"would\" + 0.066*\"something\" + 0.047*\"things\"')\n",
      "(11, '0.130*\"stuff\" + 0.100*\"thing\" + 0.031*\"wanna\" + 0.031*\"company\"')\n",
      "(12, '0.056*\"check\" + 0.055*\"anything\" + 0.051*\"always\" + 0.039*\"every\"')\n",
      "(13, '0.059*\"write\" + 0.048*\"getting\" + 0.047*\"guess\" + 0.036*\"talking\"')\n",
      "(14, '0.090*\"could\" + 0.089*\"still\" + 0.087*\"try\" + 0.047*\"someone\"')\n"
     ]
    }
   ],
   "source": [
    "# WILL TAKE A WHILE\n",
    "# took ?? hours (stsarted 11:40 pm, not done by 1:30am)\n",
    "NUM_TOPICS = 15\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=5)\n",
    "ldamodel.save('model15t_5p_4w.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.542*\"SCREEN_NAME\" + 0.024*\"thanks\" + 0.009*\"great\" + 0.007*\"thank\"')\n",
      "(1, '0.069*\"sparkle\" + 0.050*\"point\" + 0.036*\"thumbsup\" + 0.035*\"brownie\"')\n",
      "(2, '0.026*\"think\" + 0.023*\"would\" + 0.022*\"people\" + 0.020*\"something\"')\n",
      "(3, '0.020*\"function\" + 0.017*\"return\" + 0.013*\"change\" + 0.012*\"question\"')\n",
      "(4, '0.023*\"really\" + 0.013*\"stuff\" + 0.012*\"things\" + 0.011*\"would\"')\n"
     ]
    }
   ],
   "source": [
    "# WILL TAKE A WHILE\n",
    "# took ~3 hours \n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=10)\n",
    "ldamodel.save('model5t_10p_4w.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
