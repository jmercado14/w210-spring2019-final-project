{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization.summarizer import summarize_corpus\n",
    "\n",
    "import re\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract word embeddings from GLOVE dataset\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B/glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"chat_summarization.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for s in df['article_text']:\n",
    "    sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['honestly, things aren’t going that great',\n",
       " 'i have no idea how i’m doing so far.',\n",
       " 'we’ve turned in four assignments so far, but i haven’t received feedback on ANY of them.',\n",
       " 'it’s super frustrating.',\n",
       " 'i might be doing great, but i might be failing.',\n",
       " 'i’d ask for more time from the TAs, or try to bring  on some additional TAs so they can turn around assignments faster',\n",
       " 'the way that they encourage lots of class discussion is really nice',\n",
       " \"i'd ask for more time from the TAs, or try to bring on some additional TAs so they can turn around assignments faster\",\n",
       " \"this week's class was really a drag\",\n",
       " 'live session was a huge waste of time',\n",
       " \"the TA didn't spend enough time on the topics we need for the problem set.\",\n",
       " \"I have NO idea what's going on.\",\n",
       " \"Daniel's live sessions are engaging.\",\n",
       " 'i liked talking to my classmates in the breakout rooms, though they can sometimes be awkward...',\n",
       " 'the TAs seem to really be overwhelmed',\n",
       " 'office hours are really helpful and the TAs really seem like they understand the material.',\n",
       " \"i just don't think they have enough resources right now to keep up with all of the assignments.\",\n",
       " 'live sessions are really long and discombobulated.',\n",
       " \"the live session was just a repeat of the async material, and didn't feel like it was worth the time.\",\n",
       " 'the feedback on the problem sets is really helpful and thorough!',\n",
       " \"I just don't like how long it takes to actually GET that feedback.\",\n",
       " 'the guest live session instructor last week a really charismatic and interesting to listen to.',\n",
       " \"i liked the way he applied last week's material to projects he had worked on in his day job.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "# make alphabets lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "    if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((100,))\n",
    "    sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TextRank Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just don't like how long it takes to actually GET that feedback.\n",
      "office hours are really helpful and the TAs really seem like they understand the material.\n",
      "the live session was just a repeat of the async material, and didn't feel like it was worth the time.\n",
      "the TA didn't spend enough time on the topics we need for the problem set.\n",
      "i liked the way he applied last week's material to projects he had worked on in his day job.\n"
     ]
    }
   ],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "# Extract top 5 sentences as the summary\n",
    "for i in range(5):\n",
    "    print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Gensim Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"honestly, things aren’t going that great. i have no idea how i’m doing so far.. we’ve turned in four assignments so far, but i haven’t received feedback on ANY of them.. it’s super frustrating.. i might be doing great, but i might be failing.. i’d ask for more time from the TAs, or try to bring  on some additional TAs so they can turn around assignments faster. the way that they encourage lots of class discussion is really nice. i'd ask for more time from the TAs, or try to bring on some additional TAs so they can turn around assignments faster. this week's class was really a drag. live session was a huge waste of time. the TA didn't spend enough time on the topics we need for the problem set.. I have NO idea what's going on.. Daniel's live sessions are engaging.. i liked talking to my classmates in the breakout rooms, though they can sometimes be awkward.... the TAs seem to really be overwhelmed. office hours are really helpful and the TAs really seem like they understand the material.. i just don't think they have enough resources right now to keep up with all of the assignments.. live sessions are really long and discombobulated.. the live session was just a repeat of the async material, and didn't feel like it was worth the time.. the feedback on the problem sets is really helpful and thorough!. I just don't like how long it takes to actually GET that feedback.. the guest live session instructor last week a really charismatic and interesting to listen to.. i liked the way he applied last week's material to projects he had worked on in his day job.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \". \"\n",
    "text = s.join(sentences)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i’d ask for more time from the TAs, or try to bring  on some additional TAs so they can turn around assignments faster.\n",
      "i'd ask for more time from the TAs, or try to bring on some additional TAs so they can turn around assignments faster.\n",
      "live session was a huge waste of time.\n",
      "the live session was just a repeat of the async material, and didn't feel like it was worth the time..\n"
     ]
    }
   ],
   "source": [
    "print(summarize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['s'], [' '], ['i'], ['s'], [' '], [' '], ['i'], [' '], [' '], [' '], ['i'], [' '], [' '], [' '], ['i'], [' '], [' '], ['i'], [' '], ['i'], [' '], ['s'], [' '], [' '], [' '], [' '], ['i'], [' '], [' '], ['s'], ['s'], ['i'], ['s'], [' '], ['s'], [' '], [' '], [' '], ['i'], [' '], [' '], ['i'], [' '], [' '], [' '], [' '], [' '], [' '], ['i'], ['s'], [' '], ['s'], [' '], ['s'], ['i'], [' '], ['i'], [' '], ['i'], [' '], [' '], ['i'], [' '], [' '], [' '], ['i'], [' '], ['i'], [' '], [' '], ['i'], ['i'], [' '], ['i'], [' '], ['s'], [' '], [' '], [' '], ['i'], [' '], [' '], [' '], ['s'], [' '], [' '], [' '], [' '], ['i'], [' '], [' '], [' '], ['s'], [' '], ['i'], ['i'], [' '], ['s'], [' '], ['s'], [' '], [' '], [' '], [' '], [' '], ['s'], ['s'], ['i'], ['s'], [' '], ['s'], [' '], [' '], [' '], [' '], [' '], [' '], ['s'], [' '], [' '], ['s'], ['s'], [' '], ['i'], ['s'], ['s'], ['s'], ['i'], [' '], ['i'], ['s'], [' '], [' '], ['i'], [' '], ['i'], [' '], ['s'], [' '], [' '], [' '], ['i'], [' '], [' '], [' '], ['s'], [' '], [' '], [' '], [' '], ['i'], [' '], [' '], ['s'], [' '], ['i'], ['i'], [' '], ['s'], [' '], ['s'], [' '], [' '], [' '], [' '], [' '], ['s'], ['s'], ['i'], ['s'], [' '], ['s'], [' '], ['i'], ['s'], [' '], ['s'], [' '], ['s'], ['s'], [' '], ['s'], [' '], [' '], [' '], [' '], ['i'], [' '], ['s'], ['s'], ['s'], ['i'], [' '], ['s'], [' '], [' '], [' '], ['s'], [' '], [' '], ['i'], [' '], [' '], [' '], ['i'], [' '], ['s'], [' '], [' '], ['i'], [' '], [' '], [' '], ['i'], ['s'], [' '], [' '], [' '], [' '], [' '], [' '], ['s'], [' '], [' '], [' '], [' '], ['i'], [' '], ['s'], [' '], ['i'], [' '], [' '], ['i'], ['s'], [' '], ['i'], [' '], ['s'], ['s'], ['s'], ['i'], ['s'], [' '], [' '], ['i'], [' '], ['i'], [' '], ['i'], [' '], ['i'], [' '], [' '], [' '], ['s'], ['s'], ['s'], [' '], ['i'], [' '], [' '], [' '], ['s'], [' '], [' '], [' '], [' '], ['s'], ['i'], ['s'], [' '], [' '], [' '], [' '], ['s'], [' '], ['s'], [' '], [' '], [' '], [' '], [' '], ['i'], [' '], ['s'], [' '], [' '], [' '], [' '], [' '], [' '], ['s'], [' '], [' '], ['s'], [' '], ['i'], [' '], [' '], ['s'], [' '], [' '], ['i'], [' '], ['i'], [' '], ['s'], [' '], [' '], ['i'], [' '], [' '], [' '], [' ']]\n"
     ]
    }
   ],
   "source": [
    "print(summarize_corpus(text, .2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
