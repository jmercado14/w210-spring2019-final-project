{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "import re\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(sent):\n",
    "    sent_new = \" \".join([i for i in sent if i not in stop_words])\n",
    "    return sent_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process sentence\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract word embeddings from GLOVE dataset\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B/glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"241_summarization.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for s in df['article_text']:\n",
    "    sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I've got a question on the sample code for calculating robust and clustered SEs.\",\n",
       " \"When we're taking clustering into account (starting line ~100 of the example file), do we also need to fit a new model with the cluster as a covariate, or is alright to stick with the initial model defined on line ~81\",\n",
       " 'If we include an indicator for the clusters -- what are we going to estimate on that feature?',\n",
       " \"Basically, like every other dummy variable that we use, we'll estimate the difference in outcomes between cluster -- which might be useful for reducing the variance.\",\n",
       " \"What would happen if we don't include it though?\",\n",
       " \"Good question -- if we don't include it, we won't estimate or account for any cluster level effects\",\n",
       " 'Yep yep; we won’t estimate any cluster level, mean differences.',\n",
       " 'But, the estimate of the standard error isn’t predicated on having a measure of those cluster level differences.',\n",
       " 'Would it be wrong to include cluster as a covariate?',\n",
       " \"I was a little surprised it wasn't included in the example set\",\n",
       " 'Our concern with clustering, or using a clustered estimator, is typically on the inference.',\n",
       " 'If we don’t use a clustered estimator, then our standard errors are going to presume that all the treatment and control units were independently assigned.',\n",
       " 'Nope!',\n",
       " 'Not wrong to include it, just not strictly necessary.',\n",
       " 'Typically, (and that’s a watch word for Alex being lazy...) a cluster estimator _will_ explain variance in the outcome, and so might be useful.',\n",
       " 'You’ve got to measure the cluster either way, so you can estimate a model that does vs doesn’t include, and then use an F-test to evaluate whether it reduced regression errors.',\n",
       " 'When we have a model that does not interact treatment with the intercept — ie a standard model — then the intercept estimates the mean in the baseline group, and the regression coefficient the marginal change between treatment and baseline.',\n",
       " 'If we interact treatment with a group indicator, interpretation requires a bit more careful thought.',\n",
       " 'Consider that you’ve got the estrogen, soybeans, and sex data.',\n",
       " 'A model that estimates `y ~ beta_0 + beta_1_woman + beta_2_soybeans + beta_3_woman_*_soybeans` will estimate the treatment effect for men on `beta_2` and the treatment effect for women on the sum of `beta_2 + beta_3`.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've got a question on the sample code for calculating robust and clustered SEs. When we're taking clustering into account (starting line ~100 of the example file), do we also need to fit a new model with the cluster as a covariate, or is alright to stick with the initial model defined on line ~81 If we include an indicator for the clusters -- what are we going to estimate on that feature? Basically, like every other dummy variable that we use, we'll estimate the difference in outcomes between cluster -- which might be useful for reducing the variance. What would happen if we don't include it though? Good question -- if we don't include it, we won't estimate or account for any cluster level effects Yep yep; we won’t estimate any cluster level, mean differences. But, the estimate of the standard error isn’t predicated on having a measure of those cluster level differences. Would it be wrong to include cluster as a covariate? I was a little surprised it wasn't included in the example set Our concern with clustering, or using a clustered estimator, is typically on the inference. If we don’t use a clustered estimator, then our standard errors are going to presume that all the treatment and control units were independently assigned. Nope! Not wrong to include it, just not strictly necessary. Typically, (and that’s a watch word for Alex being lazy...) a cluster estimator _will_ explain variance in the outcome, and so might be useful. You’ve got to measure the cluster either way, so you can estimate a model that does vs doesn’t include, and then use an F-test to evaluate whether it reduced regression errors. When we have a model that does not interact treatment with the intercept — ie a standard model — then the intercept estimates the mean in the baseline group, and the regression coefficient the marginal change between treatment and baseline. If we interact treatment with a group indicator, interpretation requires a bit more careful thought. Consider that you’ve got the estrogen, soybeans, and sex data. A model that estimates `y ~ beta_0 + beta_1_woman + beta_2_soybeans + beta_3_woman_*_soybeans` will estimate the treatment effect for men on `beta_2` and the treatment effect for women on the sum of `beta_2 + beta_3`.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \" \"\n",
    "clean_text = s.join(sentences)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beta_2', 2),\n",
       " ('Alex', 1),\n",
       " ('F', 1),\n",
       " ('`y ~ beta_0 + beta_1_woman +', 1),\n",
       " ('beta_3', 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nlp(clean_text)\n",
    "items = [x.text for x in text.ents]\n",
    "Counter(items).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Alex, F, `y ~ beta_0 + beta_1_woman +, beta_2, beta_2, beta_3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.ents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just don't like how long it takes to actually GET that feedback.\n",
      "office hours are really helpful and the TAs really seem like they understand the material.\n",
      "the live session was just a repeat of the async material, and didn't feel like it was worth the time.\n",
      "the TA didn't spend enough time on the topics we need for the problem set.\n",
      "i liked the way he applied last week's material to projects he had worked on in his day job.\n"
     ]
    }
   ],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "# Extract top 5 sentences as the summary\n",
    "for i in range(5):\n",
    "    print(ranked_sentences[i][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
