{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(\"training_data/RMP_data/full_RMP_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid</th>\n",
       "      <th>dept</th>\n",
       "      <th>date</th>\n",
       "      <th>forcredit</th>\n",
       "      <th>attendance</th>\n",
       "      <th>textbookuse</th>\n",
       "      <th>interest</th>\n",
       "      <th>grade</th>\n",
       "      <th>tags</th>\n",
       "      <th>comments</th>\n",
       "      <th>helpcount</th>\n",
       "      <th>nothelpcount</th>\n",
       "      <th>online</th>\n",
       "      <th>profgender</th>\n",
       "      <th>profhotness</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>clarity</th>\n",
       "      <th>easiness</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24228248</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>1/5/15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It's a must have</td>\n",
       "      <td>Really into it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Would take again\", \"Hilarious\", \"Tests are t...</td>\n",
       "      <td>Great Professor My wife took this class twice ...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24218909</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>1/2/15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mandatory</td>\n",
       "      <td>It's a must have</td>\n",
       "      <td>Sorta interested</td>\n",
       "      <td>A</td>\n",
       "      <td>[\"Skip class? You won't pass.\", \"Tests are tou...</td>\n",
       "      <td>Great Professor Study the notes from class and...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24215795</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>1/2/15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Essential to passing</td>\n",
       "      <td>Really into it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Hilarious\", \"Would take again\", \"Skip class?...</td>\n",
       "      <td>Brother Brau is a great guy He gives great spi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24204179</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>12/30/14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not Mandatory</td>\n",
       "      <td>Essential to passing</td>\n",
       "      <td>Sorta interested</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Tests are tough\", \"Get ready to read\"]</td>\n",
       "      <td>People rave about Brau but I personally dont g...</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24198463</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>12/28/14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not Mandatory</td>\n",
       "      <td>You need it sometimes</td>\n",
       "      <td>Sorta interested</td>\n",
       "      <td>A</td>\n",
       "      <td>[\"Inspirational\", \"Hilarious\", \"Skip class? Yo...</td>\n",
       "      <td>This class doesnt have much homework which was...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     tid      dept      date forcredit     attendance  \\\n",
       "0  24228248  916674  Business    1/5/15       Yes            NaN   \n",
       "1  24218909  916674  Business    1/2/15       Yes      Mandatory   \n",
       "2  24215795  916674  Business    1/2/15       Yes            NaN   \n",
       "3  24204179  916674  Business  12/30/14       Yes  Not Mandatory   \n",
       "4  24198463  916674  Business  12/28/14       Yes  Not Mandatory   \n",
       "\n",
       "             textbookuse          interest grade  \\\n",
       "0       It's a must have    Really into it   NaN   \n",
       "1       It's a must have  Sorta interested     A   \n",
       "2   Essential to passing    Really into it   NaN   \n",
       "3   Essential to passing  Sorta interested   NaN   \n",
       "4  You need it sometimes  Sorta interested     A   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [\"Would take again\", \"Hilarious\", \"Tests are t...   \n",
       "1  [\"Skip class? You won't pass.\", \"Tests are tou...   \n",
       "2  [\"Hilarious\", \"Would take again\", \"Skip class?...   \n",
       "3           [\"Tests are tough\", \"Get ready to read\"]   \n",
       "4  [\"Inspirational\", \"Hilarious\", \"Skip class? Yo...   \n",
       "\n",
       "                                            comments  helpcount  nothelpcount  \\\n",
       "0  Great Professor My wife took this class twice ...          0            10   \n",
       "1  Great Professor Study the notes from class and...          0             1   \n",
       "2  Brother Brau is a great guy He gives great spi...          1             2   \n",
       "3  People rave about Brau but I personally dont g...         18             6   \n",
       "4  This class doesnt have much homework which was...          1             0   \n",
       "\n",
       "  online  profgender  profhotness  helpfulness  clarity  easiness  quality  \n",
       "0    NaN           0            0          4.0      5.0       3.0      9.0  \n",
       "1    NaN           0            0          4.0      4.0       2.0      8.0  \n",
       "2    NaN           0            0          4.0      4.0       3.0      8.0  \n",
       "3    NaN           0            0          3.0      1.0       2.0      4.0  \n",
       "4    NaN           0            0          4.0      4.0       4.0      8.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187167 entries, 0 to 187166\n",
      "Data columns (total 20 columns):\n",
      "id              187167 non-null int64\n",
      "tid             187167 non-null int64\n",
      "dept            187167 non-null object\n",
      "date            187167 non-null object\n",
      "forcredit       11000 non-null object\n",
      "attendance      14788 non-null object\n",
      "textbookuse     141373 non-null object\n",
      "interest        175112 non-null object\n",
      "grade           9835 non-null object\n",
      "tags            187167 non-null object\n",
      "comments        186776 non-null object\n",
      "helpcount       187167 non-null int64\n",
      "nothelpcount    187167 non-null int64\n",
      "online          991 non-null object\n",
      "profgender      187167 non-null int64\n",
      "profhotness     187167 non-null int64\n",
      "helpfulness     117811 non-null float64\n",
      "clarity         117811 non-null float64\n",
      "easiness        117811 non-null float64\n",
      "quality         117811 non-null float64\n",
      "dtypes: float64(4), int64(6), object(10)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()\n",
    "# 187167 rows, 20 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    187167.000000\n",
       "mean          0.055699\n",
       "std           0.372341\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max          29.000000\n",
       "Name: helpcount, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['helpcount'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        991\n",
       "unique         1\n",
       "top       online\n",
       "freq         991\n",
       "Name: online, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['online'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          187167\n",
       "unique            334\n",
       "top       Mathematics\n",
       "freq            14298\n",
       "Name: dept, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['dept'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dept\n",
       "Marketing                   596\n",
       "Law                         625\n",
       "Mechanical Engineering      625\n",
       "Art History                 686\n",
       "Social Work                 718\n",
       "Women's Studies             724\n",
       "Dance                       741\n",
       "Finance                     887\n",
       "Agriculture                 943\n",
       "Classics                    945\n",
       "Art                         994\n",
       "Social Science             1060\n",
       "Literature                 1163\n",
       "Statistics                 1197\n",
       "Theater                    1244\n",
       "Health Science             1384\n",
       "Fine Arts                  1409\n",
       "Spanish                    1437\n",
       "Journalism                 1537\n",
       "Education                  1581\n",
       "Geology                    1694\n",
       "Geography                  2205\n",
       "Humanities                 2397\n",
       "Philosophy                 2514\n",
       "Accounting                 2570\n",
       "Anthropology               2649\n",
       "Music                      2759\n",
       "Computer Science           3181\n",
       "Science                    3953\n",
       "Communication              4126\n",
       "Physics                    4317\n",
       "Engineering                4528\n",
       "Sociology                  4989\n",
       "Business                   5855\n",
       "Languages                  6433\n",
       "Political Science          6503\n",
       "Economics                  6672\n",
       "Psychology                 7682\n",
       "History                    7844\n",
       "Biology                   10272\n",
       "Religion                  11218\n",
       "Chemistry                 11300\n",
       "English                   11798\n",
       "Mathematics               14298\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.groupby(['dept']).size().sort_values()[290:334]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade\n",
       "A                 3980\n",
       "A+                 837\n",
       "A-                1490\n",
       "Audit/No Grade      11\n",
       "B                  939\n",
       "B+                 901\n",
       "B-                 296\n",
       "C                  231\n",
       "C+                 149\n",
       "C-                  75\n",
       "D                   37\n",
       "D+                  19\n",
       "D-                  11\n",
       "F                   36\n",
       "INC                 49\n",
       "Not sure yet       625\n",
       "P                   47\n",
       "Rather not say      34\n",
       "WD                  68\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.groupby(['grade']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.871670e+05\n",
       "mean     7.005554e+05\n",
       "std      5.123135e+05\n",
       "min      1.740000e+02\n",
       "25%      2.735930e+05\n",
       "50%      5.923380e+05\n",
       "75%      1.016084e+06\n",
       "max      1.984570e+06\n",
       "Name: tid, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['tid'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tid\n",
       "174        261\n",
       "176        309\n",
       "178        227\n",
       "186        151\n",
       "188        254\n",
       "829         39\n",
       "1245       219\n",
       "3069       108\n",
       "4310       258\n",
       "4735       232\n",
       "4949        32\n",
       "7659        40\n",
       "7694        14\n",
       "8359         4\n",
       "8656        44\n",
       "8906         6\n",
       "8956        17\n",
       "9479        38\n",
       "9583         9\n",
       "9588        40\n",
       "9589        85\n",
       "9806         7\n",
       "10221       16\n",
       "10222      187\n",
       "11058      404\n",
       "12776       76\n",
       "12777       56\n",
       "12779        4\n",
       "12780       14\n",
       "12933        8\n",
       "          ... \n",
       "1977044      1\n",
       "1977591      1\n",
       "1978133      1\n",
       "1978136      1\n",
       "1978139      1\n",
       "1978737      1\n",
       "1978957      1\n",
       "1979618      1\n",
       "1979662      1\n",
       "1980239      1\n",
       "1980434      1\n",
       "1980546      2\n",
       "1981108      1\n",
       "1981430      1\n",
       "1981438      1\n",
       "1981510      1\n",
       "1981565      1\n",
       "1981610      1\n",
       "1981613      1\n",
       "1981620      1\n",
       "1981788      1\n",
       "1982007      2\n",
       "1982497      1\n",
       "1982714      1\n",
       "1982934      1\n",
       "1983153      2\n",
       "1983179      1\n",
       "1983648      1\n",
       "1984218      1\n",
       "1984570      1\n",
       "Length: 15583, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.groupby(['tid']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          186776\n",
       "unique         179670\n",
       "top       No Comments\n",
       "freq             5159\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['comments'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df[training_df['comments'] != 'No Comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid</th>\n",
       "      <th>helpcount</th>\n",
       "      <th>nothelpcount</th>\n",
       "      <th>profgender</th>\n",
       "      <th>profhotness</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>clarity</th>\n",
       "      <th>easiness</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.820080e+05</td>\n",
       "      <td>1.820080e+05</td>\n",
       "      <td>182008.000000</td>\n",
       "      <td>182008.000000</td>\n",
       "      <td>182008.000000</td>\n",
       "      <td>182008.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.538445e+07</td>\n",
       "      <td>7.070923e+05</td>\n",
       "      <td>0.057184</td>\n",
       "      <td>0.033229</td>\n",
       "      <td>0.303465</td>\n",
       "      <td>0.232913</td>\n",
       "      <td>3.739448</td>\n",
       "      <td>3.700046</td>\n",
       "      <td>3.041557</td>\n",
       "      <td>7.439494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.230749e+06</td>\n",
       "      <td>5.145705e+05</td>\n",
       "      <td>0.377323</td>\n",
       "      <td>0.283856</td>\n",
       "      <td>0.459755</td>\n",
       "      <td>0.422688</td>\n",
       "      <td>1.422131</td>\n",
       "      <td>1.368991</td>\n",
       "      <td>1.256229</td>\n",
       "      <td>2.657747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.230000e+02</td>\n",
       "      <td>1.740000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.247934e+07</td>\n",
       "      <td>2.795800e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.605265e+07</td>\n",
       "      <td>5.961480e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.013159e+07</td>\n",
       "      <td>1.029664e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.438667e+07</td>\n",
       "      <td>1.984570e+06</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           tid      helpcount   nothelpcount  \\\n",
       "count  1.820080e+05  1.820080e+05  182008.000000  182008.000000   \n",
       "mean   1.538445e+07  7.070923e+05       0.057184       0.033229   \n",
       "std    6.230749e+06  5.145705e+05       0.377323       0.283856   \n",
       "min    2.230000e+02  1.740000e+02       0.000000       0.000000   \n",
       "25%    1.247934e+07  2.795800e+05       0.000000       0.000000   \n",
       "50%    1.605265e+07  5.961480e+05       0.000000       0.000000   \n",
       "75%    2.013159e+07  1.029664e+06       0.000000       0.000000   \n",
       "max    2.438667e+07  1.984570e+06      29.000000      25.000000   \n",
       "\n",
       "          profgender    profhotness    helpfulness        clarity  \\\n",
       "count  182008.000000  182008.000000  115071.000000  115071.000000   \n",
       "mean        0.303465       0.232913       3.739448       3.700046   \n",
       "std         0.459755       0.422688       1.422131       1.368991   \n",
       "min         0.000000       0.000000       1.000000       1.000000   \n",
       "25%         0.000000       0.000000       3.000000       3.000000   \n",
       "50%         0.000000       0.000000       4.000000       4.000000   \n",
       "75%         1.000000       0.000000       5.000000       5.000000   \n",
       "max         1.000000       1.000000       5.000000       5.000000   \n",
       "\n",
       "            easiness        quality  \n",
       "count  115071.000000  115071.000000  \n",
       "mean        3.041557       7.439494  \n",
       "std         1.256229       2.657747  \n",
       "min         1.000000       2.000000  \n",
       "25%         2.000000       6.000000  \n",
       "50%         3.000000       8.000000  \n",
       "75%         4.000000      10.000000  \n",
       "max         5.000000      10.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count            181617\n",
       "unique           179669\n",
       "top       Great teacher\n",
       "freq                 72\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['comments'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_sciences = [\n",
    "'Computer Science',\n",
    "'Economics',\n",
    "'Engineering',\n",
    "'Engineering Technology',\n",
    "'Mathematics',\n",
    "'Mechanical Engineering',\n",
    "'Physics',\n",
    "'Science',\n",
    "'Statistics']\n",
    "# related sciences with >1000 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid</th>\n",
       "      <th>helpcount</th>\n",
       "      <th>nothelpcount</th>\n",
       "      <th>profgender</th>\n",
       "      <th>profhotness</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>clarity</th>\n",
       "      <th>easiness</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.761000e+04</td>\n",
       "      <td>3.761000e+04</td>\n",
       "      <td>37610.000000</td>\n",
       "      <td>37610.000000</td>\n",
       "      <td>37610.000000</td>\n",
       "      <td>37610.000000</td>\n",
       "      <td>24882.000000</td>\n",
       "      <td>24882.000000</td>\n",
       "      <td>24882.000000</td>\n",
       "      <td>24882.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.493916e+07</td>\n",
       "      <td>6.601918e+05</td>\n",
       "      <td>0.072108</td>\n",
       "      <td>0.039218</td>\n",
       "      <td>0.222388</td>\n",
       "      <td>0.136932</td>\n",
       "      <td>3.442770</td>\n",
       "      <td>3.380838</td>\n",
       "      <td>2.889719</td>\n",
       "      <td>6.823607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.605385e+06</td>\n",
       "      <td>5.286968e+05</td>\n",
       "      <td>0.470017</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.415856</td>\n",
       "      <td>0.343780</td>\n",
       "      <td>1.520924</td>\n",
       "      <td>1.469615</td>\n",
       "      <td>1.270867</td>\n",
       "      <td>2.860156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.593000e+03</td>\n",
       "      <td>1.860000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.198317e+07</td>\n",
       "      <td>2.380820e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.569156e+07</td>\n",
       "      <td>5.234150e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.002543e+07</td>\n",
       "      <td>9.704920e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.438667e+07</td>\n",
       "      <td>1.982934e+06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           tid     helpcount  nothelpcount    profgender  \\\n",
       "count  3.761000e+04  3.761000e+04  37610.000000  37610.000000  37610.000000   \n",
       "mean   1.493916e+07  6.601918e+05      0.072108      0.039218      0.222388   \n",
       "std    6.605385e+06  5.286968e+05      0.470017      0.315228      0.415856   \n",
       "min    1.593000e+03  1.860000e+02      0.000000      0.000000      0.000000   \n",
       "25%    1.198317e+07  2.380820e+05      0.000000      0.000000      0.000000   \n",
       "50%    1.569156e+07  5.234150e+05      0.000000      0.000000      0.000000   \n",
       "75%    2.002543e+07  9.704920e+05      0.000000      0.000000      0.000000   \n",
       "max    2.438667e+07  1.982934e+06     20.000000     19.000000      1.000000   \n",
       "\n",
       "        profhotness   helpfulness       clarity      easiness       quality  \n",
       "count  37610.000000  24882.000000  24882.000000  24882.000000  24882.000000  \n",
       "mean       0.136932      3.442770      3.380838      2.889719      6.823607  \n",
       "std        0.343780      1.520924      1.469615      1.270867      2.860156  \n",
       "min        0.000000      1.000000      1.000000      1.000000      2.000000  \n",
       "25%        0.000000      2.000000      2.000000      2.000000      4.000000  \n",
       "50%        0.000000      4.000000      4.000000      3.000000      8.000000  \n",
       "75%        0.000000      5.000000      5.000000      4.000000      9.000000  \n",
       "max        1.000000      5.000000      5.000000      5.000000     10.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sciences_df = training_df[training_df['dept'].isin(related_sciences)]\n",
    "sciences_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37610 entries, 1408 to 187165\n",
      "Data columns (total 20 columns):\n",
      "id              37610 non-null int64\n",
      "tid             37610 non-null int64\n",
      "dept            37610 non-null object\n",
      "date            37610 non-null object\n",
      "forcredit       2241 non-null object\n",
      "attendance      3155 non-null object\n",
      "textbookuse     27893 non-null object\n",
      "interest        34694 non-null object\n",
      "grade           1974 non-null object\n",
      "tags            37610 non-null object\n",
      "comments        37514 non-null object\n",
      "helpcount       37610 non-null int64\n",
      "nothelpcount    37610 non-null int64\n",
      "online          127 non-null object\n",
      "profgender      37610 non-null int64\n",
      "profhotness     37610 non-null int64\n",
      "helpfulness     24882 non-null float64\n",
      "clarity         24882 non-null float64\n",
      "easiness        24882 non-null float64\n",
      "quality         24882 non-null float64\n",
      "dtypes: float64(4), int64(6), object(10)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "sciences_df.info()\n",
    "#35k rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_documents(document_array):\n",
    "    \n",
    "    tokenized = []\n",
    "    \n",
    "    for doc in document_array:\n",
    "        tokens = prepare_text_for_lda(str(doc))\n",
    "        tokenized.append(tokens)\n",
    "        \n",
    "    return tokenized\n",
    "\n",
    "def generate_dictionary_corpus(data_id, tokenized_text):\n",
    "    # going to take 5-10 minutes\n",
    "    \n",
    "    dictionary = corpora.Dictionary(tokenized_text)\n",
    "    \n",
    "    dictionary_filename = \"topic_dictionaries/%s_dictionary_feedback.gensim\" % (data_id)\n",
    "    corpus = [dictionary.doc2bow(text) for text in tokenized_text]\n",
    "    corpus_filename = \"topic_corpi/%s_corpus_feedback.pkl\" % (data_id)\n",
    "    \n",
    "    pickle.dump(corpus, open(corpus_filename, 'wb'))\n",
    "    dictionary.save(dictionary_filename)\n",
    "    return dictionary, corpus\n",
    "\n",
    "def load_dictionary_corpus(data_id):\n",
    "    dictionary_filename = \"topic_dictionaries/%s_dictionary_feedback.gensim\" % (data_id)\n",
    "    dictionary = corpora.Dictionary.load(dictionary_filename)\n",
    "    corpus_filename = \"topic_corpi/%s_corpus_feedback.pkl\" % (data_id)\n",
    "    with open(corpus_filename, 'rb') as f:\n",
    "        corpus = pickle.load(f)\n",
    "    if (len(dictionary) == 0):\n",
    "        return\n",
    "    return dictionary, corpus\n",
    "\n",
    "\n",
    "def generate_lda(data_id, corpus, dictionary, num_topics, num_passes, num_words):\n",
    "    # runtime will depend on number of passes\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, \n",
    "                                                alpha='auto', eta='auto', eval_every=0, passes=num_passes)\n",
    "    ldamodel_filename = 'topic_models/%s_model%st_%sp.gensim' % (data_id, str(num_topics), str(num_passes))\n",
    "    ldamodel.save(ldamodel_filename)\n",
    "    \n",
    "    sub_topics = ldamodel.print_topics(num_words=num_words)\n",
    "    for sub_topic in sub_topics:\n",
    "        print(sub_topic)\n",
    "        \n",
    "    return ldamodel\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Great Professor Study the notes from class and...\n",
       "2    Brother Brau is a great guy He gives great spi...\n",
       "3    People rave about Brau but I personally dont g...\n",
       "4    This class doesnt have much homework which was...\n",
       "5    Bro Brau definitely knows what he is doing  I ...\n",
       "6    Lectures are long but he does a good job of br...\n",
       "7    Can be a good buddy but not a good professor T...\n",
       "8    I love Brother Brau for his spiritual thoughts...\n",
       "9    Professor Brau really cares  If he talks about...\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.comments[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feedback_tokenized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-758c9e2d1878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeedback_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dictionary_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-3862d6af30f8>\u001b[0m in \u001b[0;36mgenerate_dictionary_corpus\u001b[0;34m(data_id, tokenized_text)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdictionary_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"topic_dictionaries/%s_dictionary_feedback.gensim\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeedback_tokenized\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mcorpus_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"topic_corpi/%s_corpus_feedback.pkl\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feedback_tokenized' is not defined"
     ]
    }
   ],
   "source": [
    "feedback_text = prepare_documents(training_df.comments)\n",
    "\n",
    "dictionary, corpus = generate_dictionary_corpus(\"RMP\", feedback_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.175*\"extremely\" + 0.103*\"however\" + 0.085*\"review\" + 0.064*\"thing\" + 0.037*\"although\"')\n",
      "(1, '0.139*\"teach\" + 0.130*\"teaching\" + 0.107*\"boring\" + 0.067*\"could\" + 0.042*\"worst\"')\n",
      "(2, '0.162*\"point\" + 0.131*\"enjoy\" + 0.111*\"attendance\" + 0.079*\"like\" + 0.060*\"mandatory\"')\n",
      "(3, '0.392*\"student\" + 0.110*\"want\" + 0.080*\"office\" + 0.064*\"care\" + 0.045*\"need\"')\n",
      "(4, '0.267*\"recommend\" + 0.108*\"grading\" + 0.104*\"highly\" + 0.099*\"grader\" + 0.095*\"discussion\"')\n",
      "(5, '0.072*\"lecture\" + 0.060*\"helpful\" + 0.055*\"grade\" + 0.050*\"material\" + 0.042*\"exam\"')\n",
      "(6, '0.126*\"hours\" + 0.120*\"subject\" + 0.109*\"project\" + 0.108*\"seem\" + 0.056*\"fairly\"')\n",
      "(7, '0.250*\"class\" + 0.065*\"really\" + 0.059*\"teacher\" + 0.056*\"professor\" + 0.054*\"great\"')\n",
      "(8, '0.153*\"final\" + 0.145*\"midterm\" + 0.140*\"homework\" + 0.106*\"papers\" + 0.088*\"write\"')\n",
      "(9, '0.153*\"topic\" + 0.050*\"unclear\" + 0.049*\"world\" + 0.043*\"leave\" + 0.041*\"either\"')\n",
      "(10, '0.112*\"problem\" + 0.061*\"email\" + 0.038*\"incredibly\" + 0.036*\"choice\" + 0.033*\"practice\"')\n",
      "(11, '0.210*\"know\" + 0.124*\"stuff\" + 0.090*\"essay\" + 0.062*\"knowledge\" + 0.054*\"short\"')\n",
      "(12, '0.099*\"better\" + 0.068*\"extra\" + 0.063*\"credit\" + 0.053*\"speak\" + 0.038*\"assign\"')\n",
      "(13, '0.124*\"understand\" + 0.104*\"always\" + 0.085*\"clear\" + 0.077*\"willing\" + 0.070*\"explain\"')\n",
      "(14, '0.125*\"overall\" + 0.114*\"instructor\" + 0.058*\"knowledgeable\" + 0.054*\"experience\" + 0.047*\"learning\"')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feedback_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b2f9b7c154f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dictionary_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_TOPICS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_PASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_ITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcoherence_model_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeedback_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcoherence_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoherence_model_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nCoherence Score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_lda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feedback_text' is not defined"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 15\n",
    "NUM_ITERATIONS = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS, NUM_ITERATIONS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.31847731469200774\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.146*\"professor\" + 0.078*\"exam\" + 0.060*\"teaching\" + 0.052*\"course\" + 0.051*\"difficult\"')\n",
      "(1, '0.179*\"make\" + 0.100*\"know\" + 0.093*\"instructor\" + 0.083*\"grading\" + 0.059*\"stuff\"')\n",
      "(2, '0.191*\"student\" + 0.085*\"always\" + 0.054*\"want\" + 0.050*\"think\" + 0.047*\"love\"')\n",
      "(3, '0.116*\"learn\" + 0.081*\"pretty\" + 0.067*\"final\" + 0.064*\"midterm\" + 0.052*\"though\"')\n",
      "(4, '0.110*\"first\" + 0.105*\"seem\" + 0.082*\"worst\" + 0.080*\"extra\" + 0.075*\"credit\"')\n",
      "(5, '0.366*\"class\" + 0.095*\"really\" + 0.087*\"teacher\" + 0.079*\"great\" + 0.063*\"helpful\"')\n",
      "(6, '0.165*\"explain\" + 0.094*\"anything\" + 0.072*\"thing\" + 0.059*\"concept\" + 0.057*\"clearly\"')\n",
      "(7, '0.200*\"would\" + 0.168*\"recommend\" + 0.087*\"definitely\" + 0.081*\"taking\" + 0.039*\"avoid\"')\n",
      "(8, '0.182*\"highly\" + 0.110*\"favorite\" + 0.087*\"history\" + 0.049*\"leave\" + 0.040*\"simple\"')\n",
      "(9, '0.267*\"assignment\" + 0.133*\"listen\" + 0.087*\"lecturer\" + 0.071*\"hard\" + 0.070*\"different\"')\n",
      "(10, '0.125*\"things\" + 0.093*\"grader\" + 0.090*\"discussion\" + 0.053*\"email\" + 0.047*\"challenge\"')\n",
      "(11, '0.258*\"boring\" + 0.131*\"topic\" + 0.096*\"help\" + 0.082*\"excellent\" + 0.062*\"outside\"')\n",
      "(12, '0.165*\"willing\" + 0.064*\"talking\" + 0.062*\"speak\" + 0.058*\"need\" + 0.048*\"nothing\"')\n",
      "(13, '0.108*\"lecture\" + 0.083*\"grade\" + 0.058*\"reading\" + 0.056*\"question\" + 0.051*\"test\"')\n",
      "(14, '0.232*\"interest\" + 0.166*\"material\" + 0.077*\"extremely\" + 0.056*\"could\" + 0.049*\"subject\"')\n",
      "\n",
      "Coherence Score:  0.3177322860969289\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 15\n",
    "NUM_ITERATIONS = 50\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS, NUM_ITERATIONS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusion -  number of iterations doesn't significantly affect Cv score. Going to remove ongoing, default to 50\n",
    "# also removed eval_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.096*\"slide\" + 0.084*\"mistake\" + 0.063*\"example\" + 0.048*\"history\" + 0.044*\"nothing\"')\n",
      "(1, '0.331*\"student\" + 0.105*\"want\" + 0.086*\"grading\" + 0.061*\"care\" + 0.036*\"sister\"')\n",
      "(2, '0.367*\"interest\" + 0.081*\"topic\" + 0.077*\"subject\" + 0.039*\"involve\" + 0.036*\"passionate\"')\n",
      "(3, '0.154*\"writing\" + 0.132*\"discussion\" + 0.063*\"order\" + 0.055*\"assign\" + 0.053*\"meaning\"')\n",
      "(4, '0.203*\"know\" + 0.123*\"stuff\" + 0.092*\"participation\" + 0.089*\"talking\" + 0.028*\"complete\"')\n",
      "(5, '0.076*\"worst\" + 0.044*\"leave\" + 0.041*\"academic\" + 0.038*\"combine\" + 0.037*\"without\"')\n",
      "(6, '0.099*\"experience\" + 0.068*\"refuse\" + 0.068*\"story\" + 0.066*\"prove\" + 0.063*\"knowledge\"')\n",
      "(7, '0.152*\"instructor\" + 0.034*\"state\" + 0.033*\"excite\" + 0.027*\"become\" + 0.025*\"agree\"')\n",
      "(8, '0.196*\"understand\" + 0.107*\"explain\" + 0.101*\"things\" + 0.078*\"problem\" + 0.065*\"sometimes\"')\n",
      "(9, '0.371*\"teaching\" + 0.057*\"style\" + 0.034*\"improve\" + 0.033*\"skill\" + 0.030*\"idea\"')\n",
      "(10, '0.077*\"lecture\" + 0.054*\"grade\" + 0.046*\"material\" + 0.042*\"reading\" + 0.039*\"exam\"')\n",
      "(11, '0.122*\"hours\" + 0.104*\"office\" + 0.067*\"avoid\" + 0.043*\"anymore\" + 0.041*\"comment\"')\n",
      "(12, '0.238*\"answer\" + 0.139*\"sense\" + 0.064*\"humor\" + 0.050*\"choice\" + 0.043*\"multiple\"')\n",
      "(13, '0.064*\"boring\" + 0.052*\"assignment\" + 0.044*\"project\" + 0.043*\"write\" + 0.042*\"papers\"')\n",
      "(14, '0.182*\"class\" + 0.052*\"really\" + 0.045*\"teacher\" + 0.044*\"professor\" + 0.041*\"great\"')\n",
      "\n",
      "Coherence Score:  0.3387806250925685\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 25\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.089*\"credit\" + 0.087*\"extra\" + 0.067*\"history\"')\n",
      "(1, '0.173*\"know\" + 0.144*\"papers\" + 0.106*\"stuff\"')\n",
      "(2, '0.119*\"project\" + 0.076*\"mistake\" + 0.048*\"outside\"')\n",
      "(3, '0.223*\"understand\" + 0.097*\"hours\" + 0.083*\"office\"')\n",
      "(4, '0.046*\"grade\" + 0.041*\"material\" + 0.037*\"would\"')\n",
      "(5, '0.329*\"student\" + 0.098*\"want\" + 0.063*\"care\"')\n",
      "(6, '0.191*\"explain\" + 0.082*\"talking\" + 0.080*\"excellent\"')\n",
      "(7, '0.065*\"email\" + 0.045*\"friendly\" + 0.034*\"encourage\"')\n",
      "(8, '0.084*\"writing\" + 0.061*\"paper\" + 0.054*\"attendance\"')\n",
      "(9, '0.062*\"knowledge\" + 0.049*\"combine\" + 0.043*\"sweet\"')\n",
      "(10, '0.223*\"class\" + 0.062*\"really\" + 0.055*\"teacher\"')\n",
      "(11, '0.142*\"lecture\" + 0.073*\"test\" + 0.070*\"exam\"')\n",
      "(12, '0.098*\"amaze\" + 0.080*\"favorite\" + 0.073*\"speak\"')\n",
      "(13, '0.265*\"recommend\" + 0.132*\"taking\" + 0.098*\"highly\"')\n",
      "(14, '0.183*\"answer\" + 0.134*\"instructor\" + 0.077*\"avoid\"')\n",
      "\n",
      "Coherence Score:  0.3228353796505149\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 100\n",
    "NUM_WORDS = 3\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.198*\"would\" + 0.164*\"recommend\" + 0.085*\"awesome\" + 0.083*\"taking\" + 0.060*\"highly\"')\n",
      "(1, '0.071*\"speak\" + 0.054*\"powerpoint\" + 0.046*\"level\" + 0.039*\"school\" + 0.036*\"right\"')\n",
      "(2, '0.093*\"understanding\" + 0.086*\"post\" + 0.073*\"email\" + 0.050*\"friendly\" + 0.042*\"helping\"')\n",
      "(3, '0.092*\"learn\" + 0.069*\"teach\" + 0.051*\"course\" + 0.034*\"never\" + 0.031*\"think\"')\n",
      "(4, '0.364*\"student\" + 0.113*\"want\" + 0.088*\"instructor\" + 0.068*\"care\" + 0.030*\"style\"')\n",
      "(5, '0.138*\"subject\" + 0.055*\"matter\" + 0.055*\"major\" + 0.047*\"knowledge\" + 0.046*\"refuse\"')\n",
      "(6, '0.113*\"papers\" + 0.101*\"writing\" + 0.097*\"listen\" + 0.090*\"discussion\" + 0.064*\"attendance\"')\n",
      "(7, '0.179*\"question\" + 0.112*\"midterm\" + 0.111*\"final\" + 0.092*\"answer\" + 0.068*\"hours\"')\n",
      "(8, '0.101*\"sense\" + 0.095*\"mistake\" + 0.071*\"avoid\" + 0.057*\"frustrate\" + 0.051*\"constantly\"')\n",
      "(9, '0.137*\"grader\" + 0.104*\"credit\" + 0.103*\"extra\" + 0.045*\"feedback\" + 0.039*\"offer\"')\n",
      "(10, '0.190*\"class\" + 0.054*\"really\" + 0.047*\"teacher\" + 0.046*\"professor\" + 0.042*\"great\"')\n",
      "(11, '0.093*\"lecture\" + 0.064*\"grade\" + 0.049*\"reading\" + 0.047*\"exam\" + 0.046*\"test\"')\n",
      "(12, '0.144*\"love\" + 0.041*\"approachable\" + 0.034*\"brother\" + 0.034*\"looking\" + 0.033*\"forward\"')\n",
      "(13, '0.161*\"project\" + 0.080*\"excellent\" + 0.062*\"group\" + 0.054*\"leave\" + 0.048*\"prove\"')\n",
      "(14, '0.079*\"knowledgeable\" + 0.058*\"story\" + 0.049*\"combine\" + 0.043*\"bring\" + 0.036*\"state\"')\n",
      "\n",
      "Coherence Score:  0.3339541476482888\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 50\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.165*\"writing\" + 0.108*\"speak\" + 0.069*\"often\" + 0.056*\"meaning\" + 0.053*\"found\"')\n",
      "(1, '0.071*\"like\" + 0.056*\"smart\" + 0.056*\"another\" + 0.052*\"constantly\" + 0.052*\"level\"')\n",
      "(2, '0.193*\"recommend\" + 0.098*\"taking\" + 0.086*\"project\" + 0.076*\"hours\" + 0.070*\"highly\"')\n",
      "(3, '0.169*\"awesome\" + 0.105*\"grader\" + 0.081*\"favorite\" + 0.063*\"english\" + 0.058*\"spanish\"')\n",
      "(4, '0.196*\"know\" + 0.119*\"stuff\" + 0.086*\"talking\" + 0.070*\"email\" + 0.053*\"prove\"')\n",
      "(5, '0.136*\"instructor\" + 0.130*\"subject\" + 0.064*\"essay\" + 0.052*\"matter\" + 0.050*\"leave\"')\n",
      "(6, '0.167*\"answer\" + 0.039*\"right\" + 0.038*\"biweekly\" + 0.036*\"choice\" + 0.032*\"short\"')\n",
      "(7, '0.174*\"class\" + 0.043*\"lecture\" + 0.042*\"professor\" + 0.030*\"grade\" + 0.028*\"helpful\"')\n",
      "(8, '0.091*\"credit\" + 0.091*\"extra\" + 0.050*\"anymore\" + 0.036*\"sweet\" + 0.032*\"allow\"')\n",
      "(9, '0.271*\"student\" + 0.118*\"always\" + 0.087*\"willing\" + 0.085*\"want\" + 0.051*\"sense\"')\n",
      "(10, '0.180*\"teacher\" + 0.162*\"great\" + 0.104*\"learn\" + 0.035*\"love\" + 0.035*\"better\"')\n",
      "(11, '0.127*\"topic\" + 0.055*\"history\" + 0.052*\"means\" + 0.046*\"quite\" + 0.044*\"assign\"')\n",
      "(12, '0.195*\"understand\" + 0.107*\"explain\" + 0.101*\"things\" + 0.050*\"example\" + 0.043*\"concept\"')\n",
      "(13, '0.283*\"really\" + 0.200*\"interest\" + 0.095*\"make\" + 0.091*\"teaching\" + 0.053*\"funny\"')\n",
      "(14, '0.075*\"would\" + 0.062*\"teach\" + 0.046*\"course\" + 0.031*\"never\" + 0.028*\"think\"')\n",
      "\n",
      "Coherence Score:  0.33549398582257933\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 35\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.183*\"writing\" + 0.085*\"sister\" + 0.065*\"assign\" + 0.061*\"style\" + 0.042*\"relate\"')\n",
      "(1, '0.283*\"question\" + 0.147*\"answer\" + 0.046*\"constantly\" + 0.039*\"prove\" + 0.034*\"right\"')\n",
      "(2, '0.222*\"study\" + 0.158*\"grading\" + 0.095*\"speak\" + 0.051*\"guide\" + 0.034*\"present\"')\n",
      "(3, '0.328*\"teacher\" + 0.296*\"great\" + 0.073*\"awesome\" + 0.043*\"super\" + 0.025*\"spanish\"')\n",
      "(4, '0.075*\"english\" + 0.060*\"absolutely\" + 0.050*\"biweekly\" + 0.046*\"college\" + 0.040*\"forward\"')\n",
      "(5, '0.150*\"know\" + 0.091*\"stuff\" + 0.066*\"talking\" + 0.054*\"history\" + 0.046*\"refuse\"')\n",
      "(6, '0.217*\"would\" + 0.182*\"recommend\" + 0.093*\"taking\" + 0.065*\"highly\" + 0.058*\"grader\"')\n",
      "(7, '0.135*\"instructor\" + 0.086*\"worst\" + 0.076*\"extra\" + 0.075*\"credit\" + 0.071*\"post\"')\n",
      "(8, '0.119*\"really\" + 0.100*\"professor\" + 0.074*\"student\" + 0.059*\"learn\" + 0.044*\"teach\"')\n",
      "(9, '0.114*\"helpful\" + 0.071*\"understand\" + 0.056*\"always\" + 0.052*\"clear\" + 0.044*\"extremely\"')\n",
      "(10, '0.099*\"problem\" + 0.086*\"sense\" + 0.085*\"mistake\" + 0.058*\"avoid\" + 0.048*\"email\"')\n",
      "(11, '0.127*\"quiz\" + 0.105*\"midterm\" + 0.101*\"final\" + 0.068*\"write\" + 0.065*\"papers\"')\n",
      "(12, '0.185*\"assignment\" + 0.068*\"essay\" + 0.056*\"leave\" + 0.038*\"least\" + 0.030*\"allow\"')\n",
      "(13, '0.067*\"anything\" + 0.038*\"nothing\" + 0.027*\"completely\" + 0.025*\"useless\" + 0.022*\"entire\"')\n",
      "(14, '0.194*\"class\" + 0.048*\"lecture\" + 0.040*\"interest\" + 0.034*\"grade\" + 0.029*\"material\"')\n",
      "\n",
      "Coherence Score:  0.3430358996734756\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 20\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic number of passes seems to be between 15 and 25 (20 best so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i don't know about how helpful these subtopics are. what if i try... using a specific subset of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Business', 'Economics', 'Religion', 'Church History',\n",
       "       'Social Science', 'Anthropology', 'Accounting', 'Music',\n",
       "       'Psychology', 'Chemistry', 'Theater', 'Biology', 'Fine Arts',\n",
       "       'History', 'Political Science', 'Science', 'Interior Design',\n",
       "       'Humanities', 'Mathematics', 'Statistics', 'Art', 'Physiology',\n",
       "       'Agriculture', 'Geography', 'Spanish', 'Physics', 'Sociology',\n",
       "       'Family & Consumer Science', 'Writing', 'Film', 'Philosophy',\n",
       "       'Communication', 'Computer Science', 'Nutrition & Food Science',\n",
       "       'English', 'Finance', 'Japanese', 'Geology', 'Engineering',\n",
       "       'Marriage Family & Human Dev', 'Languages', 'Physical Sciences',\n",
       "       'Dance', 'Student Services', 'French', 'Health Science',\n",
       "       'Classical Studies', 'Literature', 'English Language & Literature',\n",
       "       'Information Systems', 'Mathematics Education', 'Classics',\n",
       "       'Exercise & Sport Science', 'Microbiology',\n",
       "       'Communication Disorders', 'Physical Education',\n",
       "       'Health & Physical Education', 'Russian', 'Art History',\n",
       "       'Foreign Languages', 'School of Family Life', 'German',\n",
       "       'Visual Arts', 'Linguistics', 'Family Studies', 'Social Work',\n",
       "       'Asian & Near Eastern Languages', 'Chemical Engineering',\n",
       "       'Business Administration', 'Human Development', 'Exercise Science',\n",
       "       'Chinese', 'Honors', 'Mechanical Engineering',\n",
       "       'Molecular Biosciences', 'Early Childhood Education',\n",
       "       'International Studies', 'Italian', 'Theatre & Media Arts',\n",
       "       'Civil Engineering', 'Electrical Engineering', 'Medicine', 'Law',\n",
       "       'Secondary Education', 'Recreation', 'Management', 'Physical Ed',\n",
       "       'Hebrew', 'Korean', 'Information Technology', 'Ancient Scripture',\n",
       "       'Scandinavian', 'Industrial Design', 'Elementary Education',\n",
       "       'Educational Leadership', 'French & Italian', 'Technology',\n",
       "       'Education', 'Arabic', 'Portuguese', 'Nursing',\n",
       "       'Organizational Ldrshp  Strat', 'Not Specified', 'Life Science',\n",
       "       'Criminal Justice', 'Nutrition  Food Science',\n",
       "       'University Studies', 'Latin American Studies',\n",
       "       'Aerospace Studies', 'Marketing', \"Women's Studies\", 'Journalism',\n",
       "       'Ethnic Studies', 'Art & Art History', 'East Asian Studies',\n",
       "       'Theology', 'Genetics', 'Zoology', 'Spanish & Portuguese',\n",
       "       'Asian Studies', 'Environmental Studies', 'Pharmacy',\n",
       "       'Agricultural Economics', 'Design', 'Consumer Science',\n",
       "       'Nutrition', 'Kinesiology', 'East Asian Lang. & Literature',\n",
       "       'Rehabilitation Psychology', 'African Studies', 'Astronomy',\n",
       "       'Military Science', 'Oncology', 'Biomedical Engineering',\n",
       "       'Horticulture', 'Mathematical and Computer Sci.',\n",
       "       'Religious Studies', 'Foreign Languages & Literature',\n",
       "       'Computer Information Technology', 'Child & Family Studies',\n",
       "       'Business Management', 'Animal Science', 'Home & Family Studies',\n",
       "       'Academic Services', 'Architecture', 'Automotive Technology',\n",
       "       'Career & College Prep', 'Online Learning', 'Career Development',\n",
       "       'Latin', 'Health & Human Performance', 'General Studies',\n",
       "       'Library Science', 'Cultural Studies', 'Physics & Astronomy',\n",
       "       'Family Social Science', 'Materials Science',\n",
       "       'Genetics / Cell Biology & Dev.', 'Biological Sciences',\n",
       "       'Sign Language', 'Organizational Leadership', 'Human Resources',\n",
       "       'Graphic Arts', 'Speech/Language/Hearing Sci.',\n",
       "       'Communication Studies', 'Gender, Women, and Sex Studies',\n",
       "       'Educational Psychology', 'Information Decision Sciences',\n",
       "       'Chicano Studies', 'African-American Studies', 'Writing Studies',\n",
       "       'Curriculum & Instruction', 'Child Development',\n",
       "       'Asian Languages & Literatures', 'Food Science & Nutrition',\n",
       "       'Sports Management', 'Electrical & Comp. Engineering',\n",
       "       'Aerospace Eng. & Mechanics', 'Natural History',\n",
       "       'German & Scandinavian', 'Rhetoric', 'Center for Spiritual Health',\n",
       "       'Administration', 'Theatre Arts & Dance', 'Anatomy',\n",
       "       'Art Education', 'Textiles & Clothing', 'Food Science',\n",
       "       'Comparative Studies', 'Biochemistry',\n",
       "       'Engineering Graphics Tech.', 'Hospitality Management',\n",
       "       'Environ. & Natural Resources', 'Industrial Engineering',\n",
       "       'Allied Health', 'Hospitality', 'Natural Resources',\n",
       "       'Aerospace Engineering', 'Speech & Hearing Sciences',\n",
       "       'Human Resource Management', 'Human Ecology', 'Persian',\n",
       "       'Near Eastern Studies', 'Public Policy',\n",
       "       'Agricultural Engineering', 'Slavic Languages',\n",
       "       'Public Administration', 'Neuroscience', 'Sports', 'Greek',\n",
       "       'Aviation', 'Public Health', 'Transportation & Logistics',\n",
       "       'Education & Human Ecology', 'Life Sciences',\n",
       "       'Information Science', 'Manufacturing & Construction',\n",
       "       'Construction', 'Behavioral Sciences', 'Engineering Technology',\n",
       "       'Management Communications', 'American Studies',\n",
       "       'Counseling Psychology', 'Facilities Management',\n",
       "       'Comparative Literature', 'Organization Management',\n",
       "       'Student Life', 'Organizational Ldrshp & Strat',\n",
       "       'Manufacturing Engineering Tech', 'Construction Management',\n",
       "       'Cantonese', 'Teaching & Learning', 'Swedish',\n",
       "       'Instructional Technology', 'Psychological Science', 'Hungarian',\n",
       "       'English As A Second Language', 'Graduate Studies',\n",
       "       'Continuing Education', 'Classical & Medieval Studies',\n",
       "       'English Language  Literature', 'Health  Physical Education',\n",
       "       'French  Italian', 'Physics  Astronomy',\n",
       "       'History & Asian American Studies', 'Atmospheric Sciences',\n",
       "       'Entomology', 'Veterinary Sciences', 'Dietetics', 'TA',\n",
       "       'Cell & Regenerative Biology', 'Hydrogeology',\n",
       "       'Spanish  Portuguese', 'Culinary Arts', 'Women',\n",
       "       'Art  Art History', 'Ag Bus, Plant & Animal Sci', 'Counseling',\n",
       "       'Agribusiness', 'Agronomy', 'College Success',\n",
       "       'Computer Science & Engineering', 'Foundations', 'EMT & Paramedic',\n",
       "       'Home  Family Studies', 'Health  Human Performance',\n",
       "       'Recreation & Leisure Studies', 'Child  Family Studies',\n",
       "       'Foreign Languages  Literature', 'Wildlife',\n",
       "       'Postsecondary Teaching', 'American Sign Language',\n",
       "       'Career & Community Lrng Center', 'Supply Chain Management',\n",
       "       'Urban Studies', 'Forest Resources', 'Strategic Management',\n",
       "       'Ecology & Evolutionary Biology', 'Plant Biology',\n",
       "       'Applied Economics', 'Public Affairs', 'Archaeology',\n",
       "       'Sports Science', 'Bioproducts/Biosystems',\n",
       "       'Fisheries Wildlife  Biology', 'Educational Development', 'Dental',\n",
       "       'Fisheries, Wildlife & Biology', 'Surgery', 'Naval Science',\n",
       "       'Earth Science', 'Landscape Architecture & Regional Planning',\n",
       "       'Food Science  Nutrition', 'German  Scandinavian',\n",
       "       'Electrical  Comp. Engineering', 'BioproductsBiosystems',\n",
       "       'Bioethics', 'SpeechLanguageHearing Sci.',\n",
       "       'Gender Women and Sex Studies', 'Global Studies',\n",
       "       'Curriculum  Instruction', 'Food, Agriculture & Bio Eng',\n",
       "       'Swahili', 'Athletic Training', 'Environmental Science',\n",
       "       'Managerial Science', 'Environment', 'Materials Science & Eng.',\n",
       "       'World Languages & Cultures', 'Nuclear Engineering',\n",
       "       'Arts & Sciences', 'Respiratory Therapy', 'Medical Technology',\n",
       "       'Soviet & East European Studi', 'Yiddish', 'Physical Therapy',\n",
       "       'Turkish', 'Welding', 'Systems Engineering',\n",
       "       'Visual Communication Design', 'Psychiatry',\n",
       "       'Environ.  Natural Resources', 'Textiles  Clothing',\n",
       "       'Science Education', 'Art & Design', 'Biostatistics',\n",
       "       'Health Services Management', 'Polish', 'Medieval Studies',\n",
       "       'Biotechnology', 'Health Information Science',\n",
       "       'Womens & Gender Studies', 'Womens  Gender Studies'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['dept'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Again, but now just related sciences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, with 35k rows - just related sciences with >1000 rows\n",
    "feedback_text = prepare_documents(sciences_df.comments)\n",
    "\n",
    "dictionary, corpus = generate_dictionary_corpus(\"sciences\", feedback_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.120*\"class\" + 0.060*\"professor\" + 0.041*\"teach\" + 0.030*\"learn\" + 0.029*\"would\"')\n",
      "(1, '0.320*\"question\" + 0.142*\"answer\" + 0.036*\"email\" + 0.036*\"unclear\" + 0.035*\"mistake\"')\n",
      "(2, '0.142*\"subject\" + 0.055*\"matter\" + 0.032*\"behind\" + 0.029*\"intelligent\" + 0.027*\"understandable\"')\n",
      "(3, '0.205*\"hours\" + 0.200*\"office\" + 0.032*\"available\" + 0.023*\"powerpoint\" + 0.019*\"otherwise\"')\n",
      "(4, '0.055*\"joke\" + 0.052*\"science\" + 0.044*\"awful\" + 0.042*\"tell\" + 0.039*\"stats\"')\n",
      "(5, '0.118*\"lecture\" + 0.077*\"test\" + 0.073*\"homework\" + 0.065*\"exam\" + 0.050*\"problem\"')\n",
      "(6, '0.119*\"terrible\" + 0.060*\"getting\" + 0.036*\"chance\" + 0.033*\"method\" + 0.029*\"research\"')\n",
      "(7, '0.197*\"grade\" + 0.135*\"midterm\" + 0.130*\"final\" + 0.088*\"curve\" + 0.052*\"average\"')\n",
      "(8, '0.114*\"class\" + 0.067*\"teacher\" + 0.063*\"really\" + 0.052*\"great\" + 0.049*\"student\"')\n",
      "(9, '0.066*\"credit\" + 0.060*\"extra\" + 0.053*\"project\" + 0.031*\"choice\" + 0.030*\"suck\"')\n",
      "(10, '0.113*\"grading\" + 0.051*\"writing\" + 0.031*\"guide\" + 0.028*\"tutor\" + 0.024*\"papers\"')\n",
      "(11, '0.091*\"recommend\" + 0.069*\"extremely\" + 0.058*\"professor\" + 0.045*\"definitely\" + 0.041*\"taking\"')\n",
      "(12, '0.272*\"explain\" + 0.160*\"things\" + 0.115*\"concept\" + 0.077*\"accent\" + 0.071*\"clearly\"')\n",
      "(13, '0.099*\"note\" + 0.087*\"boring\" + 0.060*\"point\" + 0.052*\"textbook\" + 0.046*\"online\"')\n",
      "(14, '0.057*\"relate\" + 0.047*\"works\" + 0.045*\"work\" + 0.040*\"consider\" + 0.039*\"generally\"')\n",
      "\n",
      "Coherence Score:  0.35700482816599427\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 15\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.250*\"would\" + 0.173*\"recommend\" + 0.081*\"taking\" + 0.066*\"highly\" + 0.042*\"another\"')\n",
      "(1, '0.149*\"know\" + 0.110*\"stuff\" + 0.066*\"talking\" + 0.049*\"grader\" + 0.033*\"friendly\"')\n",
      "(2, '0.288*\"professor\" + 0.087*\"clear\" + 0.067*\"extremely\" + 0.043*\"subject\" + 0.034*\"physics\"')\n",
      "(3, '0.080*\"follow\" + 0.060*\"often\" + 0.045*\"discussion\" + 0.042*\"mistake\" + 0.042*\"section\"')\n",
      "(4, '0.078*\"anything\" + 0.068*\"avoid\" + 0.061*\"terrible\" + 0.048*\"nothing\" + 0.044*\"something\"')\n",
      "(5, '0.208*\"class\" + 0.061*\"teacher\" + 0.057*\"really\" + 0.047*\"great\" + 0.038*\"helpful\"')\n",
      "(6, '0.232*\"hours\" + 0.225*\"office\" + 0.054*\"english\" + 0.038*\"choice\" + 0.037*\"suck\"')\n",
      "(7, '0.219*\"student\" + 0.126*\"teaching\" + 0.048*\"seem\" + 0.043*\"want\" + 0.041*\"care\"')\n",
      "(8, '0.085*\"worst\" + 0.053*\"horrible\" + 0.034*\"experience\" + 0.033*\"level\" + 0.032*\"school\"')\n",
      "(9, '0.121*\"understand\" + 0.102*\"question\" + 0.088*\"explain\" + 0.052*\"things\" + 0.045*\"answer\"')\n",
      "(10, '0.158*\"boring\" + 0.088*\"grading\" + 0.059*\"project\" + 0.056*\"straight\" + 0.034*\"group\"')\n",
      "(11, '0.093*\"instructor\" + 0.090*\"slide\" + 0.083*\"sense\" + 0.056*\"humor\" + 0.033*\"comment\"')\n",
      "(12, '0.061*\"speak\" + 0.052*\"start\" + 0.042*\"tell\" + 0.040*\"engineering\" + 0.040*\"theory\"')\n",
      "(13, '0.098*\"lecture\" + 0.059*\"test\" + 0.057*\"material\" + 0.056*\"homework\" + 0.049*\"exam\"')\n",
      "(14, '0.124*\"grade\" + 0.084*\"midterm\" + 0.082*\"final\" + 0.056*\"curve\" + 0.049*\"point\"')\n",
      "\n",
      "Coherence Score:  0.3481691776896026\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 20\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.034*\"fail\" + 0.033*\"end\" + 0.024*\"algebra\" + 0.023*\"suppose\" + 0.021*\"involve\"')\n",
      "(1, '0.062*\"grade\" + 0.031*\"every\" + 0.029*\"better\" + 0.024*\"point\" + 0.024*\"assignment\"')\n",
      "(2, '0.080*\"lecture\" + 0.048*\"test\" + 0.045*\"homework\" + 0.040*\"exam\" + 0.037*\"question\"')\n",
      "(3, '0.142*\"know\" + 0.105*\"stuff\" + 0.069*\"smart\" + 0.031*\"knowledge\" + 0.025*\"struggle\"')\n",
      "(4, '0.124*\"worst\" + 0.108*\"anything\" + 0.094*\"avoid\" + 0.084*\"terrible\" + 0.076*\"horrible\"')\n",
      "(5, '0.153*\"class\" + 0.050*\"professor\" + 0.045*\"teacher\" + 0.042*\"really\" + 0.035*\"great\"')\n",
      "(6, '0.071*\"board\" + 0.069*\"straight\" + 0.054*\"mistake\" + 0.033*\"forward\" + 0.029*\"method\"')\n",
      "(7, '0.311*\"explain\" + 0.185*\"things\" + 0.133*\"concept\" + 0.081*\"clearly\" + 0.037*\"simple\"')\n",
      "(8, '0.198*\"funny\" + 0.052*\"joke\" + 0.050*\"science\" + 0.048*\"entertain\" + 0.039*\"tell\"')\n",
      "(9, '0.073*\"english\" + 0.051*\"suck\" + 0.047*\"passionate\" + 0.037*\"sheet\" + 0.031*\"kinda\"')\n",
      "(10, '0.195*\"first\" + 0.063*\"style\" + 0.036*\"years\" + 0.034*\"week\" + 0.033*\"powerpoint\"')\n",
      "(11, '0.137*\"accent\" + 0.107*\"instructor\" + 0.097*\"sense\" + 0.066*\"humor\" + 0.065*\"recitation\"')\n",
      "(12, '0.151*\"midterm\" + 0.147*\"final\" + 0.101*\"curve\" + 0.060*\"credit\" + 0.059*\"average\"')\n",
      "(13, '0.089*\"experience\" + 0.069*\"writing\" + 0.057*\"friendly\" + 0.054*\"knowledgeable\" + 0.053*\"engineering\"')\n",
      "(14, '0.185*\"boring\" + 0.074*\"talking\" + 0.051*\"email\" + 0.050*\"unclear\" + 0.039*\"awful\"')\n",
      "\n",
      "Coherence Score:  0.3570832778793947\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 25\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.089*\"teach\" + 0.063*\"teaching\" + 0.051*\"course\" + 0.038*\"never\" + 0.032*\"could\"')\n",
      "(1, '0.066*\"english\" + 0.063*\"speak\" + 0.062*\"style\" + 0.041*\"engineering\" + 0.033*\"others\"')\n",
      "(2, '0.116*\"professor\" + 0.106*\"teacher\" + 0.081*\"great\" + 0.068*\"helpful\" + 0.046*\"interest\"')\n",
      "(3, '0.200*\"explain\" + 0.124*\"hours\" + 0.121*\"office\" + 0.120*\"things\" + 0.086*\"concept\"')\n",
      "(4, '0.180*\"would\" + 0.124*\"recommend\" + 0.078*\"know\" + 0.062*\"actually\" + 0.059*\"taking\"')\n",
      "(5, '0.163*\"boring\" + 0.069*\"reading\" + 0.048*\"discussion\" + 0.030*\"somewhat\" + 0.028*\"story\"')\n",
      "(6, '0.074*\"credit\" + 0.069*\"slide\" + 0.068*\"extra\" + 0.056*\"board\" + 0.043*\"mistake\"')\n",
      "(7, '0.101*\"smart\" + 0.054*\"writing\" + 0.053*\"assign\" + 0.038*\"comment\" + 0.036*\"chance\"')\n",
      "(8, '0.045*\"waste\" + 0.030*\"look\" + 0.025*\"night\" + 0.024*\"ramble\" + 0.022*\"voice\"')\n",
      "(9, '0.143*\"terrible\" + 0.113*\"nothing\" + 0.098*\"useless\" + 0.090*\"absolutely\" + 0.080*\"grader\"')\n",
      "(10, '0.144*\"class\" + 0.051*\"lecture\" + 0.039*\"really\" + 0.031*\"test\" + 0.030*\"material\"')\n",
      "(11, '0.315*\"student\" + 0.063*\"want\" + 0.060*\"care\" + 0.059*\"accent\" + 0.056*\"love\"')\n",
      "(12, '0.294*\"question\" + 0.130*\"answer\" + 0.033*\"email\" + 0.029*\"ask\" + 0.027*\"wrong\"')\n",
      "(13, '0.198*\"funny\" + 0.052*\"joke\" + 0.039*\"tell\" + 0.037*\"hilarious\" + 0.037*\"stats\"')\n",
      "(14, '0.073*\"topic\" + 0.041*\"unclear\" + 0.040*\"found\" + 0.038*\"information\" + 0.034*\"useful\"')\n",
      "\n",
      "Coherence Score:  0.33642741391571623\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 30\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.088*\"lecture\" + 0.066*\"test\" + 0.064*\"homework\" + 0.056*\"exam\" + 0.043*\"problem\"')\n",
      "(1, '0.132*\"know\" + 0.097*\"stuff\" + 0.071*\"instructor\" + 0.058*\"talking\" + 0.028*\"knowledge\"')\n",
      "(2, '0.163*\"point\" + 0.075*\"english\" + 0.056*\"assign\" + 0.029*\"front\" + 0.025*\"patient\"')\n",
      "(3, '0.086*\"professor\" + 0.081*\"teacher\" + 0.065*\"great\" + 0.063*\"student\" + 0.059*\"understand\"')\n",
      "(4, '0.119*\"physics\" + 0.057*\"exactly\" + 0.047*\"suck\" + 0.037*\"straightforward\" + 0.036*\"costs\"')\n",
      "(5, '0.264*\"question\" + 0.117*\"answer\" + 0.074*\"seem\" + 0.065*\"accent\" + 0.030*\"email\"')\n",
      "(6, '0.096*\"effort\" + 0.057*\"attendance\" + 0.042*\"previous\" + 0.034*\"sister\" + 0.034*\"mandatory\"')\n",
      "(7, '0.252*\"class\" + 0.034*\"really\" + 0.034*\"interest\" + 0.027*\"teaching\" + 0.027*\"learn\"')\n",
      "(8, '0.113*\"give\" + 0.081*\"review\" + 0.067*\"online\" + 0.060*\"credit\" + 0.058*\"slide\"')\n",
      "(9, '0.230*\"hours\" + 0.225*\"office\" + 0.035*\"available\" + 0.035*\"friendly\" + 0.024*\"tutor\"')\n",
      "(10, '0.071*\"mistake\" + 0.058*\"choice\" + 0.049*\"multiple\" + 0.040*\"tricky\" + 0.032*\"random\"')\n",
      "(11, '0.063*\"teach\" + 0.050*\"would\" + 0.028*\"never\" + 0.024*\"could\" + 0.023*\"first\"')\n",
      "(12, '0.138*\"note\" + 0.059*\"attend\" + 0.044*\"discussion\" + 0.040*\"writing\" + 0.030*\"important\"')\n",
      "(13, '0.252*\"recommend\" + 0.096*\"highly\" + 0.071*\"sense\" + 0.060*\"anyone\" + 0.048*\"organize\"')\n",
      "(14, '0.064*\"grader\" + 0.038*\"stats\" + 0.029*\"prof\" + 0.027*\"kinda\" + 0.025*\"miss\"')\n",
      "\n",
      "Coherence Score:  0.36847426725147\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 10\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.434*\"student\" + 0.083*\"care\" + 0.038*\"matter\" + 0.030*\"present\" + 0.030*\"approachable\"')\n",
      "(1, '0.122*\"grading\" + 0.032*\"method\" + 0.031*\"prof\" + 0.027*\"research\" + 0.027*\"paper\"')\n",
      "(2, '0.148*\"know\" + 0.110*\"stuff\" + 0.065*\"talking\" + 0.047*\"calculus\" + 0.027*\"forward\"')\n",
      "(3, '0.094*\"slide\" + 0.089*\"sense\" + 0.061*\"humor\" + 0.036*\"straightforward\" + 0.031*\"powerpoint\"')\n",
      "(4, '0.274*\"explain\" + 0.164*\"things\" + 0.119*\"concept\" + 0.071*\"clearly\" + 0.047*\"board\"')\n",
      "(5, '0.207*\"boring\" + 0.119*\"accent\" + 0.061*\"discussion\" + 0.038*\"somewhat\" + 0.027*\"understandable\"')\n",
      "(6, '0.230*\"would\" + 0.159*\"recommend\" + 0.078*\"definitely\" + 0.075*\"taking\" + 0.061*\"highly\"')\n",
      "(7, '0.056*\"course\" + 0.042*\"never\" + 0.030*\"worst\" + 0.026*\"confuse\" + 0.026*\"seem\"')\n",
      "(8, '0.138*\"class\" + 0.044*\"professor\" + 0.040*\"teacher\" + 0.037*\"really\" + 0.031*\"great\"')\n",
      "(9, '0.110*\"lecture\" + 0.067*\"test\" + 0.062*\"homework\" + 0.055*\"exam\" + 0.042*\"problem\"')\n",
      "(10, '0.237*\"hours\" + 0.229*\"office\" + 0.038*\"available\" + 0.029*\"trouble\" + 0.020*\"algebra\"')\n",
      "(11, '0.185*\"note\" + 0.104*\"review\" + 0.091*\"online\" + 0.044*\"organize\" + 0.038*\"provide\"')\n",
      "(12, '0.122*\"avoid\" + 0.096*\"average\" + 0.056*\"unclear\" + 0.036*\"second\" + 0.035*\"costs\"')\n",
      "(13, '0.353*\"question\" + 0.156*\"answer\" + 0.065*\"instructor\" + 0.063*\"excellent\" + 0.040*\"email\"')\n",
      "(14, '0.093*\"smart\" + 0.064*\"level\" + 0.060*\"style\" + 0.044*\"college\" + 0.043*\"show\"')\n",
      "\n",
      "Coherence Score:  0.34651813935312165\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 35\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.061*\"never\" + 0.044*\"worst\" + 0.039*\"confuse\" + 0.038*\"anything\" + 0.033*\"avoid\"')\n",
      "(1, '0.166*\"point\" + 0.068*\"speak\" + 0.068*\"mistake\" + 0.067*\"since\" + 0.051*\"awful\"')\n",
      "(2, '0.080*\"credit\" + 0.073*\"extra\" + 0.062*\"project\" + 0.058*\"straight\" + 0.039*\"writing\"')\n",
      "(3, '0.162*\"boring\" + 0.043*\"unclear\" + 0.042*\"found\" + 0.039*\"listen\" + 0.021*\"become\"')\n",
      "(4, '0.118*\"lecture\" + 0.072*\"test\" + 0.066*\"homework\" + 0.059*\"exam\" + 0.045*\"problem\"')\n",
      "(5, '0.073*\"english\" + 0.041*\"previous\" + 0.033*\"sessions\" + 0.032*\"computer\" + 0.024*\"program\"')\n",
      "(6, '0.097*\"accent\" + 0.049*\"right\" + 0.037*\"wrong\" + 0.031*\"theory\" + 0.027*\"equation\"')\n",
      "(7, '0.253*\"hours\" + 0.244*\"office\" + 0.040*\"available\" + 0.031*\"trouble\" + 0.020*\"encourage\"')\n",
      "(8, '0.083*\"smart\" + 0.057*\"level\" + 0.040*\"college\" + 0.034*\"engineering\" + 0.028*\"others\"')\n",
      "(9, '0.150*\"midterm\" + 0.148*\"final\" + 0.102*\"curve\" + 0.071*\"grading\" + 0.059*\"average\"')\n",
      "(10, '0.180*\"teaching\" + 0.044*\"instructor\" + 0.029*\"style\" + 0.027*\"email\" + 0.027*\"rather\"')\n",
      "(11, '0.058*\"knowledgeable\" + 0.052*\"comment\" + 0.047*\"wonderful\" + 0.044*\"intelligent\" + 0.042*\"understandable\"')\n",
      "(12, '0.141*\"student\" + 0.131*\"understand\" + 0.095*\"explain\" + 0.057*\"things\" + 0.047*\"everything\"')\n",
      "(13, '0.143*\"class\" + 0.046*\"professor\" + 0.042*\"teacher\" + 0.039*\"really\" + 0.032*\"great\"')\n",
      "(14, '0.302*\"question\" + 0.134*\"answer\" + 0.030*\"ask\" + 0.029*\"assign\" + 0.027*\"choice\"')\n",
      "\n",
      "Coherence Score:  0.3474438284664295\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 40\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.065*\"discussion\" + 0.061*\"grader\" + 0.058*\"section\" + 0.044*\"talks\" + 0.032*\"hate\"')\n",
      "(1, '0.153*\"know\" + 0.114*\"stuff\" + 0.073*\"instructor\" + 0.067*\"talking\" + 0.047*\"mistake\"')\n",
      "(2, '0.102*\"teacher\" + 0.095*\"really\" + 0.078*\"great\" + 0.064*\"helpful\" + 0.044*\"interest\"')\n",
      "(3, '0.042*\"especially\" + 0.037*\"amount\" + 0.036*\"somewhat\" + 0.035*\"engineering\" + 0.028*\"intelligent\"')\n",
      "(4, '0.405*\"student\" + 0.147*\"willing\" + 0.081*\"want\" + 0.078*\"care\" + 0.027*\"available\"')\n",
      "(5, '0.142*\"lecture\" + 0.087*\"test\" + 0.079*\"homework\" + 0.070*\"exam\" + 0.054*\"problem\"')\n",
      "(6, '0.156*\"class\" + 0.051*\"professor\" + 0.033*\"material\" + 0.031*\"understand\" + 0.027*\"teach\"')\n",
      "(7, '0.062*\"project\" + 0.045*\"email\" + 0.022*\"looking\" + 0.022*\"computer\" + 0.021*\"look\"')\n",
      "(8, '0.256*\"hours\" + 0.247*\"office\" + 0.021*\"ramble\" + 0.018*\"period\" + 0.018*\"idea\"')\n",
      "(9, '0.132*\"clear\" + 0.101*\"extremely\" + 0.066*\"subject\" + 0.047*\"follow\" + 0.044*\"topic\"')\n",
      "(10, '0.211*\"explain\" + 0.148*\"recommend\" + 0.127*\"things\" + 0.092*\"concept\" + 0.057*\"highly\"')\n",
      "(11, '0.046*\"wrong\" + 0.044*\"suck\" + 0.036*\"pointless\" + 0.027*\"random\" + 0.024*\"bother\"')\n",
      "(12, '0.217*\"grade\" + 0.143*\"midterm\" + 0.141*\"final\" + 0.059*\"credit\" + 0.054*\"extra\"')\n",
      "(13, '0.303*\"question\" + 0.134*\"answer\" + 0.072*\"accent\" + 0.030*\"ask\" + 0.027*\"choice\"')\n",
      "(14, '0.163*\"point\" + 0.130*\"grading\" + 0.048*\"tell\" + 0.039*\"costs\" + 0.030*\"read\"')\n",
      "\n",
      "Coherence Score:  0.3477031948045414\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 45\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.137*\"concept\" + 0.042*\"proof\" + 0.037*\"simple\" + 0.026*\"straightforward\" + 0.024*\"similar\"')\n",
      "(1, '0.210*\"question\" + 0.180*\"explain\" + 0.109*\"things\" + 0.093*\"answer\" + 0.047*\"clearly\"')\n",
      "(2, '0.142*\"could\" + 0.105*\"anything\" + 0.047*\"level\" + 0.036*\"whole\" + 0.030*\"world\"')\n",
      "(3, '0.089*\"sense\" + 0.062*\"humor\" + 0.039*\"somewhat\" + 0.019*\"choose\" + 0.019*\"period\"')\n",
      "(4, '0.104*\"worst\" + 0.079*\"avoid\" + 0.070*\"terrible\" + 0.064*\"horrible\" + 0.056*\"nothing\"')\n",
      "(5, '0.125*\"funny\" + 0.035*\"around\" + 0.033*\"joke\" + 0.032*\"science\" + 0.031*\"entertain\"')\n",
      "(6, '0.116*\"physics\" + 0.058*\"grader\" + 0.047*\"writing\" + 0.038*\"theory\" + 0.026*\"attending\"')\n",
      "(7, '0.188*\"hours\" + 0.181*\"office\" + 0.088*\"care\" + 0.030*\"helping\" + 0.028*\"succeed\"')\n",
      "(8, '0.188*\"class\" + 0.068*\"lecture\" + 0.041*\"test\" + 0.038*\"homework\" + 0.034*\"helpful\"')\n",
      "(9, '0.076*\"teacher\" + 0.071*\"really\" + 0.054*\"student\" + 0.054*\"material\" + 0.050*\"understand\"')\n",
      "(10, '0.058*\"write\" + 0.044*\"spend\" + 0.035*\"useless\" + 0.034*\"board\" + 0.030*\"discussion\"')\n",
      "(11, '0.090*\"instructor\" + 0.075*\"another\" + 0.058*\"matter\" + 0.054*\"exactly\" + 0.044*\"suck\"')\n",
      "(12, '0.042*\"project\" + 0.038*\"require\" + 0.035*\"experience\" + 0.030*\"recitation\" + 0.026*\"group\"')\n",
      "(13, '0.176*\"professor\" + 0.123*\"great\" + 0.079*\"would\" + 0.070*\"interest\" + 0.054*\"recommend\"')\n",
      "(14, '0.169*\"grade\" + 0.111*\"midterm\" + 0.110*\"final\" + 0.076*\"curve\" + 0.053*\"grading\"')\n",
      "\n",
      "Coherence Score:  0.35582171916412075\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 50\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.174*\"grade\" + 0.114*\"midterm\" + 0.113*\"final\" + 0.085*\"first\" + 0.079*\"curve\"')\n",
      "(1, '0.207*\"lecture\" + 0.061*\"pretty\" + 0.040*\"though\" + 0.040*\"boring\" + 0.033*\"little\"')\n",
      "(2, '0.165*\"class\" + 0.052*\"professor\" + 0.048*\"teacher\" + 0.045*\"really\" + 0.037*\"great\"')\n",
      "(3, '0.135*\"accent\" + 0.091*\"often\" + 0.065*\"speak\" + 0.064*\"joke\" + 0.038*\"stupid\"')\n",
      "(4, '0.247*\"question\" + 0.109*\"answer\" + 0.070*\"point\" + 0.030*\"right\" + 0.028*\"email\"')\n",
      "(5, '0.058*\"semester\" + 0.037*\"level\" + 0.035*\"style\" + 0.026*\"suck\" + 0.026*\"college\"')\n",
      "(6, '0.312*\"student\" + 0.063*\"want\" + 0.060*\"care\" + 0.049*\"understanding\" + 0.028*\"matter\"')\n",
      "(7, '0.271*\"explain\" + 0.163*\"things\" + 0.119*\"concept\" + 0.070*\"clearly\" + 0.048*\"project\"')\n",
      "(8, '0.219*\"hours\" + 0.212*\"office\" + 0.037*\"choice\" + 0.035*\"tell\" + 0.032*\"multiple\"')\n",
      "(9, '0.061*\"never\" + 0.058*\"everything\" + 0.051*\"could\" + 0.044*\"take\" + 0.043*\"worst\"')\n",
      "(10, '0.139*\"test\" + 0.126*\"homework\" + 0.112*\"exam\" + 0.085*\"problem\" + 0.048*\"quiz\"')\n",
      "(11, '0.145*\"would\" + 0.100*\"recommend\" + 0.099*\"course\" + 0.050*\"definitely\" + 0.048*\"taking\"')\n",
      "(12, '0.115*\"example\" + 0.058*\"write\" + 0.057*\"avoid\" + 0.044*\"spend\" + 0.034*\"board\"')\n",
      "(13, '0.120*\"talking\" + 0.044*\"end\" + 0.042*\"tutor\" + 0.037*\"maybe\" + 0.032*\"generally\"')\n",
      "(14, '0.089*\"note\" + 0.049*\"textbook\" + 0.044*\"online\" + 0.040*\"follow\" + 0.039*\"cover\"')\n",
      "\n",
      "Coherence Score:  0.3674044336649639\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 50\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.120*\"worst\" + 0.091*\"avoid\" + 0.081*\"terrible\" + 0.074*\"horrible\" + 0.064*\"nothing\"')\n",
      "(1, '0.086*\"physics\" + 0.056*\"project\" + 0.047*\"experience\" + 0.032*\"awful\" + 0.032*\"college\"')\n",
      "(2, '0.320*\"question\" + 0.141*\"answer\" + 0.031*\"ask\" + 0.029*\"wrong\" + 0.028*\"suck\"')\n",
      "(3, '0.078*\"speak\" + 0.064*\"come\" + 0.040*\"method\" + 0.036*\"frustrate\" + 0.034*\"means\"')\n",
      "(4, '0.096*\"sometimes\" + 0.086*\"confuse\" + 0.085*\"seem\" + 0.064*\"follow\" + 0.049*\"often\"')\n",
      "(5, '0.075*\"boring\" + 0.051*\"point\" + 0.046*\"textbook\" + 0.032*\"reading\" + 0.032*\"slide\"')\n",
      "(6, '0.120*\"know\" + 0.089*\"stuff\" + 0.058*\"smart\" + 0.053*\"talking\" + 0.038*\"english\"')\n",
      "(7, '0.106*\"lecture\" + 0.069*\"test\" + 0.062*\"homework\" + 0.055*\"exam\" + 0.042*\"problem\"')\n",
      "(8, '0.050*\"choice\" + 0.047*\"show\" + 0.047*\"tell\" + 0.043*\"multiple\" + 0.039*\"comment\"')\n",
      "(9, '0.093*\"easy\" + 0.084*\"credit\" + 0.077*\"extra\" + 0.052*\"calculus\" + 0.032*\"engineering\"')\n",
      "(10, '0.047*\"thing\" + 0.047*\"something\" + 0.037*\"school\" + 0.032*\"someone\" + 0.029*\"whole\"')\n",
      "(11, '0.112*\"quiz\" + 0.111*\"note\" + 0.063*\"review\" + 0.059*\"write\" + 0.055*\"online\"')\n",
      "(12, '0.054*\"email\" + 0.053*\"getting\" + 0.034*\"straightforward\" + 0.029*\"end\" + 0.028*\"suggest\"')\n",
      "(13, '0.206*\"hours\" + 0.199*\"office\" + 0.068*\"sense\" + 0.047*\"humor\" + 0.024*\"wonderful\"')\n",
      "(14, '0.131*\"class\" + 0.042*\"professor\" + 0.038*\"teacher\" + 0.036*\"really\" + 0.029*\"great\"')\n",
      "\n",
      "Coherence Score:  0.3336394144164624\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 50\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findings on NUM_PASSES is different - peak at 15, then again at 30, 40\n",
    "# also some weirdness when running same parameters many times - not really same results. what happens if i run more passes?\n",
    "# working on stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.185*\"final\" + 0.184*\"midterm\" + 0.056*\"straight\" + 0.044*\"email\" + 0.033*\"post\"')\n",
      "(1, '0.161*\"sometimes\" + 0.135*\"review\" + 0.058*\"english\" + 0.057*\"speak\" + 0.055*\"unclear\"')\n",
      "(2, '0.047*\"whole\" + 0.042*\"suck\" + 0.041*\"tell\" + 0.037*\"story\" + 0.037*\"minutes\"')\n",
      "(3, '0.043*\"worst\" + 0.039*\"confuse\" + 0.038*\"anything\" + 0.033*\"avoid\" + 0.029*\"terrible\"')\n",
      "(4, '0.119*\"note\" + 0.110*\"boring\" + 0.068*\"textbook\" + 0.061*\"online\" + 0.049*\"reading\"')\n",
      "(5, '0.098*\"credit\" + 0.090*\"extra\" + 0.035*\"second\" + 0.032*\"allow\" + 0.032*\"sheet\"')\n",
      "(6, '0.105*\"lecture\" + 0.065*\"test\" + 0.058*\"homework\" + 0.051*\"exam\" + 0.038*\"problem\"')\n",
      "(7, '0.281*\"question\" + 0.146*\"hours\" + 0.140*\"office\" + 0.123*\"answer\" + 0.027*\"ask\"')\n",
      "(8, '0.156*\"know\" + 0.117*\"stuff\" + 0.069*\"talking\" + 0.054*\"discussion\" + 0.050*\"style\"')\n",
      "(9, '0.127*\"people\" + 0.081*\"smart\" + 0.050*\"grader\" + 0.050*\"getting\" + 0.036*\"important\"')\n",
      "(10, '0.135*\"class\" + 0.043*\"professor\" + 0.040*\"teacher\" + 0.037*\"really\" + 0.030*\"great\"')\n",
      "(11, '0.070*\"experience\" + 0.064*\"science\" + 0.030*\"computer\" + 0.028*\"front\" + 0.028*\"paper\"')\n",
      "(12, '0.211*\"explain\" + 0.129*\"things\" + 0.095*\"concept\" + 0.057*\"accent\" + 0.054*\"clearly\"')\n",
      "(13, '0.067*\"someone\" + 0.055*\"college\" + 0.053*\"talks\" + 0.044*\"comment\" + 0.043*\"stupid\"')\n",
      "(14, '0.202*\"example\" + 0.060*\"board\" + 0.051*\"right\" + 0.050*\"proof\" + 0.038*\"explanation\"')\n",
      "\n",
      "Coherence Score:  0.3271332624179475\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 100\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.095*\"professor\" + 0.081*\"really\" + 0.066*\"great\" + 0.053*\"helpful\" + 0.037*\"interest\"')\n",
      "(1, '0.232*\"class\" + 0.068*\"teacher\" + 0.040*\"teach\" + 0.034*\"learn\" + 0.027*\"grade\"')\n",
      "(2, '0.113*\"grading\" + 0.056*\"grader\" + 0.028*\"powerpoint\" + 0.023*\"trick\" + 0.021*\"system\"')\n",
      "(3, '0.181*\"homework\" + 0.147*\"question\" + 0.120*\"problem\" + 0.068*\"quiz\" + 0.065*\"answer\"')\n",
      "(4, '0.039*\"state\" + 0.038*\"fail\" + 0.032*\"become\" + 0.031*\"maybe\" + 0.029*\"programming\"')\n",
      "(5, '0.118*\"credit\" + 0.108*\"extra\" + 0.034*\"intelligent\" + 0.033*\"offer\" + 0.024*\"stick\"')\n",
      "(6, '0.155*\"accent\" + 0.081*\"style\" + 0.076*\"english\" + 0.072*\"unclear\" + 0.063*\"come\"')\n",
      "(7, '0.111*\"straight\" + 0.080*\"listen\" + 0.072*\"choice\" + 0.062*\"friendly\" + 0.061*\"multiple\"')\n",
      "(8, '0.202*\"final\" + 0.201*\"midterm\" + 0.081*\"average\" + 0.031*\"straightforward\" + 0.031*\"second\"')\n",
      "(9, '0.142*\"student\" + 0.139*\"material\" + 0.131*\"understand\" + 0.082*\"teaching\" + 0.042*\"know\"')\n",
      "(10, '0.252*\"explain\" + 0.154*\"things\" + 0.114*\"concept\" + 0.065*\"clearly\" + 0.037*\"calculus\"')\n",
      "(11, '0.114*\"lecture\" + 0.071*\"test\" + 0.056*\"exam\" + 0.033*\"pretty\" + 0.025*\"example\"')\n",
      "(12, '0.100*\"worst\" + 0.076*\"avoid\" + 0.067*\"terrible\" + 0.062*\"horrible\" + 0.038*\"mistake\"')\n",
      "(13, '0.315*\"would\" + 0.217*\"recommend\" + 0.083*\"highly\" + 0.052*\"anyone\" + 0.021*\"prof\"')\n",
      "(14, '0.211*\"course\" + 0.119*\"curve\" + 0.045*\"level\" + 0.039*\"rather\" + 0.020*\"move\"')\n",
      "\n",
      "Coherence Score:  0.3760742627363358\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 100\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.092*\"sense\" + 0.065*\"humor\" + 0.046*\"tell\" + 0.029*\"sessions\" + 0.027*\"kinda\"')\n",
      "(1, '0.096*\"project\" + 0.069*\"english\" + 0.065*\"group\" + 0.047*\"somewhat\" + 0.039*\"others\"')\n",
      "(2, '0.179*\"question\" + 0.152*\"explain\" + 0.094*\"things\" + 0.082*\"willing\" + 0.078*\"answer\"')\n",
      "(3, '0.355*\"student\" + 0.072*\"want\" + 0.071*\"care\" + 0.039*\"effort\" + 0.035*\"outside\"')\n",
      "(4, '0.119*\"grade\" + 0.076*\"final\" + 0.074*\"midterm\" + 0.055*\"curve\" + 0.046*\"point\"')\n",
      "(5, '0.250*\"hours\" + 0.239*\"office\" + 0.077*\"instructor\" + 0.054*\"email\" + 0.023*\"difficulty\"')\n",
      "(6, '0.066*\"major\" + 0.059*\"college\" + 0.053*\"change\" + 0.036*\"truly\" + 0.034*\"otherwise\"')\n",
      "(7, '0.128*\"class\" + 0.040*\"professor\" + 0.038*\"teacher\" + 0.035*\"really\" + 0.028*\"great\"')\n",
      "(8, '0.108*\"assignment\" + 0.073*\"reading\" + 0.035*\"assign\" + 0.034*\"attendance\" + 0.030*\"important\"')\n",
      "(9, '0.130*\"lecture\" + 0.082*\"test\" + 0.071*\"homework\" + 0.063*\"exam\" + 0.047*\"problem\"')\n",
      "(10, '0.071*\"terrible\" + 0.045*\"discussion\" + 0.031*\"ask\" + 0.030*\"awful\" + 0.030*\"wrong\"')\n",
      "(11, '0.091*\"worst\" + 0.069*\"avoid\" + 0.065*\"accent\" + 0.056*\"horrible\" + 0.049*\"nothing\"')\n",
      "(12, '0.050*\"calculus\" + 0.049*\"level\" + 0.037*\"come\" + 0.032*\"show\" + 0.032*\"knowledge\"')\n",
      "(13, '0.086*\"slide\" + 0.069*\"straight\" + 0.042*\"talks\" + 0.039*\"pointless\" + 0.035*\"forward\"')\n",
      "(14, '0.205*\"pretty\" + 0.119*\"know\" + 0.100*\"sometimes\" + 0.089*\"stuff\" + 0.052*\"talking\"')\n",
      "\n",
      "Coherence Score:  0.34871069116621045\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 200\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.123*\"cover\" + 0.105*\"nothing\" + 0.057*\"awful\" + 0.053*\"present\" + 0.026*\"skip\"')\n",
      "(1, '0.327*\"student\" + 0.098*\"know\" + 0.074*\"stuff\" + 0.067*\"want\" + 0.065*\"care\"')\n",
      "(2, '0.137*\"class\" + 0.050*\"lecture\" + 0.043*\"professor\" + 0.041*\"teacher\" + 0.037*\"really\"')\n",
      "(3, '0.108*\"test\" + 0.094*\"homework\" + 0.083*\"exam\" + 0.061*\"problem\" + 0.057*\"difficult\"')\n",
      "(4, '0.258*\"explain\" + 0.160*\"things\" + 0.066*\"clearly\" + 0.038*\"mistake\" + 0.031*\"simple\"')\n",
      "(5, '0.088*\"topic\" + 0.069*\"project\" + 0.059*\"without\" + 0.046*\"group\" + 0.032*\"costs\"')\n",
      "(6, '0.061*\"style\" + 0.058*\"matter\" + 0.044*\"tell\" + 0.040*\"story\" + 0.039*\"passionate\"')\n",
      "(7, '0.188*\"course\" + 0.035*\"rather\" + 0.032*\"economics\" + 0.026*\"world\" + 0.026*\"knowledge\"')\n",
      "(8, '0.105*\"sense\" + 0.093*\"instructor\" + 0.075*\"humor\" + 0.063*\"grader\" + 0.038*\"quickly\"')\n",
      "(9, '0.125*\"point\" + 0.089*\"credit\" + 0.082*\"extra\" + 0.060*\"discussion\" + 0.050*\"section\"')\n",
      "(10, '0.117*\"note\" + 0.069*\"textbook\" + 0.063*\"write\" + 0.063*\"online\" + 0.053*\"follow\"')\n",
      "(11, '0.112*\"final\" + 0.109*\"midterm\" + 0.081*\"curve\" + 0.054*\"grading\" + 0.045*\"average\"')\n",
      "(12, '0.350*\"question\" + 0.153*\"answer\" + 0.043*\"right\" + 0.030*\"talks\" + 0.024*\"stupid\"')\n",
      "(13, '0.082*\"teach\" + 0.056*\"teaching\" + 0.035*\"never\" + 0.028*\"could\" + 0.027*\"first\"')\n",
      "(14, '0.145*\"boring\" + 0.077*\"accent\" + 0.058*\"slide\" + 0.037*\"speak\" + 0.037*\"english\"')\n",
      "\n",
      "Coherence Score:  0.33399436169244867\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 200\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.145*\"class\" + 0.046*\"professor\" + 0.043*\"teacher\" + 0.040*\"really\" + 0.032*\"great\"')\n",
      "(1, '0.165*\"know\" + 0.124*\"stuff\" + 0.072*\"talking\" + 0.060*\"straight\" + 0.055*\"science\"')\n",
      "(2, '0.069*\"people\" + 0.065*\"seem\" + 0.036*\"instructor\" + 0.036*\"something\" + 0.030*\"level\"')\n",
      "(3, '0.098*\"worst\" + 0.087*\"anything\" + 0.061*\"horrible\" + 0.054*\"impossible\" + 0.053*\"nothing\"')\n",
      "(4, '0.055*\"rather\" + 0.054*\"speak\" + 0.053*\"english\" + 0.048*\"instead\" + 0.043*\"talks\"')\n",
      "(5, '0.129*\"funny\" + 0.092*\"try\" + 0.052*\"like\" + 0.035*\"joke\" + 0.034*\"entertain\"')\n",
      "(6, '0.173*\"final\" + 0.168*\"midterm\" + 0.162*\"boring\" + 0.040*\"exactly\" + 0.033*\"tell\"')\n",
      "(7, '0.083*\"credit\" + 0.077*\"extra\" + 0.057*\"brother\" + 0.043*\"grader\" + 0.031*\"enjoyable\"')\n",
      "(8, '0.093*\"slide\" + 0.064*\"matter\" + 0.045*\"show\" + 0.045*\"world\" + 0.044*\"knowledge\"')\n",
      "(9, '0.070*\"grade\" + 0.044*\"never\" + 0.040*\"going\" + 0.037*\"every\" + 0.028*\"assignment\"')\n",
      "(10, '0.128*\"lecture\" + 0.081*\"test\" + 0.070*\"homework\" + 0.062*\"exam\" + 0.048*\"explain\"')\n",
      "(11, '0.134*\"pretty\" + 0.088*\"though\" + 0.072*\"little\" + 0.069*\"curve\" + 0.065*\"sometimes\"')\n",
      "(12, '0.134*\"avoid\" + 0.118*\"terrible\" + 0.088*\"useless\" + 0.047*\"waste\" + 0.039*\"costs\"')\n",
      "(13, '0.217*\"hours\" + 0.206*\"office\" + 0.025*\"state\" + 0.019*\"work\" + 0.018*\"generally\"')\n",
      "(14, '0.304*\"question\" + 0.133*\"answer\" + 0.034*\"email\" + 0.028*\"ask\" + 0.026*\"writing\"')\n",
      "\n",
      "Coherence Score:  0.32050161874744443\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.073*\"style\" + 0.035*\"trouble\" + 0.034*\"intelligent\" + 0.029*\"programming\" + 0.026*\"program\"')\n",
      "(1, '0.079*\"attend\" + 0.068*\"absolutely\" + 0.034*\"stupid\" + 0.032*\"hate\" + 0.029*\"tutor\"')\n",
      "(2, '0.144*\"accent\" + 0.049*\"knowledgeable\" + 0.038*\"method\" + 0.035*\"mandatory\" + 0.035*\"understandable\"')\n",
      "(3, '0.111*\"write\" + 0.064*\"board\" + 0.049*\"speak\" + 0.048*\"english\" + 0.038*\"story\"')\n",
      "(4, '0.211*\"course\" + 0.055*\"instructor\" + 0.046*\"level\" + 0.030*\"world\" + 0.026*\"comment\"')\n",
      "(5, '0.232*\"question\" + 0.102*\"answer\" + 0.074*\"sometimes\" + 0.068*\"confuse\" + 0.041*\"attention\"')\n",
      "(6, '0.296*\"problem\" + 0.175*\"example\" + 0.045*\"proof\" + 0.027*\"theory\" + 0.024*\"similar\"')\n",
      "(7, '0.172*\"class\" + 0.054*\"professor\" + 0.051*\"teacher\" + 0.047*\"really\" + 0.038*\"great\"')\n",
      "(8, '0.220*\"explain\" + 0.148*\"clear\" + 0.137*\"things\" + 0.103*\"concept\" + 0.056*\"clearly\"')\n",
      "(9, '0.120*\"anything\" + 0.104*\"avoid\" + 0.092*\"terrible\" + 0.085*\"horrible\" + 0.046*\"someone\"')\n",
      "(10, '0.117*\"worst\" + 0.048*\"calculus\" + 0.046*\"school\" + 0.037*\"start\" + 0.034*\"awful\"')\n",
      "(11, '0.253*\"lecture\" + 0.050*\"note\" + 0.048*\"boring\" + 0.045*\"going\" + 0.030*\"textbook\"')\n",
      "(12, '0.097*\"straight\" + 0.077*\"email\" + 0.050*\"forward\" + 0.045*\"quickly\" + 0.040*\"prof\"')\n",
      "(13, '0.057*\"test\" + 0.049*\"homework\" + 0.044*\"exam\" + 0.030*\"difficult\" + 0.029*\"grade\"')\n",
      "(14, '0.171*\"student\" + 0.120*\"would\" + 0.083*\"recommend\" + 0.069*\"hours\" + 0.066*\"office\"')\n",
      "\n",
      "Coherence Score:  0.3543293517559398\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.201*\"class\" + 0.063*\"professor\" + 0.059*\"teacher\" + 0.055*\"really\" + 0.044*\"great\"')\n",
      "(1, '0.196*\"explain\" + 0.122*\"things\" + 0.092*\"concept\" + 0.050*\"clearly\" + 0.044*\"topic\"')\n",
      "(2, '0.080*\"cover\" + 0.070*\"impossible\" + 0.035*\"suck\" + 0.024*\"method\" + 0.023*\"random\"')\n",
      "(3, '0.079*\"boring\" + 0.067*\"could\" + 0.064*\"first\" + 0.061*\"better\" + 0.053*\"people\"')\n",
      "(4, '0.174*\"recommend\" + 0.145*\"hours\" + 0.138*\"office\" + 0.085*\"taking\" + 0.066*\"highly\"')\n",
      "(5, '0.061*\"speak\" + 0.053*\"awful\" + 0.042*\"theory\" + 0.040*\"costs\" + 0.040*\"comment\"')\n",
      "(6, '0.339*\"question\" + 0.148*\"answer\" + 0.032*\"ask\" + 0.023*\"stupid\" + 0.019*\"move\"')\n",
      "(7, '0.105*\"know\" + 0.079*\"stuff\" + 0.069*\"love\" + 0.057*\"enjoy\" + 0.050*\"like\"')\n",
      "(8, '0.080*\"lecture\" + 0.051*\"test\" + 0.044*\"homework\" + 0.039*\"exam\" + 0.037*\"helpful\"')\n",
      "(9, '0.083*\"terrible\" + 0.050*\"calculus\" + 0.049*\"experience\" + 0.049*\"level\" + 0.049*\"school\"')\n",
      "(10, '0.104*\"worst\" + 0.080*\"avoid\" + 0.074*\"accent\" + 0.064*\"horrible\" + 0.056*\"nothing\"')\n",
      "(11, '0.072*\"confuse\" + 0.060*\"write\" + 0.051*\"follow\" + 0.047*\"spend\" + 0.040*\"often\"')\n",
      "(12, '0.266*\"student\" + 0.054*\"want\" + 0.054*\"care\" + 0.041*\"understanding\" + 0.026*\"outside\"')\n",
      "(13, '0.088*\"instructor\" + 0.080*\"discussion\" + 0.066*\"section\" + 0.062*\"unclear\" + 0.045*\"pointless\"')\n",
      "(14, '0.128*\"grade\" + 0.081*\"final\" + 0.079*\"midterm\" + 0.059*\"curve\" + 0.039*\"grading\"')\n",
      "\n",
      "Coherence Score:  0.3453487472173829\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='umass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving on to # topics\n",
    "So, it seems that more passes makes the variance in Coherence smaller. Let's move on to varying # of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.011*\"arrogant\" + 0.010*\"classroom\" + 0.009*\"rock\" + 0.008*\"book\" + 0.007*\"respect\"')\n",
      "(1, '0.069*\"worst\" + 0.020*\"awful\" + 0.019*\"suck\" + 0.014*\"quarter\" + 0.012*\"random\"')\n",
      "(2, '0.074*\"final\" + 0.072*\"midterm\" + 0.033*\"credit\" + 0.030*\"extra\" + 0.030*\"average\"')\n",
      "(3, '0.064*\"class\" + 0.024*\"lecture\" + 0.020*\"professor\" + 0.019*\"teacher\" + 0.017*\"really\"')\n",
      "(4, '0.053*\"online\" + 0.053*\"avoid\" + 0.037*\"slide\" + 0.035*\"useless\" + 0.018*\"post\"')\n",
      "\n",
      "Coherence Score (Cv):  0.4097889812328419\n",
      "\n",
      "Coherence Score (umass):  -9.11944395447859\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 5\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.103*\"care\" + 0.073*\"sense\" + 0.052*\"humor\" + 0.033*\"helping\" + 0.029*\"comment\"')\n",
      "(1, '0.029*\"thing\" + 0.026*\"worth\" + 0.024*\"experience\" + 0.024*\"science\" + 0.023*\"joke\"')\n",
      "(2, '0.184*\"explain\" + 0.115*\"things\" + 0.086*\"concept\" + 0.048*\"grading\" + 0.047*\"clearly\"')\n",
      "(3, '0.083*\"teach\" + 0.045*\"course\" + 0.035*\"never\" + 0.029*\"could\" + 0.029*\"think\"')\n",
      "(4, '0.188*\"question\" + 0.087*\"final\" + 0.085*\"midterm\" + 0.082*\"answer\" + 0.035*\"average\"')\n",
      "(5, '0.048*\"useless\" + 0.042*\"discussion\" + 0.032*\"speak\" + 0.032*\"english\" + 0.030*\"basically\"')\n",
      "(6, '0.091*\"assignment\" + 0.089*\"point\" + 0.064*\"credit\" + 0.059*\"extra\" + 0.047*\"project\"')\n",
      "(7, '0.061*\"lecture\" + 0.038*\"test\" + 0.033*\"homework\" + 0.033*\"material\" + 0.031*\"understand\"')\n",
      "(8, '0.190*\"class\" + 0.060*\"professor\" + 0.056*\"teacher\" + 0.052*\"really\" + 0.042*\"great\"')\n",
      "(9, '0.035*\"writing\" + 0.034*\"talks\" + 0.029*\"relate\" + 0.024*\"tutor\" + 0.024*\"state\"')\n",
      "\n",
      "Coherence Score (Cv):  0.32588561823721846\n",
      "\n",
      "Coherence Score (umass):  -6.286069785917216\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 10\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.050*\"proof\" + 0.043*\"base\" + 0.042*\"grader\" + 0.038*\"assign\" + 0.027*\"equation\"')\n",
      "(1, '0.306*\"question\" + 0.134*\"answer\" + 0.034*\"email\" + 0.029*\"ask\" + 0.028*\"wrong\"')\n",
      "(2, '0.151*\"hours\" + 0.143*\"office\" + 0.137*\"final\" + 0.133*\"midterm\" + 0.100*\"curve\"')\n",
      "(3, '0.164*\"class\" + 0.052*\"professor\" + 0.048*\"teacher\" + 0.045*\"really\" + 0.036*\"great\"')\n",
      "(4, '0.161*\"would\" + 0.112*\"recommend\" + 0.054*\"taking\" + 0.043*\"highly\" + 0.027*\"project\"')\n",
      "(5, '0.133*\"physics\" + 0.129*\"avoid\" + 0.073*\"absolutely\" + 0.037*\"costs\" + 0.025*\"research\"')\n",
      "(6, '0.089*\"grading\" + 0.050*\"style\" + 0.033*\"show\" + 0.024*\"method\" + 0.022*\"looking\"')\n",
      "(7, '0.079*\"explain\" + 0.070*\"difficult\" + 0.061*\"pretty\" + 0.054*\"course\" + 0.053*\"clear\"')\n",
      "(8, '0.070*\"recitation\" + 0.057*\"passionate\" + 0.041*\"sister\" + 0.034*\"difficulty\" + 0.032*\"hands\"')\n",
      "(9, '0.153*\"people\" + 0.067*\"school\" + 0.038*\"comment\" + 0.029*\"computer\" + 0.028*\"annoying\"')\n",
      "(10, '0.159*\"know\" + 0.119*\"stuff\" + 0.070*\"talking\" + 0.036*\"writing\" + 0.035*\"talks\"')\n",
      "(11, '0.040*\"never\" + 0.036*\"going\" + 0.031*\"first\" + 0.028*\"worst\" + 0.026*\"confuse\"')\n",
      "(12, '0.038*\"choice\" + 0.032*\"multiple\" + 0.031*\"straightforward\" + 0.027*\"sheet\" + 0.026*\"figure\"')\n",
      "(13, '0.136*\"lecture\" + 0.085*\"test\" + 0.074*\"homework\" + 0.066*\"exam\" + 0.048*\"problem\"')\n",
      "(14, '0.065*\"decent\" + 0.047*\"previous\" + 0.046*\"guide\" + 0.044*\"similar\" + 0.039*\"state\"')\n",
      "\n",
      "Coherence Score (Cv):  0.33948587136705305\n",
      "\n",
      "Coherence Score (umass):  -7.687713677109255\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.369*\"question\" + 0.161*\"answer\" + 0.046*\"right\" + 0.033*\"wrong\" + 0.026*\"stupid\"')\n",
      "(1, '0.107*\"physics\" + 0.065*\"instructor\" + 0.050*\"matter\" + 0.037*\"department\" + 0.037*\"approachable\"')\n",
      "(2, '0.120*\"understand\" + 0.087*\"explain\" + 0.080*\"interest\" + 0.077*\"make\" + 0.054*\"things\"')\n",
      "(3, '0.201*\"grade\" + 0.128*\"final\" + 0.124*\"midterm\" + 0.093*\"curve\" + 0.052*\"average\"')\n",
      "(4, '0.080*\"almost\" + 0.068*\"calculus\" + 0.056*\"exactly\" + 0.046*\"tell\" + 0.045*\"writing\"')\n",
      "(5, '0.286*\"class\" + 0.090*\"professor\" + 0.049*\"teach\" + 0.042*\"learn\" + 0.040*\"would\"')\n",
      "(6, '0.100*\"lecturer\" + 0.093*\"cover\" + 0.070*\"fairly\" + 0.069*\"quite\" + 0.065*\"possible\"')\n",
      "(7, '0.211*\"really\" + 0.053*\"though\" + 0.047*\"know\" + 0.044*\"little\" + 0.040*\"try\"')\n",
      "(8, '0.247*\"course\" + 0.074*\"challenge\" + 0.065*\"something\" + 0.054*\"level\" + 0.023*\"computer\"')\n",
      "(9, '0.209*\"recommend\" + 0.105*\"definitely\" + 0.102*\"taking\" + 0.080*\"highly\" + 0.051*\"anyone\"')\n",
      "(10, '0.120*\"lecture\" + 0.075*\"test\" + 0.065*\"homework\" + 0.064*\"material\" + 0.058*\"exam\"')\n",
      "(11, '0.449*\"student\" + 0.092*\"want\" + 0.091*\"care\" + 0.030*\"succeed\" + 0.029*\"helping\"')\n",
      "(12, '0.127*\"write\" + 0.127*\"avoid\" + 0.073*\"board\" + 0.049*\"awful\" + 0.048*\"ask\"')\n",
      "(13, '0.378*\"teacher\" + 0.282*\"great\" + 0.035*\"person\" + 0.029*\"brother\" + 0.016*\"friendly\"')\n",
      "(14, '0.060*\"boring\" + 0.057*\"going\" + 0.052*\"every\" + 0.040*\"people\" + 0.028*\"reading\"')\n",
      "(15, '0.145*\"assignment\" + 0.102*\"credit\" + 0.094*\"extra\" + 0.045*\"attendance\" + 0.029*\"offer\"')\n",
      "(16, '0.097*\"confuse\" + 0.094*\"point\" + 0.062*\"hard\" + 0.054*\"often\" + 0.042*\"mistake\"')\n",
      "(17, '0.107*\"easy\" + 0.096*\"topic\" + 0.075*\"project\" + 0.070*\"discussion\" + 0.057*\"section\"')\n",
      "(18, '0.195*\"always\" + 0.174*\"hours\" + 0.166*\"office\" + 0.156*\"willing\" + 0.043*\"outside\"')\n",
      "(19, '0.118*\"grading\" + 0.055*\"information\" + 0.046*\"suck\" + 0.045*\"present\" + 0.044*\"post\"')\n",
      "\n",
      "Coherence Score (Cv):  0.3202201352047905\n",
      "\n",
      "Coherence Score (umass):  -7.3178962004409644\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 20\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, '0.181*\"subject\" + 0.085*\"effort\" + 0.071*\"matter\" + 0.050*\"world\" + 0.021*\"personally\"')\n",
      "(23, '0.103*\"nothing\" + 0.059*\"major\" + 0.057*\"come\" + 0.047*\"change\" + 0.040*\"engineering\"')\n",
      "(14, '0.135*\"avoid\" + 0.113*\"credit\" + 0.104*\"extra\" + 0.076*\"possible\" + 0.039*\"costs\"')\n",
      "(19, '0.180*\"worst\" + 0.097*\"slide\" + 0.071*\"mistake\" + 0.049*\"college\" + 0.039*\"stupid\"')\n",
      "(21, '0.085*\"project\" + 0.065*\"found\" + 0.058*\"group\" + 0.054*\"recitation\" + 0.051*\"attendance\"')\n",
      "(7, '0.108*\"like\" + 0.068*\"although\" + 0.052*\"tell\" + 0.049*\"story\" + 0.043*\"somewhat\"')\n",
      "(20, '0.143*\"physics\" + 0.072*\"level\" + 0.049*\"suck\" + 0.045*\"pointless\" + 0.033*\"simply\"')\n",
      "(2, '0.179*\"take\" + 0.113*\"terrible\" + 0.068*\"calculus\" + 0.058*\"email\" + 0.048*\"already\"')\n",
      "(22, '0.151*\"point\" + 0.114*\"easy\" + 0.066*\"right\" + 0.053*\"start\" + 0.041*\"friendly\"')\n",
      "(18, '0.234*\"hours\" + 0.222*\"office\" + 0.050*\"speak\" + 0.049*\"english\" + 0.043*\"awful\"')\n",
      "(17, '0.301*\"teaching\" + 0.053*\"experience\" + 0.051*\"style\" + 0.034*\"show\" + 0.034*\"helping\"')\n",
      "(5, '0.317*\"explain\" + 0.197*\"things\" + 0.148*\"concept\" + 0.081*\"clearly\" + 0.066*\"excellent\"')\n",
      "(10, '0.241*\"pretty\" + 0.129*\"little\" + 0.114*\"overall\" + 0.109*\"tough\" + 0.078*\"lecturer\"')\n",
      "(11, '0.337*\"question\" + 0.147*\"answer\" + 0.067*\"horrible\" + 0.031*\"ask\" + 0.016*\"tangent\"')\n",
      "(13, '0.120*\"could\" + 0.092*\"anything\" + 0.062*\"spend\" + 0.060*\"probably\" + 0.050*\"thing\"')\n",
      "(6, '0.259*\"would\" + 0.179*\"recommend\" + 0.090*\"definitely\" + 0.087*\"taking\" + 0.068*\"highly\"')\n",
      "(15, '0.121*\"funny\" + 0.057*\"semester\" + 0.055*\"enjoy\" + 0.039*\"quite\" + 0.037*\"brother\"')\n",
      "(24, '0.274*\"lecture\" + 0.054*\"note\" + 0.052*\"boring\" + 0.049*\"going\" + 0.038*\"sometimes\"')\n",
      "(12, '0.093*\"test\" + 0.080*\"homework\" + 0.072*\"exam\" + 0.052*\"problem\" + 0.049*\"difficult\"')\n",
      "(16, '0.199*\"class\" + 0.063*\"professor\" + 0.059*\"teacher\" + 0.054*\"really\" + 0.044*\"great\"')\n",
      "\n",
      "Coherence Score (Cv):  0.3113650049917539\n",
      "\n",
      "Coherence Score (umass):  -8.275279340903431\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 25\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, '0.069*\"writing\" + 0.049*\"others\" + 0.047*\"trouble\" + 0.041*\"drop\" + 0.035*\"power\"')\n",
      "(3, '0.121*\"thing\" + 0.100*\"level\" + 0.079*\"whole\" + 0.073*\"easily\" + 0.047*\"seriously\"')\n",
      "(22, '0.101*\"straight\" + 0.090*\"proof\" + 0.078*\"exactly\" + 0.070*\"recitation\" + 0.057*\"pointless\"')\n",
      "(26, '0.156*\"easy\" + 0.155*\"semester\" + 0.102*\"brother\" + 0.041*\"sister\" + 0.037*\"become\"')\n",
      "(19, '0.177*\"assignment\" + 0.124*\"credit\" + 0.115*\"extra\" + 0.052*\"available\" + 0.035*\"offer\"')\n",
      "(29, '0.135*\"lecturer\" + 0.112*\"excellent\" + 0.072*\"making\" + 0.052*\"show\" + 0.049*\"friendly\"')\n",
      "(23, '0.273*\"boring\" + 0.056*\"incredibly\" + 0.048*\"knowledgeable\" + 0.032*\"awake\" + 0.031*\"read\"')\n",
      "(24, '0.215*\"take\" + 0.118*\"hard\" + 0.051*\"entire\" + 0.049*\"studying\" + 0.028*\"content\"')\n",
      "(2, '0.135*\"grading\" + 0.120*\"horrible\" + 0.105*\"impossible\" + 0.079*\"calculus\" + 0.075*\"right\"')\n",
      "(0, '0.076*\"experience\" + 0.075*\"school\" + 0.052*\"college\" + 0.051*\"stats\" + 0.045*\"enjoyable\"')\n",
      "(12, '0.280*\"explain\" + 0.174*\"things\" + 0.131*\"concept\" + 0.072*\"clearly\" + 0.066*\"super\"')\n",
      "(15, '0.275*\"would\" + 0.190*\"recommend\" + 0.093*\"taking\" + 0.072*\"highly\" + 0.046*\"another\"')\n",
      "(28, '0.327*\"exam\" + 0.141*\"example\" + 0.106*\"give\" + 0.080*\"review\" + 0.070*\"practice\"')\n",
      "(8, '0.391*\"teacher\" + 0.292*\"great\" + 0.036*\"person\" + 0.021*\"major\" + 0.017*\"knowledge\"')\n",
      "(9, '0.334*\"really\" + 0.075*\"know\" + 0.064*\"try\" + 0.063*\"sometimes\" + 0.056*\"stuff\"')\n",
      "(5, '0.367*\"lecture\" + 0.073*\"note\" + 0.043*\"textbook\" + 0.040*\"online\" + 0.039*\"write\"')\n",
      "(7, '0.185*\"understand\" + 0.116*\"teaching\" + 0.093*\"course\" + 0.059*\"could\" + 0.059*\"think\"')\n",
      "(21, '0.254*\"professor\" + 0.100*\"interest\" + 0.097*\"make\" + 0.074*\"clear\" + 0.059*\"funny\"')\n",
      "(1, '0.116*\"test\" + 0.100*\"homework\" + 0.065*\"problem\" + 0.061*\"difficult\" + 0.059*\"grade\"')\n",
      "(27, '0.395*\"class\" + 0.078*\"material\" + 0.068*\"teach\" + 0.059*\"learn\" + 0.029*\"never\"')\n",
      "\n",
      "Coherence Score (Cv):  0.3572794208136185\n",
      "\n",
      "Coherence Score (umass):  -8.985262763128167\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 30\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.168*\"effort\" + 0.071*\"trouble\" + 0.048*\"unorganized\" + 0.047*\"brilliant\" + 0.028*\"engineer\"')\n",
      "(34, '0.139*\"fairly\" + 0.079*\"stats\" + 0.047*\"become\" + 0.035*\"solution\" + 0.032*\"score\"')\n",
      "(32, '0.153*\"sense\" + 0.109*\"humor\" + 0.083*\"decent\" + 0.076*\"tell\" + 0.071*\"story\"')\n",
      "(28, '0.186*\"terrible\" + 0.075*\"waste\" + 0.075*\"available\" + 0.046*\"frustrate\" + 0.044*\"drop\"')\n",
      "(26, '0.129*\"instructor\" + 0.110*\"calculus\" + 0.069*\"important\" + 0.055*\"keep\" + 0.048*\"generous\"')\n",
      "(13, '0.153*\"smart\" + 0.106*\"science\" + 0.076*\"incredibly\" + 0.046*\"works\" + 0.034*\"remember\"')\n",
      "(19, '0.144*\"excellent\" + 0.097*\"entertain\" + 0.076*\"awful\" + 0.076*\"hilarious\" + 0.062*\"enjoyable\"')\n",
      "(23, '0.113*\"thing\" + 0.083*\"section\" + 0.065*\"reason\" + 0.057*\"passionate\" + 0.052*\"previous\"')\n",
      "(2, '0.154*\"lecturer\" + 0.053*\"straightforward\" + 0.046*\"complete\" + 0.044*\"others\" + 0.041*\"engage\"')\n",
      "(12, '0.131*\"probably\" + 0.099*\"straight\" + 0.090*\"mistake\" + 0.073*\"least\" + 0.051*\"forward\"')\n",
      "(6, '0.510*\"student\" + 0.103*\"care\" + 0.046*\"making\" + 0.038*\"ask\" + 0.023*\"offer\"')\n",
      "(15, '0.252*\"pretty\" + 0.174*\"funny\" + 0.097*\"love\" + 0.080*\"follow\" + 0.077*\"super\"')\n",
      "(5, '0.130*\"first\" + 0.092*\"still\" + 0.078*\"semester\" + 0.073*\"horrible\" + 0.064*\"impossible\"')\n",
      "(18, '0.164*\"never\" + 0.115*\"worst\" + 0.111*\"actually\" + 0.102*\"anything\" + 0.061*\"need\"')\n",
      "(33, '0.297*\"explain\" + 0.185*\"things\" + 0.139*\"concept\" + 0.076*\"clearly\" + 0.052*\"project\"')\n",
      "(29, '0.338*\"question\" + 0.148*\"answer\" + 0.055*\"often\" + 0.047*\"possible\" + 0.032*\"instead\"')\n",
      "(8, '0.234*\"would\" + 0.162*\"recommend\" + 0.092*\"awesome\" + 0.081*\"definitely\" + 0.079*\"taking\"')\n",
      "(7, '0.418*\"lecture\" + 0.083*\"note\" + 0.079*\"boring\" + 0.049*\"textbook\" + 0.045*\"online\"')\n",
      "(25, '0.112*\"test\" + 0.096*\"homework\" + 0.086*\"exam\" + 0.063*\"problem\" + 0.059*\"difficult\"')\n",
      "(24, '0.219*\"class\" + 0.069*\"professor\" + 0.065*\"teacher\" + 0.059*\"really\" + 0.048*\"great\"')\n",
      "\n",
      "Coherence Score (Cv):  0.3540702487136242\n",
      "\n",
      "Coherence Score (umass):  -10.048715422035027\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 35\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, '0.232*\"horrible\" + 0.044*\"receive\" + 0.041*\"except\" + 0.040*\"hardly\" + 0.038*\"handwriting\"')\n",
      "(24, '0.160*\"brother\" + 0.085*\"theory\" + 0.074*\"keep\" + 0.058*\"apply\" + 0.051*\"miss\"')\n",
      "(26, '0.113*\"organize\" + 0.094*\"department\" + 0.047*\"work\" + 0.047*\"consider\" + 0.043*\"unorganized\"')\n",
      "(18, '0.134*\"calculus\" + 0.089*\"available\" + 0.073*\"previous\" + 0.058*\"genuinely\" + 0.051*\"early\"')\n",
      "(37, '0.175*\"understanding\" + 0.114*\"experience\" + 0.076*\"might\" + 0.053*\"focus\" + 0.039*\"actual\"')\n",
      "(0, '0.097*\"someone\" + 0.078*\"suck\" + 0.065*\"somewhat\" + 0.063*\"excite\" + 0.055*\"wonderful\"')\n",
      "(28, '0.132*\"thing\" + 0.100*\"around\" + 0.093*\"speak\" + 0.092*\"english\" + 0.086*\"economics\"')\n",
      "(27, '0.110*\"without\" + 0.058*\"years\" + 0.057*\"chance\" + 0.056*\"hate\" + 0.052*\"method\"')\n",
      "(7, '0.134*\"attend\" + 0.117*\"discussion\" + 0.096*\"section\" + 0.066*\"pointless\" + 0.048*\"engage\"')\n",
      "(16, '0.111*\"usually\" + 0.104*\"right\" + 0.096*\"getting\" + 0.083*\"decent\" + 0.067*\"amount\"')\n",
      "(4, '0.311*\"pretty\" + 0.147*\"overall\" + 0.087*\"like\" + 0.071*\"fairly\" + 0.039*\"important\"')\n",
      "(10, '0.203*\"note\" + 0.121*\"textbook\" + 0.077*\"slide\" + 0.073*\"often\" + 0.046*\"information\"')\n",
      "(35, '0.247*\"always\" + 0.198*\"willing\" + 0.075*\"person\" + 0.066*\"something\" + 0.056*\"favorite\"')\n",
      "(38, '0.157*\"think\" + 0.123*\"people\" + 0.116*\"seem\" + 0.107*\"physics\" + 0.079*\"probably\"')\n",
      "(17, '0.298*\"difficult\" + 0.102*\"however\" + 0.078*\"cover\" + 0.062*\"enough\" + 0.045*\"since\"')\n",
      "(1, '0.277*\"grade\" + 0.128*\"curve\" + 0.098*\"want\" + 0.071*\"average\" + 0.067*\"challenge\"')\n",
      "(36, '0.317*\"would\" + 0.219*\"recommend\" + 0.107*\"taking\" + 0.084*\"highly\" + 0.053*\"anyone\"')\n",
      "(2, '0.309*\"explain\" + 0.192*\"things\" + 0.144*\"concept\" + 0.079*\"clearly\" + 0.053*\"quite\"')\n",
      "(6, '0.214*\"lecture\" + 0.116*\"homework\" + 0.104*\"exam\" + 0.076*\"problem\" + 0.045*\"example\"')\n",
      "(33, '0.198*\"class\" + 0.062*\"professor\" + 0.058*\"teacher\" + 0.054*\"really\" + 0.046*\"test\"')\n",
      "\n",
      "Coherence Score (Cv):  0.38040969846336814\n",
      "\n",
      "Coherence Score (umass):  -11.010429395616278\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 40\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, '0.152*\"pointless\" + 0.108*\"sister\" + 0.049*\"harsh\" + 0.045*\"engineer\" + 0.034*\"certain\"')\n",
      "(9, '0.117*\"might\" + 0.070*\"apply\" + 0.065*\"watch\" + 0.055*\"thoroughly\" + 0.049*\"video\"')\n",
      "(20, '0.116*\"awful\" + 0.072*\"laugh\" + 0.071*\"chapter\" + 0.063*\"otherwise\" + 0.044*\"personality\"')\n",
      "(4, '0.226*\"super\" + 0.120*\"unclear\" + 0.100*\"explanation\" + 0.063*\"genuinely\" + 0.051*\"along\"')\n",
      "(40, '0.277*\"physics\" + 0.139*\"school\" + 0.042*\"unhelpful\" + 0.024*\"count\" + 0.022*\"certainly\"')\n",
      "(44, '0.156*\"brother\" + 0.140*\"science\" + 0.072*\"hate\" + 0.037*\"regret\" + 0.032*\"catch\"')\n",
      "(18, '0.091*\"ask\" + 0.089*\"choice\" + 0.076*\"multiple\" + 0.065*\"allow\" + 0.064*\"quickly\"')\n",
      "(19, '0.179*\"hard\" + 0.174*\"like\" + 0.160*\"need\" + 0.036*\"constantly\" + 0.033*\"except\"')\n",
      "(41, '0.255*\"point\" + 0.111*\"right\" + 0.089*\"basically\" + 0.073*\"entire\" + 0.045*\"read\"')\n",
      "(43, '0.146*\"impossible\" + 0.144*\"slide\" + 0.129*\"almost\" + 0.054*\"sheet\" + 0.039*\"crazy\"')\n",
      "(7, '0.314*\"grade\" + 0.200*\"final\" + 0.193*\"midterm\" + 0.030*\"second\" + 0.020*\"papers\"')\n",
      "(17, '0.167*\"could\" + 0.158*\"awesome\" + 0.151*\"better\" + 0.090*\"horrible\" + 0.049*\"someone\"')\n",
      "(3, '0.287*\"pretty\" + 0.158*\"give\" + 0.154*\"little\" + 0.088*\"reading\" + 0.064*\"require\"')\n",
      "(13, '0.178*\"study\" + 0.178*\"note\" + 0.106*\"review\" + 0.096*\"online\" + 0.093*\"practice\"')\n",
      "(34, '0.469*\"student\" + 0.096*\"want\" + 0.095*\"care\" + 0.048*\"calculus\" + 0.033*\"department\"')\n",
      "(35, '0.291*\"would\" + 0.201*\"recommend\" + 0.101*\"definitely\" + 0.098*\"taking\" + 0.077*\"highly\"')\n",
      "(14, '0.583*\"really\" + 0.086*\"still\" + 0.062*\"smart\" + 0.048*\"discussion\" + 0.039*\"getting\"')\n",
      "(11, '0.256*\"explain\" + 0.159*\"things\" + 0.144*\"example\" + 0.120*\"concept\" + 0.065*\"clearly\"')\n",
      "(8, '0.179*\"lecture\" + 0.113*\"test\" + 0.097*\"homework\" + 0.096*\"material\" + 0.086*\"exam\"')\n",
      "(2, '0.277*\"class\" + 0.087*\"professor\" + 0.082*\"teacher\" + 0.061*\"great\" + 0.052*\"understand\"')\n",
      "\n",
      "Coherence Score (Cv):  0.4063226034333349\n",
      "\n",
      "Coherence Score (umass):  -11.796648430413393\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 45\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, '0.093*\"doable\" + 0.089*\"approach\" + 0.080*\"solution\" + 0.051*\"strict\" + 0.042*\"irrelevant\"')\n",
      "(14, '0.127*\"equation\" + 0.089*\"watch\" + 0.043*\"optional\" + 0.038*\"happen\" + 0.036*\"entirely\"')\n",
      "(19, '0.064*\"skip\" + 0.061*\"unorganized\" + 0.060*\"agree\" + 0.057*\"partial\" + 0.056*\"asleep\"')\n",
      "(31, '0.179*\"experience\" + 0.135*\"recitation\" + 0.054*\"prior\" + 0.037*\"kearl\" + 0.033*\"breeze\"')\n",
      "(43, '0.131*\"information\" + 0.121*\"instead\" + 0.060*\"tangent\" + 0.049*\"literally\" + 0.045*\"whatever\"')\n",
      "(3, '0.181*\"quite\" + 0.143*\"around\" + 0.141*\"section\" + 0.054*\"giving\" + 0.035*\"alright\"')\n",
      "(9, '0.104*\"waste\" + 0.103*\"writing\" + 0.103*\"stats\" + 0.049*\"opportunity\" + 0.048*\"ridiculously\"')\n",
      "(0, '0.161*\"straight\" + 0.145*\"science\" + 0.084*\"somewhat\" + 0.083*\"forward\" + 0.061*\"truly\"')\n",
      "(32, '0.186*\"useless\" + 0.178*\"almost\" + 0.066*\"random\" + 0.049*\"directly\" + 0.047*\"formula\"')\n",
      "(30, '0.129*\"without\" + 0.107*\"unclear\" + 0.063*\"fail\" + 0.059*\"state\" + 0.054*\"works\"')\n",
      "(12, '0.313*\"grade\" + 0.199*\"final\" + 0.193*\"midterm\" + 0.024*\"finish\" + 0.023*\"understandable\"')\n",
      "(25, '0.543*\"student\" + 0.111*\"want\" + 0.110*\"care\" + 0.036*\"succeed\" + 0.035*\"helping\"')\n",
      "(4, '0.351*\"explain\" + 0.218*\"things\" + 0.164*\"concept\" + 0.090*\"clearly\" + 0.017*\"system\"')\n",
      "(36, '0.414*\"helpful\" + 0.198*\"hours\" + 0.189*\"office\" + 0.049*\"outside\" + 0.020*\"kinda\"')\n",
      "(48, '0.320*\"would\" + 0.221*\"recommend\" + 0.108*\"tough\" + 0.084*\"highly\" + 0.038*\"organize\"')\n",
      "(35, '0.629*\"really\" + 0.088*\"help\" + 0.076*\"enjoy\" + 0.068*\"like\" + 0.021*\"given\"')\n",
      "(29, '0.393*\"exam\" + 0.162*\"study\" + 0.162*\"note\" + 0.038*\"english\" + 0.035*\"basically\"')\n",
      "(47, '0.486*\"lecture\" + 0.087*\"going\" + 0.057*\"textbook\" + 0.055*\"however\" + 0.043*\"reading\"')\n",
      "(28, '0.249*\"homework\" + 0.200*\"question\" + 0.162*\"problem\" + 0.087*\"answer\" + 0.072*\"give\"')\n",
      "(33, '0.247*\"class\" + 0.078*\"professor\" + 0.073*\"teacher\" + 0.057*\"test\" + 0.054*\"great\"')\n",
      "\n",
      "Coherence Score (Cv):  0.42866274297297585\n",
      "\n",
      "Coherence Score (umass):  -12.652167271308624\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 50\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (Cv): ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
