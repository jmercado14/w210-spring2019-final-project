{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(\"training_data/RMP_data/full_RMP_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid</th>\n",
       "      <th>dept</th>\n",
       "      <th>date</th>\n",
       "      <th>forcredit</th>\n",
       "      <th>attendance</th>\n",
       "      <th>textbookuse</th>\n",
       "      <th>interest</th>\n",
       "      <th>grade</th>\n",
       "      <th>tags</th>\n",
       "      <th>comments</th>\n",
       "      <th>helpcount</th>\n",
       "      <th>nothelpcount</th>\n",
       "      <th>online</th>\n",
       "      <th>profgender</th>\n",
       "      <th>profhotness</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>clarity</th>\n",
       "      <th>easiness</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24228248</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>1/5/15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It's a must have</td>\n",
       "      <td>Really into it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Would take again\", \"Hilarious\", \"Tests are t...</td>\n",
       "      <td>Great Professor My wife took this class twice ...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24218909</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>1/2/15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mandatory</td>\n",
       "      <td>It's a must have</td>\n",
       "      <td>Sorta interested</td>\n",
       "      <td>A</td>\n",
       "      <td>[\"Skip class? You won't pass.\", \"Tests are tou...</td>\n",
       "      <td>Great Professor Study the notes from class and...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24215795</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>1/2/15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Essential to passing</td>\n",
       "      <td>Really into it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Hilarious\", \"Would take again\", \"Skip class?...</td>\n",
       "      <td>Brother Brau is a great guy He gives great spi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24204179</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>12/30/14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not Mandatory</td>\n",
       "      <td>Essential to passing</td>\n",
       "      <td>Sorta interested</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Tests are tough\", \"Get ready to read\"]</td>\n",
       "      <td>People rave about Brau but I personally dont g...</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24198463</td>\n",
       "      <td>916674</td>\n",
       "      <td>Business</td>\n",
       "      <td>12/28/14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not Mandatory</td>\n",
       "      <td>You need it sometimes</td>\n",
       "      <td>Sorta interested</td>\n",
       "      <td>A</td>\n",
       "      <td>[\"Inspirational\", \"Hilarious\", \"Skip class? Yo...</td>\n",
       "      <td>This class doesnt have much homework which was...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     tid      dept      date forcredit     attendance  \\\n",
       "0  24228248  916674  Business    1/5/15       Yes            NaN   \n",
       "1  24218909  916674  Business    1/2/15       Yes      Mandatory   \n",
       "2  24215795  916674  Business    1/2/15       Yes            NaN   \n",
       "3  24204179  916674  Business  12/30/14       Yes  Not Mandatory   \n",
       "4  24198463  916674  Business  12/28/14       Yes  Not Mandatory   \n",
       "\n",
       "             textbookuse          interest grade  \\\n",
       "0       It's a must have    Really into it   NaN   \n",
       "1       It's a must have  Sorta interested     A   \n",
       "2   Essential to passing    Really into it   NaN   \n",
       "3   Essential to passing  Sorta interested   NaN   \n",
       "4  You need it sometimes  Sorta interested     A   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [\"Would take again\", \"Hilarious\", \"Tests are t...   \n",
       "1  [\"Skip class? You won't pass.\", \"Tests are tou...   \n",
       "2  [\"Hilarious\", \"Would take again\", \"Skip class?...   \n",
       "3           [\"Tests are tough\", \"Get ready to read\"]   \n",
       "4  [\"Inspirational\", \"Hilarious\", \"Skip class? Yo...   \n",
       "\n",
       "                                            comments  helpcount  nothelpcount  \\\n",
       "0  Great Professor My wife took this class twice ...          0            10   \n",
       "1  Great Professor Study the notes from class and...          0             1   \n",
       "2  Brother Brau is a great guy He gives great spi...          1             2   \n",
       "3  People rave about Brau but I personally dont g...         18             6   \n",
       "4  This class doesnt have much homework which was...          1             0   \n",
       "\n",
       "  online  profgender  profhotness  helpfulness  clarity  easiness  quality  \n",
       "0    NaN           0            0          4.0      5.0       3.0      9.0  \n",
       "1    NaN           0            0          4.0      4.0       2.0      8.0  \n",
       "2    NaN           0            0          4.0      4.0       3.0      8.0  \n",
       "3    NaN           0            0          3.0      1.0       2.0      4.0  \n",
       "4    NaN           0            0          4.0      4.0       4.0      8.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187167 entries, 0 to 187166\n",
      "Data columns (total 20 columns):\n",
      "id              187167 non-null int64\n",
      "tid             187167 non-null int64\n",
      "dept            187167 non-null object\n",
      "date            187167 non-null object\n",
      "forcredit       11000 non-null object\n",
      "attendance      14788 non-null object\n",
      "textbookuse     141373 non-null object\n",
      "interest        175112 non-null object\n",
      "grade           9835 non-null object\n",
      "tags            187167 non-null object\n",
      "comments        186776 non-null object\n",
      "helpcount       187167 non-null int64\n",
      "nothelpcount    187167 non-null int64\n",
      "online          991 non-null object\n",
      "profgender      187167 non-null int64\n",
      "profhotness     187167 non-null int64\n",
      "helpfulness     117811 non-null float64\n",
      "clarity         117811 non-null float64\n",
      "easiness        117811 non-null float64\n",
      "quality         117811 non-null float64\n",
      "dtypes: float64(4), int64(6), object(10)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()\n",
    "# 187167 rows, 20 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    187167.000000\n",
       "mean          0.055699\n",
       "std           0.372341\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max          29.000000\n",
       "Name: helpcount, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['helpcount'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        991\n",
       "unique         1\n",
       "top       online\n",
       "freq         991\n",
       "Name: online, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['online'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          187167\n",
       "unique            334\n",
       "top       Mathematics\n",
       "freq            14298\n",
       "Name: dept, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['dept'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dept\n",
       "Marketing                   596\n",
       "Law                         625\n",
       "Mechanical Engineering      625\n",
       "Art History                 686\n",
       "Social Work                 718\n",
       "Women's Studies             724\n",
       "Dance                       741\n",
       "Finance                     887\n",
       "Agriculture                 943\n",
       "Classics                    945\n",
       "Art                         994\n",
       "Social Science             1060\n",
       "Literature                 1163\n",
       "Statistics                 1197\n",
       "Theater                    1244\n",
       "Health Science             1384\n",
       "Fine Arts                  1409\n",
       "Spanish                    1437\n",
       "Journalism                 1537\n",
       "Education                  1581\n",
       "Geology                    1694\n",
       "Geography                  2205\n",
       "Humanities                 2397\n",
       "Philosophy                 2514\n",
       "Accounting                 2570\n",
       "Anthropology               2649\n",
       "Music                      2759\n",
       "Computer Science           3181\n",
       "Science                    3953\n",
       "Communication              4126\n",
       "Physics                    4317\n",
       "Engineering                4528\n",
       "Sociology                  4989\n",
       "Business                   5855\n",
       "Languages                  6433\n",
       "Political Science          6503\n",
       "Economics                  6672\n",
       "Psychology                 7682\n",
       "History                    7844\n",
       "Biology                   10272\n",
       "Religion                  11218\n",
       "Chemistry                 11300\n",
       "English                   11798\n",
       "Mathematics               14298\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.groupby(['dept']).size().sort_values()[290:334]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade\n",
       "A                 3980\n",
       "A+                 837\n",
       "A-                1490\n",
       "Audit/No Grade      11\n",
       "B                  939\n",
       "B+                 901\n",
       "B-                 296\n",
       "C                  231\n",
       "C+                 149\n",
       "C-                  75\n",
       "D                   37\n",
       "D+                  19\n",
       "D-                  11\n",
       "F                   36\n",
       "INC                 49\n",
       "Not sure yet       625\n",
       "P                   47\n",
       "Rather not say      34\n",
       "WD                  68\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.groupby(['grade']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.871670e+05\n",
       "mean     7.005554e+05\n",
       "std      5.123135e+05\n",
       "min      1.740000e+02\n",
       "25%      2.735930e+05\n",
       "50%      5.923380e+05\n",
       "75%      1.016084e+06\n",
       "max      1.984570e+06\n",
       "Name: tid, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['tid'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tid\n",
       "174        261\n",
       "176        309\n",
       "178        227\n",
       "186        151\n",
       "188        254\n",
       "829         39\n",
       "1245       219\n",
       "3069       108\n",
       "4310       258\n",
       "4735       232\n",
       "4949        32\n",
       "7659        40\n",
       "7694        14\n",
       "8359         4\n",
       "8656        44\n",
       "8906         6\n",
       "8956        17\n",
       "9479        38\n",
       "9583         9\n",
       "9588        40\n",
       "9589        85\n",
       "9806         7\n",
       "10221       16\n",
       "10222      187\n",
       "11058      404\n",
       "12776       76\n",
       "12777       56\n",
       "12779        4\n",
       "12780       14\n",
       "12933        8\n",
       "          ... \n",
       "1977044      1\n",
       "1977591      1\n",
       "1978133      1\n",
       "1978136      1\n",
       "1978139      1\n",
       "1978737      1\n",
       "1978957      1\n",
       "1979618      1\n",
       "1979662      1\n",
       "1980239      1\n",
       "1980434      1\n",
       "1980546      2\n",
       "1981108      1\n",
       "1981430      1\n",
       "1981438      1\n",
       "1981510      1\n",
       "1981565      1\n",
       "1981610      1\n",
       "1981613      1\n",
       "1981620      1\n",
       "1981788      1\n",
       "1982007      2\n",
       "1982497      1\n",
       "1982714      1\n",
       "1982934      1\n",
       "1983153      2\n",
       "1983179      1\n",
       "1983648      1\n",
       "1984218      1\n",
       "1984570      1\n",
       "Length: 15583, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.groupby(['tid']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          186776\n",
       "unique         179670\n",
       "top       No Comments\n",
       "freq             5159\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['comments'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df[training_df['comments'] != 'No Comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid</th>\n",
       "      <th>helpcount</th>\n",
       "      <th>nothelpcount</th>\n",
       "      <th>profgender</th>\n",
       "      <th>profhotness</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>clarity</th>\n",
       "      <th>easiness</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.820080e+05</td>\n",
       "      <td>1.820080e+05</td>\n",
       "      <td>182008.000000</td>\n",
       "      <td>182008.000000</td>\n",
       "      <td>182008.000000</td>\n",
       "      <td>182008.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.538445e+07</td>\n",
       "      <td>7.070923e+05</td>\n",
       "      <td>0.057184</td>\n",
       "      <td>0.033229</td>\n",
       "      <td>0.303465</td>\n",
       "      <td>0.232913</td>\n",
       "      <td>3.739448</td>\n",
       "      <td>3.700046</td>\n",
       "      <td>3.041557</td>\n",
       "      <td>7.439494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.230749e+06</td>\n",
       "      <td>5.145705e+05</td>\n",
       "      <td>0.377323</td>\n",
       "      <td>0.283856</td>\n",
       "      <td>0.459755</td>\n",
       "      <td>0.422688</td>\n",
       "      <td>1.422131</td>\n",
       "      <td>1.368991</td>\n",
       "      <td>1.256229</td>\n",
       "      <td>2.657747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.230000e+02</td>\n",
       "      <td>1.740000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.247934e+07</td>\n",
       "      <td>2.795800e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.605265e+07</td>\n",
       "      <td>5.961480e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.013159e+07</td>\n",
       "      <td>1.029664e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.438667e+07</td>\n",
       "      <td>1.984570e+06</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           tid      helpcount   nothelpcount  \\\n",
       "count  1.820080e+05  1.820080e+05  182008.000000  182008.000000   \n",
       "mean   1.538445e+07  7.070923e+05       0.057184       0.033229   \n",
       "std    6.230749e+06  5.145705e+05       0.377323       0.283856   \n",
       "min    2.230000e+02  1.740000e+02       0.000000       0.000000   \n",
       "25%    1.247934e+07  2.795800e+05       0.000000       0.000000   \n",
       "50%    1.605265e+07  5.961480e+05       0.000000       0.000000   \n",
       "75%    2.013159e+07  1.029664e+06       0.000000       0.000000   \n",
       "max    2.438667e+07  1.984570e+06      29.000000      25.000000   \n",
       "\n",
       "          profgender    profhotness    helpfulness        clarity  \\\n",
       "count  182008.000000  182008.000000  115071.000000  115071.000000   \n",
       "mean        0.303465       0.232913       3.739448       3.700046   \n",
       "std         0.459755       0.422688       1.422131       1.368991   \n",
       "min         0.000000       0.000000       1.000000       1.000000   \n",
       "25%         0.000000       0.000000       3.000000       3.000000   \n",
       "50%         0.000000       0.000000       4.000000       4.000000   \n",
       "75%         1.000000       0.000000       5.000000       5.000000   \n",
       "max         1.000000       1.000000       5.000000       5.000000   \n",
       "\n",
       "            easiness        quality  \n",
       "count  115071.000000  115071.000000  \n",
       "mean        3.041557       7.439494  \n",
       "std         1.256229       2.657747  \n",
       "min         1.000000       2.000000  \n",
       "25%         2.000000       6.000000  \n",
       "50%         3.000000       8.000000  \n",
       "75%         4.000000      10.000000  \n",
       "max         5.000000      10.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count            181617\n",
       "unique           179669\n",
       "top       Great teacher\n",
       "freq                 72\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['comments'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_sciences = [\n",
    "'Computer Science',\n",
    "'Economics',\n",
    "'Engineering',\n",
    "'Engineering Technology',\n",
    "'Mathematics',\n",
    "'Mechanical Engineering',\n",
    "'Physics',\n",
    "'Science',\n",
    "'Statistics']\n",
    "# related sciences with >1000 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid</th>\n",
       "      <th>helpcount</th>\n",
       "      <th>nothelpcount</th>\n",
       "      <th>profgender</th>\n",
       "      <th>profhotness</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>clarity</th>\n",
       "      <th>easiness</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.761000e+04</td>\n",
       "      <td>3.761000e+04</td>\n",
       "      <td>37610.000000</td>\n",
       "      <td>37610.000000</td>\n",
       "      <td>37610.000000</td>\n",
       "      <td>37610.000000</td>\n",
       "      <td>24882.000000</td>\n",
       "      <td>24882.000000</td>\n",
       "      <td>24882.000000</td>\n",
       "      <td>24882.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.493916e+07</td>\n",
       "      <td>6.601918e+05</td>\n",
       "      <td>0.072108</td>\n",
       "      <td>0.039218</td>\n",
       "      <td>0.222388</td>\n",
       "      <td>0.136932</td>\n",
       "      <td>3.442770</td>\n",
       "      <td>3.380838</td>\n",
       "      <td>2.889719</td>\n",
       "      <td>6.823607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.605385e+06</td>\n",
       "      <td>5.286968e+05</td>\n",
       "      <td>0.470017</td>\n",
       "      <td>0.315228</td>\n",
       "      <td>0.415856</td>\n",
       "      <td>0.343780</td>\n",
       "      <td>1.520924</td>\n",
       "      <td>1.469615</td>\n",
       "      <td>1.270867</td>\n",
       "      <td>2.860156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.593000e+03</td>\n",
       "      <td>1.860000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.198317e+07</td>\n",
       "      <td>2.380820e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.569156e+07</td>\n",
       "      <td>5.234150e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.002543e+07</td>\n",
       "      <td>9.704920e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.438667e+07</td>\n",
       "      <td>1.982934e+06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           tid     helpcount  nothelpcount    profgender  \\\n",
       "count  3.761000e+04  3.761000e+04  37610.000000  37610.000000  37610.000000   \n",
       "mean   1.493916e+07  6.601918e+05      0.072108      0.039218      0.222388   \n",
       "std    6.605385e+06  5.286968e+05      0.470017      0.315228      0.415856   \n",
       "min    1.593000e+03  1.860000e+02      0.000000      0.000000      0.000000   \n",
       "25%    1.198317e+07  2.380820e+05      0.000000      0.000000      0.000000   \n",
       "50%    1.569156e+07  5.234150e+05      0.000000      0.000000      0.000000   \n",
       "75%    2.002543e+07  9.704920e+05      0.000000      0.000000      0.000000   \n",
       "max    2.438667e+07  1.982934e+06     20.000000     19.000000      1.000000   \n",
       "\n",
       "        profhotness   helpfulness       clarity      easiness       quality  \n",
       "count  37610.000000  24882.000000  24882.000000  24882.000000  24882.000000  \n",
       "mean       0.136932      3.442770      3.380838      2.889719      6.823607  \n",
       "std        0.343780      1.520924      1.469615      1.270867      2.860156  \n",
       "min        0.000000      1.000000      1.000000      1.000000      2.000000  \n",
       "25%        0.000000      2.000000      2.000000      2.000000      4.000000  \n",
       "50%        0.000000      4.000000      4.000000      3.000000      8.000000  \n",
       "75%        0.000000      5.000000      5.000000      4.000000      9.000000  \n",
       "max        1.000000      5.000000      5.000000      5.000000     10.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sciences_df = training_df[training_df['dept'].isin(related_sciences)]\n",
    "sciences_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37610 entries, 1408 to 187165\n",
      "Data columns (total 20 columns):\n",
      "id              37610 non-null int64\n",
      "tid             37610 non-null int64\n",
      "dept            37610 non-null object\n",
      "date            37610 non-null object\n",
      "forcredit       2241 non-null object\n",
      "attendance      3155 non-null object\n",
      "textbookuse     27893 non-null object\n",
      "interest        34694 non-null object\n",
      "grade           1974 non-null object\n",
      "tags            37610 non-null object\n",
      "comments        37514 non-null object\n",
      "helpcount       37610 non-null int64\n",
      "nothelpcount    37610 non-null int64\n",
      "online          127 non-null object\n",
      "profgender      37610 non-null int64\n",
      "profhotness     37610 non-null int64\n",
      "helpfulness     24882 non-null float64\n",
      "clarity         24882 non-null float64\n",
      "easiness        24882 non-null float64\n",
      "quality         24882 non-null float64\n",
      "dtypes: float64(4), int64(6), object(10)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "sciences_df.info()\n",
    "#35k rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_documents(document_array):\n",
    "    \n",
    "    tokenized = []\n",
    "    \n",
    "    for doc in document_array:\n",
    "        tokens = prepare_text_for_lda(str(doc))\n",
    "        tokenized.append(tokens)\n",
    "\n",
    "    # Add bigrams to docs (only ones that appear 20 times or more).\n",
    "    bigram = Phrases(tokenized, min_count=20)\n",
    "    for idx in range(len(tokenized)):\n",
    "        for token in bigram[tokenized[idx]]:\n",
    "            if '_' in token:\n",
    "                # Token is a bigram, add to document.\n",
    "                tokenized[idx].append(token)\n",
    "        \n",
    "    return tokenized\n",
    "\n",
    "def generate_dictionary_corpus(data_id, tokenized_text):\n",
    "    # going to take 5-10 minutes\n",
    "    \n",
    "    dictionary = corpora.Dictionary(tokenized_text)\n",
    "    # Filter out words that occur less than 150 documents, or more than 75% of the documents.\n",
    "    dictionary.filter_extremes(no_below=150, no_above=0.75)\n",
    "    \n",
    "    dictionary_filename = \"topic_dictionaries/%s_dictionary_feedback.gensim\" % (data_id)\n",
    "    corpus = [dictionary.doc2bow(text) for text in tokenized_text]\n",
    "    corpus_filename = \"topic_corpi/%s_corpus_feedback.pkl\" % (data_id)\n",
    "    \n",
    "    pickle.dump(corpus, open(corpus_filename, 'wb'))\n",
    "    dictionary.save(dictionary_filename)\n",
    "    return dictionary, corpus\n",
    "\n",
    "def load_dictionary_corpus(data_id):\n",
    "    dictionary_filename = \"topic_dictionaries/%s_dictionary_feedback.gensim\" % (data_id)\n",
    "    dictionary = corpora.Dictionary.load(dictionary_filename)\n",
    "    corpus_filename = \"topic_corpi/%s_corpus_feedback.pkl\" % (data_id)\n",
    "    with open(corpus_filename, 'rb') as f:\n",
    "        corpus = pickle.load(f)\n",
    "    if (len(dictionary) == 0):\n",
    "        return\n",
    "    return dictionary, corpus\n",
    "\n",
    "\n",
    "def generate_lda(data_id, corpus, dictionary, num_topics, num_passes, num_words):\n",
    "    # runtime will depend on number of passes\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, \n",
    "                                                alpha='auto', eta='auto', eval_every=0, passes=num_passes)\n",
    "    ldamodel_filename = 'topic_models/%s_model%st_%sp.gensim' % (data_id, str(num_topics), str(num_passes))\n",
    "    ldamodel.save(ldamodel_filename)\n",
    "    \n",
    "    sub_topics = ldamodel.print_topics(num_words=num_words)\n",
    "    for sub_topic in sub_topics:\n",
    "        print(sub_topic)\n",
    "        \n",
    "    return ldamodel\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Great Professor Study the notes from class and...\n",
       "2    Brother Brau is a great guy He gives great spi...\n",
       "3    People rave about Brau but I personally dont g...\n",
       "4    This class doesnt have much homework which was...\n",
       "5    Bro Brau definitely knows what he is doing  I ...\n",
       "6    Lectures are long but he does a good job of br...\n",
       "7    Can be a good buddy but not a good professor T...\n",
       "8    I love Brother Brau for his spiritual thoughts...\n",
       "9    Professor Brau really cares  If he talks about...\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.comments[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ff8887779d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeedback_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-865494a40752>\u001b[0m in \u001b[0;36mprepare_documents\u001b[0;34m(document_array)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_text_for_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e74a5cfdf2d9>\u001b[0m in \u001b[0;36mprepare_text_for_lda\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_text_for_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0men_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e74a5cfdf2d9>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlda_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morth_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    338\u001b[0m             raise ValueError(Errors.E088.format(length=len(text),\n\u001b[1;32m    339\u001b[0m                                                 max_length=self.max_length))\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer._attach_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.get\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/spacy/lang/lex_attrs.py\u001b[0m in \u001b[0;36mlower\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feedback_text = prepare_documents(training_df.comments)\n",
    "\n",
    "dictionary, corpus = generate_dictionary_corpus(\"RMP\", feedback_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dictionary, corpus = generate_dictionary_corpus(\"RMP\", feedback_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.175*\"extremely\" + 0.103*\"however\" + 0.085*\"review\" + 0.064*\"thing\" + 0.037*\"although\"')\n",
      "(1, '0.139*\"teach\" + 0.130*\"teaching\" + 0.107*\"boring\" + 0.067*\"could\" + 0.042*\"worst\"')\n",
      "(2, '0.162*\"point\" + 0.131*\"enjoy\" + 0.111*\"attendance\" + 0.079*\"like\" + 0.060*\"mandatory\"')\n",
      "(3, '0.392*\"student\" + 0.110*\"want\" + 0.080*\"office\" + 0.064*\"care\" + 0.045*\"need\"')\n",
      "(4, '0.267*\"recommend\" + 0.108*\"grading\" + 0.104*\"highly\" + 0.099*\"grader\" + 0.095*\"discussion\"')\n",
      "(5, '0.072*\"lecture\" + 0.060*\"helpful\" + 0.055*\"grade\" + 0.050*\"material\" + 0.042*\"exam\"')\n",
      "(6, '0.126*\"hours\" + 0.120*\"subject\" + 0.109*\"project\" + 0.108*\"seem\" + 0.056*\"fairly\"')\n",
      "(7, '0.250*\"class\" + 0.065*\"really\" + 0.059*\"teacher\" + 0.056*\"professor\" + 0.054*\"great\"')\n",
      "(8, '0.153*\"final\" + 0.145*\"midterm\" + 0.140*\"homework\" + 0.106*\"papers\" + 0.088*\"write\"')\n",
      "(9, '0.153*\"topic\" + 0.050*\"unclear\" + 0.049*\"world\" + 0.043*\"leave\" + 0.041*\"either\"')\n",
      "(10, '0.112*\"problem\" + 0.061*\"email\" + 0.038*\"incredibly\" + 0.036*\"choice\" + 0.033*\"practice\"')\n",
      "(11, '0.210*\"know\" + 0.124*\"stuff\" + 0.090*\"essay\" + 0.062*\"knowledge\" + 0.054*\"short\"')\n",
      "(12, '0.099*\"better\" + 0.068*\"extra\" + 0.063*\"credit\" + 0.053*\"speak\" + 0.038*\"assign\"')\n",
      "(13, '0.124*\"understand\" + 0.104*\"always\" + 0.085*\"clear\" + 0.077*\"willing\" + 0.070*\"explain\"')\n",
      "(14, '0.125*\"overall\" + 0.114*\"instructor\" + 0.058*\"knowledgeable\" + 0.054*\"experience\" + 0.047*\"learning\"')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feedback_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b2f9b7c154f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dictionary_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_TOPICS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_PASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_ITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcoherence_model_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeedback_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcoherence_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoherence_model_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nCoherence Score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_lda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feedback_text' is not defined"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 15\n",
    "NUM_ITERATIONS = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS, NUM_ITERATIONS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.31847731469200774\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.146*\"professor\" + 0.078*\"exam\" + 0.060*\"teaching\" + 0.052*\"course\" + 0.051*\"difficult\"')\n",
      "(1, '0.179*\"make\" + 0.100*\"know\" + 0.093*\"instructor\" + 0.083*\"grading\" + 0.059*\"stuff\"')\n",
      "(2, '0.191*\"student\" + 0.085*\"always\" + 0.054*\"want\" + 0.050*\"think\" + 0.047*\"love\"')\n",
      "(3, '0.116*\"learn\" + 0.081*\"pretty\" + 0.067*\"final\" + 0.064*\"midterm\" + 0.052*\"though\"')\n",
      "(4, '0.110*\"first\" + 0.105*\"seem\" + 0.082*\"worst\" + 0.080*\"extra\" + 0.075*\"credit\"')\n",
      "(5, '0.366*\"class\" + 0.095*\"really\" + 0.087*\"teacher\" + 0.079*\"great\" + 0.063*\"helpful\"')\n",
      "(6, '0.165*\"explain\" + 0.094*\"anything\" + 0.072*\"thing\" + 0.059*\"concept\" + 0.057*\"clearly\"')\n",
      "(7, '0.200*\"would\" + 0.168*\"recommend\" + 0.087*\"definitely\" + 0.081*\"taking\" + 0.039*\"avoid\"')\n",
      "(8, '0.182*\"highly\" + 0.110*\"favorite\" + 0.087*\"history\" + 0.049*\"leave\" + 0.040*\"simple\"')\n",
      "(9, '0.267*\"assignment\" + 0.133*\"listen\" + 0.087*\"lecturer\" + 0.071*\"hard\" + 0.070*\"different\"')\n",
      "(10, '0.125*\"things\" + 0.093*\"grader\" + 0.090*\"discussion\" + 0.053*\"email\" + 0.047*\"challenge\"')\n",
      "(11, '0.258*\"boring\" + 0.131*\"topic\" + 0.096*\"help\" + 0.082*\"excellent\" + 0.062*\"outside\"')\n",
      "(12, '0.165*\"willing\" + 0.064*\"talking\" + 0.062*\"speak\" + 0.058*\"need\" + 0.048*\"nothing\"')\n",
      "(13, '0.108*\"lecture\" + 0.083*\"grade\" + 0.058*\"reading\" + 0.056*\"question\" + 0.051*\"test\"')\n",
      "(14, '0.232*\"interest\" + 0.166*\"material\" + 0.077*\"extremely\" + 0.056*\"could\" + 0.049*\"subject\"')\n",
      "\n",
      "Coherence Score:  0.3177322860969289\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 15\n",
    "NUM_ITERATIONS = 50\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS, NUM_ITERATIONS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusion -  number of iterations doesn't significantly affect Cv score. Going to remove ongoing, default to 50\n",
    "# also removed eval_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.096*\"slide\" + 0.084*\"mistake\" + 0.063*\"example\" + 0.048*\"history\" + 0.044*\"nothing\"')\n",
      "(1, '0.331*\"student\" + 0.105*\"want\" + 0.086*\"grading\" + 0.061*\"care\" + 0.036*\"sister\"')\n",
      "(2, '0.367*\"interest\" + 0.081*\"topic\" + 0.077*\"subject\" + 0.039*\"involve\" + 0.036*\"passionate\"')\n",
      "(3, '0.154*\"writing\" + 0.132*\"discussion\" + 0.063*\"order\" + 0.055*\"assign\" + 0.053*\"meaning\"')\n",
      "(4, '0.203*\"know\" + 0.123*\"stuff\" + 0.092*\"participation\" + 0.089*\"talking\" + 0.028*\"complete\"')\n",
      "(5, '0.076*\"worst\" + 0.044*\"leave\" + 0.041*\"academic\" + 0.038*\"combine\" + 0.037*\"without\"')\n",
      "(6, '0.099*\"experience\" + 0.068*\"refuse\" + 0.068*\"story\" + 0.066*\"prove\" + 0.063*\"knowledge\"')\n",
      "(7, '0.152*\"instructor\" + 0.034*\"state\" + 0.033*\"excite\" + 0.027*\"become\" + 0.025*\"agree\"')\n",
      "(8, '0.196*\"understand\" + 0.107*\"explain\" + 0.101*\"things\" + 0.078*\"problem\" + 0.065*\"sometimes\"')\n",
      "(9, '0.371*\"teaching\" + 0.057*\"style\" + 0.034*\"improve\" + 0.033*\"skill\" + 0.030*\"idea\"')\n",
      "(10, '0.077*\"lecture\" + 0.054*\"grade\" + 0.046*\"material\" + 0.042*\"reading\" + 0.039*\"exam\"')\n",
      "(11, '0.122*\"hours\" + 0.104*\"office\" + 0.067*\"avoid\" + 0.043*\"anymore\" + 0.041*\"comment\"')\n",
      "(12, '0.238*\"answer\" + 0.139*\"sense\" + 0.064*\"humor\" + 0.050*\"choice\" + 0.043*\"multiple\"')\n",
      "(13, '0.064*\"boring\" + 0.052*\"assignment\" + 0.044*\"project\" + 0.043*\"write\" + 0.042*\"papers\"')\n",
      "(14, '0.182*\"class\" + 0.052*\"really\" + 0.045*\"teacher\" + 0.044*\"professor\" + 0.041*\"great\"')\n",
      "\n",
      "Coherence Score:  0.3387806250925685\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 25\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.089*\"credit\" + 0.087*\"extra\" + 0.067*\"history\"')\n",
      "(1, '0.173*\"know\" + 0.144*\"papers\" + 0.106*\"stuff\"')\n",
      "(2, '0.119*\"project\" + 0.076*\"mistake\" + 0.048*\"outside\"')\n",
      "(3, '0.223*\"understand\" + 0.097*\"hours\" + 0.083*\"office\"')\n",
      "(4, '0.046*\"grade\" + 0.041*\"material\" + 0.037*\"would\"')\n",
      "(5, '0.329*\"student\" + 0.098*\"want\" + 0.063*\"care\"')\n",
      "(6, '0.191*\"explain\" + 0.082*\"talking\" + 0.080*\"excellent\"')\n",
      "(7, '0.065*\"email\" + 0.045*\"friendly\" + 0.034*\"encourage\"')\n",
      "(8, '0.084*\"writing\" + 0.061*\"paper\" + 0.054*\"attendance\"')\n",
      "(9, '0.062*\"knowledge\" + 0.049*\"combine\" + 0.043*\"sweet\"')\n",
      "(10, '0.223*\"class\" + 0.062*\"really\" + 0.055*\"teacher\"')\n",
      "(11, '0.142*\"lecture\" + 0.073*\"test\" + 0.070*\"exam\"')\n",
      "(12, '0.098*\"amaze\" + 0.080*\"favorite\" + 0.073*\"speak\"')\n",
      "(13, '0.265*\"recommend\" + 0.132*\"taking\" + 0.098*\"highly\"')\n",
      "(14, '0.183*\"answer\" + 0.134*\"instructor\" + 0.077*\"avoid\"')\n",
      "\n",
      "Coherence Score:  0.3228353796505149\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 100\n",
    "NUM_WORDS = 3\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.198*\"would\" + 0.164*\"recommend\" + 0.085*\"awesome\" + 0.083*\"taking\" + 0.060*\"highly\"')\n",
      "(1, '0.071*\"speak\" + 0.054*\"powerpoint\" + 0.046*\"level\" + 0.039*\"school\" + 0.036*\"right\"')\n",
      "(2, '0.093*\"understanding\" + 0.086*\"post\" + 0.073*\"email\" + 0.050*\"friendly\" + 0.042*\"helping\"')\n",
      "(3, '0.092*\"learn\" + 0.069*\"teach\" + 0.051*\"course\" + 0.034*\"never\" + 0.031*\"think\"')\n",
      "(4, '0.364*\"student\" + 0.113*\"want\" + 0.088*\"instructor\" + 0.068*\"care\" + 0.030*\"style\"')\n",
      "(5, '0.138*\"subject\" + 0.055*\"matter\" + 0.055*\"major\" + 0.047*\"knowledge\" + 0.046*\"refuse\"')\n",
      "(6, '0.113*\"papers\" + 0.101*\"writing\" + 0.097*\"listen\" + 0.090*\"discussion\" + 0.064*\"attendance\"')\n",
      "(7, '0.179*\"question\" + 0.112*\"midterm\" + 0.111*\"final\" + 0.092*\"answer\" + 0.068*\"hours\"')\n",
      "(8, '0.101*\"sense\" + 0.095*\"mistake\" + 0.071*\"avoid\" + 0.057*\"frustrate\" + 0.051*\"constantly\"')\n",
      "(9, '0.137*\"grader\" + 0.104*\"credit\" + 0.103*\"extra\" + 0.045*\"feedback\" + 0.039*\"offer\"')\n",
      "(10, '0.190*\"class\" + 0.054*\"really\" + 0.047*\"teacher\" + 0.046*\"professor\" + 0.042*\"great\"')\n",
      "(11, '0.093*\"lecture\" + 0.064*\"grade\" + 0.049*\"reading\" + 0.047*\"exam\" + 0.046*\"test\"')\n",
      "(12, '0.144*\"love\" + 0.041*\"approachable\" + 0.034*\"brother\" + 0.034*\"looking\" + 0.033*\"forward\"')\n",
      "(13, '0.161*\"project\" + 0.080*\"excellent\" + 0.062*\"group\" + 0.054*\"leave\" + 0.048*\"prove\"')\n",
      "(14, '0.079*\"knowledgeable\" + 0.058*\"story\" + 0.049*\"combine\" + 0.043*\"bring\" + 0.036*\"state\"')\n",
      "\n",
      "Coherence Score:  0.3339541476482888\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 50\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.165*\"writing\" + 0.108*\"speak\" + 0.069*\"often\" + 0.056*\"meaning\" + 0.053*\"found\"')\n",
      "(1, '0.071*\"like\" + 0.056*\"smart\" + 0.056*\"another\" + 0.052*\"constantly\" + 0.052*\"level\"')\n",
      "(2, '0.193*\"recommend\" + 0.098*\"taking\" + 0.086*\"project\" + 0.076*\"hours\" + 0.070*\"highly\"')\n",
      "(3, '0.169*\"awesome\" + 0.105*\"grader\" + 0.081*\"favorite\" + 0.063*\"english\" + 0.058*\"spanish\"')\n",
      "(4, '0.196*\"know\" + 0.119*\"stuff\" + 0.086*\"talking\" + 0.070*\"email\" + 0.053*\"prove\"')\n",
      "(5, '0.136*\"instructor\" + 0.130*\"subject\" + 0.064*\"essay\" + 0.052*\"matter\" + 0.050*\"leave\"')\n",
      "(6, '0.167*\"answer\" + 0.039*\"right\" + 0.038*\"biweekly\" + 0.036*\"choice\" + 0.032*\"short\"')\n",
      "(7, '0.174*\"class\" + 0.043*\"lecture\" + 0.042*\"professor\" + 0.030*\"grade\" + 0.028*\"helpful\"')\n",
      "(8, '0.091*\"credit\" + 0.091*\"extra\" + 0.050*\"anymore\" + 0.036*\"sweet\" + 0.032*\"allow\"')\n",
      "(9, '0.271*\"student\" + 0.118*\"always\" + 0.087*\"willing\" + 0.085*\"want\" + 0.051*\"sense\"')\n",
      "(10, '0.180*\"teacher\" + 0.162*\"great\" + 0.104*\"learn\" + 0.035*\"love\" + 0.035*\"better\"')\n",
      "(11, '0.127*\"topic\" + 0.055*\"history\" + 0.052*\"means\" + 0.046*\"quite\" + 0.044*\"assign\"')\n",
      "(12, '0.195*\"understand\" + 0.107*\"explain\" + 0.101*\"things\" + 0.050*\"example\" + 0.043*\"concept\"')\n",
      "(13, '0.283*\"really\" + 0.200*\"interest\" + 0.095*\"make\" + 0.091*\"teaching\" + 0.053*\"funny\"')\n",
      "(14, '0.075*\"would\" + 0.062*\"teach\" + 0.046*\"course\" + 0.031*\"never\" + 0.028*\"think\"')\n",
      "\n",
      "Coherence Score:  0.33549398582257933\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 35\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.183*\"writing\" + 0.085*\"sister\" + 0.065*\"assign\" + 0.061*\"style\" + 0.042*\"relate\"')\n",
      "(1, '0.283*\"question\" + 0.147*\"answer\" + 0.046*\"constantly\" + 0.039*\"prove\" + 0.034*\"right\"')\n",
      "(2, '0.222*\"study\" + 0.158*\"grading\" + 0.095*\"speak\" + 0.051*\"guide\" + 0.034*\"present\"')\n",
      "(3, '0.328*\"teacher\" + 0.296*\"great\" + 0.073*\"awesome\" + 0.043*\"super\" + 0.025*\"spanish\"')\n",
      "(4, '0.075*\"english\" + 0.060*\"absolutely\" + 0.050*\"biweekly\" + 0.046*\"college\" + 0.040*\"forward\"')\n",
      "(5, '0.150*\"know\" + 0.091*\"stuff\" + 0.066*\"talking\" + 0.054*\"history\" + 0.046*\"refuse\"')\n",
      "(6, '0.217*\"would\" + 0.182*\"recommend\" + 0.093*\"taking\" + 0.065*\"highly\" + 0.058*\"grader\"')\n",
      "(7, '0.135*\"instructor\" + 0.086*\"worst\" + 0.076*\"extra\" + 0.075*\"credit\" + 0.071*\"post\"')\n",
      "(8, '0.119*\"really\" + 0.100*\"professor\" + 0.074*\"student\" + 0.059*\"learn\" + 0.044*\"teach\"')\n",
      "(9, '0.114*\"helpful\" + 0.071*\"understand\" + 0.056*\"always\" + 0.052*\"clear\" + 0.044*\"extremely\"')\n",
      "(10, '0.099*\"problem\" + 0.086*\"sense\" + 0.085*\"mistake\" + 0.058*\"avoid\" + 0.048*\"email\"')\n",
      "(11, '0.127*\"quiz\" + 0.105*\"midterm\" + 0.101*\"final\" + 0.068*\"write\" + 0.065*\"papers\"')\n",
      "(12, '0.185*\"assignment\" + 0.068*\"essay\" + 0.056*\"leave\" + 0.038*\"least\" + 0.030*\"allow\"')\n",
      "(13, '0.067*\"anything\" + 0.038*\"nothing\" + 0.027*\"completely\" + 0.025*\"useless\" + 0.022*\"entire\"')\n",
      "(14, '0.194*\"class\" + 0.048*\"lecture\" + 0.040*\"interest\" + 0.034*\"grade\" + 0.029*\"material\"')\n",
      "\n",
      "Coherence Score:  0.3430358996734756\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 20\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"RMP\"\n",
    "\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic number of passes seems to be between 15 and 25 (20 best so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i don't know about how helpful these subtopics are. what if i try... using a specific subset of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Business', 'Economics', 'Religion', 'Church History',\n",
       "       'Social Science', 'Anthropology', 'Accounting', 'Music',\n",
       "       'Psychology', 'Chemistry', 'Theater', 'Biology', 'Fine Arts',\n",
       "       'History', 'Political Science', 'Science', 'Interior Design',\n",
       "       'Humanities', 'Mathematics', 'Statistics', 'Art', 'Physiology',\n",
       "       'Agriculture', 'Geography', 'Spanish', 'Physics', 'Sociology',\n",
       "       'Family & Consumer Science', 'Writing', 'Film', 'Philosophy',\n",
       "       'Communication', 'Computer Science', 'Nutrition & Food Science',\n",
       "       'English', 'Finance', 'Japanese', 'Geology', 'Engineering',\n",
       "       'Marriage Family & Human Dev', 'Languages', 'Physical Sciences',\n",
       "       'Dance', 'Student Services', 'French', 'Health Science',\n",
       "       'Classical Studies', 'Literature', 'English Language & Literature',\n",
       "       'Information Systems', 'Mathematics Education', 'Classics',\n",
       "       'Exercise & Sport Science', 'Microbiology',\n",
       "       'Communication Disorders', 'Physical Education',\n",
       "       'Health & Physical Education', 'Russian', 'Art History',\n",
       "       'Foreign Languages', 'School of Family Life', 'German',\n",
       "       'Visual Arts', 'Linguistics', 'Family Studies', 'Social Work',\n",
       "       'Asian & Near Eastern Languages', 'Chemical Engineering',\n",
       "       'Business Administration', 'Human Development', 'Exercise Science',\n",
       "       'Chinese', 'Honors', 'Mechanical Engineering',\n",
       "       'Molecular Biosciences', 'Early Childhood Education',\n",
       "       'International Studies', 'Italian', 'Theatre & Media Arts',\n",
       "       'Civil Engineering', 'Electrical Engineering', 'Medicine', 'Law',\n",
       "       'Secondary Education', 'Recreation', 'Management', 'Physical Ed',\n",
       "       'Hebrew', 'Korean', 'Information Technology', 'Ancient Scripture',\n",
       "       'Scandinavian', 'Industrial Design', 'Elementary Education',\n",
       "       'Educational Leadership', 'French & Italian', 'Technology',\n",
       "       'Education', 'Arabic', 'Portuguese', 'Nursing',\n",
       "       'Organizational Ldrshp  Strat', 'Not Specified', 'Life Science',\n",
       "       'Criminal Justice', 'Nutrition  Food Science',\n",
       "       'University Studies', 'Latin American Studies',\n",
       "       'Aerospace Studies', 'Marketing', \"Women's Studies\", 'Journalism',\n",
       "       'Ethnic Studies', 'Art & Art History', 'East Asian Studies',\n",
       "       'Theology', 'Genetics', 'Zoology', 'Spanish & Portuguese',\n",
       "       'Asian Studies', 'Environmental Studies', 'Pharmacy',\n",
       "       'Agricultural Economics', 'Design', 'Consumer Science',\n",
       "       'Nutrition', 'Kinesiology', 'East Asian Lang. & Literature',\n",
       "       'Rehabilitation Psychology', 'African Studies', 'Astronomy',\n",
       "       'Military Science', 'Oncology', 'Biomedical Engineering',\n",
       "       'Horticulture', 'Mathematical and Computer Sci.',\n",
       "       'Religious Studies', 'Foreign Languages & Literature',\n",
       "       'Computer Information Technology', 'Child & Family Studies',\n",
       "       'Business Management', 'Animal Science', 'Home & Family Studies',\n",
       "       'Academic Services', 'Architecture', 'Automotive Technology',\n",
       "       'Career & College Prep', 'Online Learning', 'Career Development',\n",
       "       'Latin', 'Health & Human Performance', 'General Studies',\n",
       "       'Library Science', 'Cultural Studies', 'Physics & Astronomy',\n",
       "       'Family Social Science', 'Materials Science',\n",
       "       'Genetics / Cell Biology & Dev.', 'Biological Sciences',\n",
       "       'Sign Language', 'Organizational Leadership', 'Human Resources',\n",
       "       'Graphic Arts', 'Speech/Language/Hearing Sci.',\n",
       "       'Communication Studies', 'Gender, Women, and Sex Studies',\n",
       "       'Educational Psychology', 'Information Decision Sciences',\n",
       "       'Chicano Studies', 'African-American Studies', 'Writing Studies',\n",
       "       'Curriculum & Instruction', 'Child Development',\n",
       "       'Asian Languages & Literatures', 'Food Science & Nutrition',\n",
       "       'Sports Management', 'Electrical & Comp. Engineering',\n",
       "       'Aerospace Eng. & Mechanics', 'Natural History',\n",
       "       'German & Scandinavian', 'Rhetoric', 'Center for Spiritual Health',\n",
       "       'Administration', 'Theatre Arts & Dance', 'Anatomy',\n",
       "       'Art Education', 'Textiles & Clothing', 'Food Science',\n",
       "       'Comparative Studies', 'Biochemistry',\n",
       "       'Engineering Graphics Tech.', 'Hospitality Management',\n",
       "       'Environ. & Natural Resources', 'Industrial Engineering',\n",
       "       'Allied Health', 'Hospitality', 'Natural Resources',\n",
       "       'Aerospace Engineering', 'Speech & Hearing Sciences',\n",
       "       'Human Resource Management', 'Human Ecology', 'Persian',\n",
       "       'Near Eastern Studies', 'Public Policy',\n",
       "       'Agricultural Engineering', 'Slavic Languages',\n",
       "       'Public Administration', 'Neuroscience', 'Sports', 'Greek',\n",
       "       'Aviation', 'Public Health', 'Transportation & Logistics',\n",
       "       'Education & Human Ecology', 'Life Sciences',\n",
       "       'Information Science', 'Manufacturing & Construction',\n",
       "       'Construction', 'Behavioral Sciences', 'Engineering Technology',\n",
       "       'Management Communications', 'American Studies',\n",
       "       'Counseling Psychology', 'Facilities Management',\n",
       "       'Comparative Literature', 'Organization Management',\n",
       "       'Student Life', 'Organizational Ldrshp & Strat',\n",
       "       'Manufacturing Engineering Tech', 'Construction Management',\n",
       "       'Cantonese', 'Teaching & Learning', 'Swedish',\n",
       "       'Instructional Technology', 'Psychological Science', 'Hungarian',\n",
       "       'English As A Second Language', 'Graduate Studies',\n",
       "       'Continuing Education', 'Classical & Medieval Studies',\n",
       "       'English Language  Literature', 'Health  Physical Education',\n",
       "       'French  Italian', 'Physics  Astronomy',\n",
       "       'History & Asian American Studies', 'Atmospheric Sciences',\n",
       "       'Entomology', 'Veterinary Sciences', 'Dietetics', 'TA',\n",
       "       'Cell & Regenerative Biology', 'Hydrogeology',\n",
       "       'Spanish  Portuguese', 'Culinary Arts', 'Women',\n",
       "       'Art  Art History', 'Ag Bus, Plant & Animal Sci', 'Counseling',\n",
       "       'Agribusiness', 'Agronomy', 'College Success',\n",
       "       'Computer Science & Engineering', 'Foundations', 'EMT & Paramedic',\n",
       "       'Home  Family Studies', 'Health  Human Performance',\n",
       "       'Recreation & Leisure Studies', 'Child  Family Studies',\n",
       "       'Foreign Languages  Literature', 'Wildlife',\n",
       "       'Postsecondary Teaching', 'American Sign Language',\n",
       "       'Career & Community Lrng Center', 'Supply Chain Management',\n",
       "       'Urban Studies', 'Forest Resources', 'Strategic Management',\n",
       "       'Ecology & Evolutionary Biology', 'Plant Biology',\n",
       "       'Applied Economics', 'Public Affairs', 'Archaeology',\n",
       "       'Sports Science', 'Bioproducts/Biosystems',\n",
       "       'Fisheries Wildlife  Biology', 'Educational Development', 'Dental',\n",
       "       'Fisheries, Wildlife & Biology', 'Surgery', 'Naval Science',\n",
       "       'Earth Science', 'Landscape Architecture & Regional Planning',\n",
       "       'Food Science  Nutrition', 'German  Scandinavian',\n",
       "       'Electrical  Comp. Engineering', 'BioproductsBiosystems',\n",
       "       'Bioethics', 'SpeechLanguageHearing Sci.',\n",
       "       'Gender Women and Sex Studies', 'Global Studies',\n",
       "       'Curriculum  Instruction', 'Food, Agriculture & Bio Eng',\n",
       "       'Swahili', 'Athletic Training', 'Environmental Science',\n",
       "       'Managerial Science', 'Environment', 'Materials Science & Eng.',\n",
       "       'World Languages & Cultures', 'Nuclear Engineering',\n",
       "       'Arts & Sciences', 'Respiratory Therapy', 'Medical Technology',\n",
       "       'Soviet & East European Studi', 'Yiddish', 'Physical Therapy',\n",
       "       'Turkish', 'Welding', 'Systems Engineering',\n",
       "       'Visual Communication Design', 'Psychiatry',\n",
       "       'Environ.  Natural Resources', 'Textiles  Clothing',\n",
       "       'Science Education', 'Art & Design', 'Biostatistics',\n",
       "       'Health Services Management', 'Polish', 'Medieval Studies',\n",
       "       'Biotechnology', 'Health Information Science',\n",
       "       'Womens & Gender Studies', 'Womens  Gender Studies'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['dept'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Again, but now just related sciences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, with 35k rows - just related sciences with >1000 rows\n",
    "feedback_text = prepare_documents(sciences_df.comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary, corpus = generate_dictionary_corpus(\"sciences\", feedback_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.506*\"student\" + 0.100*\"want\" + 0.094*\"care\" + 0.049*\"care_student\" + 0.035*\"helping\"')\n",
      "(1, '0.292*\"recommend\" + 0.112*\"highly\" + 0.091*\"highly_recommend\" + 0.071*\"would_recommend\" + 0.069*\"anyone\"')\n",
      "(2, '0.282*\"explain\" + 0.197*\"things\" + 0.107*\"stuff\" + 0.087*\"clearly\" + 0.081*\"explain_things\"')\n",
      "(3, '0.084*\"lecture\" + 0.073*\"test\" + 0.070*\"homework\" + 0.061*\"exam\" + 0.048*\"problem\"')\n",
      "(4, '0.154*\"avoid\" + 0.138*\"terrible\" + 0.126*\"horrible\" + 0.110*\"nothing\" + 0.087*\"absolutely\"')\n",
      "(5, '0.133*\"class\" + 0.089*\"really\" + 0.085*\"professor\" + 0.069*\"great\" + 0.062*\"helpful\"')\n",
      "(6, '0.273*\"teaching\" + 0.090*\"write\" + 0.064*\"like\" + 0.055*\"board\" + 0.046*\"grader\"')\n",
      "(7, '0.163*\"concept\" + 0.146*\"overall\" + 0.098*\"lecturer\" + 0.078*\"challenge\" + 0.072*\"fairly\"')\n",
      "(8, '0.197*\"review\" + 0.117*\"attend\" + 0.077*\"writing\" + 0.073*\"provide\" + 0.067*\"choice\"')\n",
      "(9, '0.300*\"teacher\" + 0.205*\"understand\" + 0.067*\"willing\" + 0.036*\"everyone\" + 0.035*\"understanding\"')\n",
      "(10, '0.085*\"textbook\" + 0.075*\"online\" + 0.070*\"cover\" + 0.063*\"slide\" + 0.057*\"reading\"')\n",
      "(11, '0.083*\"boring\" + 0.072*\"lecture\" + 0.064*\"try\" + 0.063*\"sometimes\" + 0.057*\"seem\"')\n",
      "(12, '0.167*\"class\" + 0.051*\"teach\" + 0.042*\"learn\" + 0.040*\"material\" + 0.036*\"would\"')\n",
      "(13, '0.142*\"credit\" + 0.129*\"extra\" + 0.124*\"sense\" + 0.084*\"humor\" + 0.062*\"sense_humor\"')\n",
      "(14, '0.180*\"hours\" + 0.175*\"office\" + 0.148*\"answer\" + 0.144*\"office_hours\" + 0.107*\"question\"')\n",
      "\n",
      "Coherence Score:  0.37466463861310173\n",
      "\n",
      "Coherence Score (umass):  -4.606763678788926\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 15\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.125*\"worst\" + 0.094*\"avoid\" + 0.084*\"terrible\" + 0.077*\"horrible\" + 0.067*\"nothing\"')\n",
      "(1, '0.146*\"pretty\" + 0.094*\"boring\" + 0.078*\"lecture\" + 0.072*\"try\" + 0.071*\"sometimes\"')\n",
      "(2, '0.140*\"tough\" + 0.100*\"practice\" + 0.084*\"attention\" + 0.068*\"straight\" + 0.058*\"grader\"')\n",
      "(3, '0.207*\"would\" + 0.136*\"recommend\" + 0.086*\"first\" + 0.067*\"taking\" + 0.043*\"semester\"')\n",
      "(4, '0.111*\"textbook\" + 0.076*\"reading\" + 0.069*\"attend\" + 0.064*\"useless\" + 0.054*\"completely\"')\n",
      "(5, '0.447*\"student\" + 0.089*\"want\" + 0.084*\"care\" + 0.064*\"smart\" + 0.061*\"like\"')\n",
      "(6, '0.165*\"class\" + 0.053*\"professor\" + 0.048*\"teacher\" + 0.045*\"really\" + 0.037*\"great\"')\n",
      "(7, '0.108*\"anything\" + 0.075*\"instructor\" + 0.072*\"spend\" + 0.065*\"talking\" + 0.050*\"without\"')\n",
      "(8, '0.192*\"course\" + 0.104*\"overall\" + 0.070*\"lecturer\" + 0.063*\"topic\" + 0.062*\"credit\"')\n",
      "(9, '0.164*\"lecture\" + 0.111*\"homework\" + 0.098*\"exam\" + 0.076*\"problem\" + 0.045*\"example\"')\n",
      "(10, '0.347*\"question\" + 0.154*\"answer\" + 0.084*\"accent\" + 0.079*\"highly\" + 0.078*\"answer_question\"')\n",
      "(11, '0.316*\"explain\" + 0.187*\"things\" + 0.134*\"concept\" + 0.082*\"clearly\" + 0.077*\"explain_things\"')\n",
      "(12, '0.057*\"think\" + 0.051*\"take\" + 0.047*\"expect\" + 0.045*\"point\" + 0.044*\"seem\"')\n",
      "(13, '0.202*\"grade\" + 0.137*\"midterm\" + 0.133*\"final\" + 0.090*\"curve\" + 0.064*\"grading\"')\n",
      "(14, '0.230*\"hours\" + 0.223*\"office\" + 0.184*\"office_hours\" + 0.120*\"know\" + 0.118*\"stuff\"')\n",
      "\n",
      "Coherence Score:  0.33218338666544617\n",
      "\n",
      "Coherence Score (umass):  -5.054020155761721\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 20\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.314*\"class\" + 0.093*\"really\" + 0.063*\"helpful\" + 0.043*\"interest\" + 0.041*\"grade\"')\n",
      "(1, '0.394*\"teacher\" + 0.302*\"great\" + 0.040*\"excellent\" + 0.032*\"straight\" + 0.020*\"approachable\"')\n",
      "(2, '0.168*\"midterm\" + 0.163*\"final\" + 0.112*\"curve\" + 0.083*\"accent\" + 0.066*\"average\"')\n",
      "(3, '0.182*\"know\" + 0.135*\"stuff\" + 0.094*\"credit\" + 0.086*\"extra\" + 0.080*\"talking\"')\n",
      "(4, '0.289*\"course\" + 0.112*\"avoid\" + 0.084*\"challenge\" + 0.066*\"possible\" + 0.062*\"experience\"')\n",
      "(5, '0.309*\"question\" + 0.177*\"always\" + 0.137*\"answer\" + 0.071*\"highly\" + 0.069*\"answer_question\"')\n",
      "(6, '0.102*\"lecture\" + 0.062*\"test\" + 0.058*\"homework\" + 0.053*\"material\" + 0.051*\"exam\"')\n",
      "(7, '0.109*\"professor\" + 0.068*\"understand\" + 0.060*\"teach\" + 0.050*\"learn\" + 0.042*\"teaching\"')\n",
      "(8, '0.254*\"difficult\" + 0.201*\"clear\" + 0.126*\"concept\" + 0.055*\"fairly\" + 0.038*\"section\"')\n",
      "(9, '0.256*\"hours\" + 0.248*\"office\" + 0.204*\"office_hours\" + 0.102*\"practice\" + 0.046*\"assign\"')\n",
      "(10, '0.446*\"student\" + 0.089*\"want\" + 0.084*\"care\" + 0.070*\"understanding\" + 0.044*\"care_student\"')\n",
      "(11, '0.110*\"seem\" + 0.089*\"grading\" + 0.074*\"instructor\" + 0.071*\"smart\" + 0.069*\"hard\"')\n",
      "(12, '0.104*\"write\" + 0.100*\"times\" + 0.077*\"slide\" + 0.063*\"board\" + 0.051*\"discussion\"')\n",
      "(13, '0.297*\"would\" + 0.206*\"recommend\" + 0.097*\"taking\" + 0.050*\"would_recommend\" + 0.050*\"another\"')\n",
      "(14, '0.315*\"explain\" + 0.187*\"things\" + 0.083*\"physics\" + 0.082*\"clearly\" + 0.077*\"explain_things\"')\n",
      "\n",
      "Coherence Score:  0.3195721274458079\n",
      "\n",
      "Coherence Score (umass):  -5.461292538804794\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 25\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.209*\"recommend\" + 0.197*\"things\" + 0.113*\"definitely\" + 0.108*\"would\" + 0.081*\"explain_things\"')\n",
      "(1, '0.218*\"know\" + 0.168*\"subject\" + 0.161*\"stuff\" + 0.066*\"matter\" + 0.059*\"know_stuff\"')\n",
      "(2, '0.302*\"always\" + 0.246*\"willing\" + 0.091*\"sense\" + 0.065*\"always_willing\" + 0.062*\"humor\"')\n",
      "(3, '0.236*\"homework\" + 0.209*\"exam\" + 0.161*\"problem\" + 0.051*\"review\" + 0.048*\"write\"')\n",
      "(4, '0.164*\"material\" + 0.109*\"explain\" + 0.064*\"example\" + 0.048*\"concept\" + 0.036*\"confuse\"')\n",
      "(5, '0.084*\"need\" + 0.056*\"mistake\" + 0.055*\"email\" + 0.054*\"rather\" + 0.045*\"useful\"')\n",
      "(6, '0.131*\"great\" + 0.109*\"helpful\" + 0.074*\"interest\" + 0.054*\"teaching\" + 0.040*\"funny\"')\n",
      "(7, '0.174*\"class\" + 0.056*\"professor\" + 0.051*\"teacher\" + 0.047*\"really\" + 0.038*\"test\"')\n",
      "(8, '0.303*\"lecture\" + 0.082*\"clear\" + 0.066*\"quiz\" + 0.065*\"note\" + 0.051*\"give\"')\n",
      "(9, '0.179*\"midterm\" + 0.175*\"final\" + 0.120*\"curve\" + 0.072*\"credit\" + 0.070*\"average\"')\n",
      "(10, '0.094*\"worst\" + 0.071*\"avoid\" + 0.064*\"terrible\" + 0.058*\"horrible\" + 0.050*\"nothing\"')\n",
      "(11, '0.274*\"pretty\" + 0.177*\"boring\" + 0.133*\"sometimes\" + 0.043*\"entertain\" + 0.041*\"assign\"')\n",
      "(12, '0.306*\"hours\" + 0.296*\"office\" + 0.243*\"office_hours\" + 0.039*\"forward\" + 0.026*\"directly\"')\n",
      "(13, '0.380*\"student\" + 0.076*\"want\" + 0.072*\"care\" + 0.068*\"highly\" + 0.056*\"highly_recommend\"')\n",
      "(14, '0.376*\"question\" + 0.167*\"answer\" + 0.084*\"answer_question\" + 0.062*\"talking\" + 0.042*\"brother\"')\n",
      "\n",
      "Coherence Score:  0.3565970428260429\n",
      "\n",
      "Coherence Score (umass):  -5.239777111016027\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 30\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.103*\"lecture\" + 0.063*\"test\" + 0.058*\"homework\" + 0.054*\"material\" + 0.051*\"exam\"')\n",
      "(1, '0.247*\"midterm\" + 0.243*\"final\" + 0.061*\"midterm_final\" + 0.046*\"attendance\" + 0.045*\"suck\"')\n",
      "(2, '0.298*\"hours\" + 0.289*\"office\" + 0.237*\"office_hours\" + 0.048*\"available\" + 0.037*\"enthusiastic\"')\n",
      "(3, '0.116*\"teacher\" + 0.108*\"really\" + 0.089*\"great\" + 0.078*\"understand\" + 0.074*\"helpful\"')\n",
      "(4, '0.369*\"explain\" + 0.221*\"things\" + 0.160*\"concept\" + 0.096*\"clearly\" + 0.090*\"explain_things\"')\n",
      "(5, '0.258*\"example\" + 0.076*\"straight\" + 0.063*\"grader\" + 0.060*\"proof\" + 0.051*\"provide\"')\n",
      "(6, '0.342*\"question\" + 0.151*\"answer\" + 0.076*\"answer_question\" + 0.067*\"horrible\" + 0.059*\"sense\"')\n",
      "(7, '0.263*\"student\" + 0.158*\"interest\" + 0.060*\"subject\" + 0.053*\"want\" + 0.050*\"care\"')\n",
      "(8, '0.207*\"know\" + 0.154*\"stuff\" + 0.101*\"instructor\" + 0.062*\"matter\" + 0.062*\"email\"')\n",
      "(9, '0.153*\"confuse\" + 0.144*\"review\" + 0.080*\"board\" + 0.056*\"simple\" + 0.043*\"minutes\"')\n",
      "(10, '0.134*\"note\" + 0.073*\"textbook\" + 0.066*\"online\" + 0.053*\"slide\" + 0.051*\"reading\"')\n",
      "(11, '0.257*\"class\" + 0.082*\"professor\" + 0.045*\"teach\" + 0.037*\"learn\" + 0.031*\"teaching\"')\n",
      "(12, '0.209*\"always\" + 0.170*\"willing\" + 0.115*\"sometimes\" + 0.087*\"accent\" + 0.065*\"like\"')\n",
      "(13, '0.323*\"would\" + 0.223*\"recommend\" + 0.110*\"definitely\" + 0.085*\"highly\" + 0.070*\"highly_recommend\"')\n",
      "(14, '0.130*\"credit\" + 0.119*\"extra\" + 0.110*\"talking\" + 0.077*\"mistake\" + 0.060*\"wrong\"')\n",
      "\n",
      "Coherence Score:  0.3179680108189714\n",
      "\n",
      "Coherence Score (umass):  -5.720589279534417\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 35\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.214*\"grade\" + 0.142*\"midterm\" + 0.140*\"final\" + 0.084*\"point\" + 0.056*\"average\"')\n",
      "(1, '0.229*\"class\" + 0.073*\"professor\" + 0.067*\"teacher\" + 0.062*\"really\" + 0.051*\"great\"')\n",
      "(2, '0.118*\"teach\" + 0.099*\"learn\" + 0.082*\"teaching\" + 0.050*\"never\" + 0.043*\"could\"')\n",
      "(3, '0.209*\"explain\" + 0.126*\"things\" + 0.078*\"worst\" + 0.054*\"clearly\" + 0.052*\"terrible\"')\n",
      "(4, '0.215*\"problem\" + 0.127*\"example\" + 0.064*\"write\" + 0.062*\"accent\" + 0.038*\"board\"')\n",
      "(5, '0.139*\"lecture\" + 0.085*\"test\" + 0.078*\"homework\" + 0.069*\"exam\" + 0.048*\"difficult\"')\n",
      "(6, '0.212*\"always\" + 0.172*\"willing\" + 0.139*\"concept\" + 0.095*\"want\" + 0.072*\"super\"')\n",
      "(7, '0.313*\"question\" + 0.138*\"answer\" + 0.132*\"funny\" + 0.069*\"answer_question\" + 0.056*\"attention\"')\n",
      "(8, '0.091*\"course\" + 0.054*\"first\" + 0.051*\"better\" + 0.050*\"take\" + 0.045*\"subject\"')\n",
      "(9, '0.159*\"know\" + 0.118*\"stuff\" + 0.082*\"enjoy\" + 0.077*\"smart\" + 0.075*\"like\"')\n",
      "(10, '0.118*\"going\" + 0.063*\"follow\" + 0.056*\"spend\" + 0.050*\"talking\" + 0.046*\"something\"')\n",
      "(11, '0.251*\"hours\" + 0.243*\"office\" + 0.199*\"office_hours\" + 0.093*\"credit\" + 0.085*\"extra\"')\n",
      "(12, '0.160*\"note\" + 0.150*\"study\" + 0.090*\"review\" + 0.087*\"textbook\" + 0.079*\"online\"')\n",
      "(13, '0.339*\"would\" + 0.175*\"recommend\" + 0.116*\"definitely\" + 0.057*\"would_recommend\" + 0.057*\"another\"')\n",
      "(14, '0.153*\"avoid\" + 0.146*\"highly\" + 0.119*\"highly_recommend\" + 0.096*\"recommend\" + 0.081*\"experience\"')\n",
      "\n",
      "Coherence Score:  0.35788681640096087\n",
      "\n",
      "Coherence Score (umass):  -4.970000008836434\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 40\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.338*\"class\" + 0.040*\"grade\" + 0.034*\"lecture\" + 0.023*\"though\" + 0.023*\"boring\"')\n",
      "(1, '0.136*\"avoid\" + 0.131*\"physics\" + 0.129*\"highly\" + 0.106*\"highly_recommend\" + 0.094*\"recommend\"')\n",
      "(2, '0.383*\"would\" + 0.191*\"recommend\" + 0.076*\"sense\" + 0.065*\"would_recommend\" + 0.065*\"another\"')\n",
      "(3, '0.102*\"lecture\" + 0.087*\"test\" + 0.079*\"homework\" + 0.070*\"exam\" + 0.054*\"problem\"')\n",
      "(4, '0.264*\"really\" + 0.137*\"explain\" + 0.082*\"things\" + 0.067*\"funny\" + 0.054*\"awesome\"')\n",
      "(5, '0.272*\"always\" + 0.221*\"willing\" + 0.141*\"definitely\" + 0.059*\"always_willing\" + 0.031*\"enthusiastic\"')\n",
      "(6, '0.129*\"accent\" + 0.077*\"straight\" + 0.062*\"proof\" + 0.052*\"assign\" + 0.050*\"instead\"')\n",
      "(7, '0.293*\"midterm\" + 0.289*\"final\" + 0.073*\"midterm_final\" + 0.069*\"matter\" + 0.053*\"suck\"')\n",
      "(8, '0.233*\"concept\" + 0.122*\"credit\" + 0.112*\"extra\" + 0.095*\"project\" + 0.055*\"explain_concept\"')\n",
      "(9, '0.113*\"never\" + 0.080*\"worst\" + 0.070*\"anything\" + 0.054*\"terrible\" + 0.050*\"horrible\"')\n",
      "(10, '0.182*\"hours\" + 0.176*\"office\" + 0.151*\"answer\" + 0.144*\"office_hours\" + 0.117*\"question\"')\n",
      "(11, '0.221*\"know\" + 0.164*\"stuff\" + 0.097*\"talking\" + 0.060*\"know_stuff\" + 0.047*\"friendly\"')\n",
      "(12, '0.605*\"teacher\" + 0.058*\"person\" + 0.041*\"english\" + 0.040*\"grader\" + 0.039*\"brother\"')\n",
      "(13, '0.077*\"professor\" + 0.054*\"great\" + 0.051*\"student\" + 0.050*\"material\" + 0.047*\"understand\"')\n",
      "(14, '0.206*\"note\" + 0.193*\"study\" + 0.117*\"review\" + 0.109*\"care\" + 0.102*\"online\"')\n",
      "\n",
      "Coherence Score:  0.33560636484365797\n",
      "\n",
      "Coherence Score (umass):  -5.834400208051076\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 40\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.387*\"student\" + 0.140*\"willing\" + 0.078*\"want\" + 0.076*\"care\" + 0.040*\"care_student\"')\n",
      "(1, '0.165*\"boring\" + 0.125*\"try\" + 0.115*\"subject\" + 0.084*\"terrible\" + 0.060*\"something\"')\n",
      "(2, '0.119*\"like\" + 0.117*\"sense\" + 0.082*\"humor\" + 0.076*\"since\" + 0.060*\"already\"')\n",
      "(3, '0.399*\"would\" + 0.203*\"recommend\" + 0.068*\"would_recommend\" + 0.067*\"anyone\" + 0.055*\"mistake\"')\n",
      "(4, '0.281*\"course\" + 0.092*\"topic\" + 0.086*\"smart\" + 0.080*\"instructor\" + 0.067*\"straight\"')\n",
      "(5, '0.108*\"lecture\" + 0.067*\"test\" + 0.059*\"homework\" + 0.053*\"exam\" + 0.039*\"problem\"')\n",
      "(6, '0.350*\"explain\" + 0.214*\"things\" + 0.158*\"concept\" + 0.090*\"clearly\" + 0.087*\"explain_things\"')\n",
      "(7, '0.224*\"hours\" + 0.215*\"office\" + 0.175*\"office_hours\" + 0.062*\"board\" + 0.051*\"proof\"')\n",
      "(8, '0.182*\"worst\" + 0.139*\"avoid\" + 0.132*\"highly\" + 0.112*\"horrible\" + 0.108*\"highly_recommend\"')\n",
      "(9, '0.101*\"confuse\" + 0.092*\"textbook\" + 0.062*\"slide\" + 0.055*\"useless\" + 0.043*\"completely\"')\n",
      "(10, '0.119*\"sometimes\" + 0.088*\"times\" + 0.087*\"accent\" + 0.075*\"credit\" + 0.069*\"extra\"')\n",
      "(11, '0.088*\"professor\" + 0.081*\"teacher\" + 0.075*\"really\" + 0.061*\"great\" + 0.056*\"material\"')\n",
      "(12, '0.282*\"teaching\" + 0.146*\"know\" + 0.109*\"stuff\" + 0.064*\"talking\" + 0.047*\"style\"')\n",
      "(13, '0.326*\"class\" + 0.056*\"teach\" + 0.048*\"learn\" + 0.024*\"never\" + 0.021*\"going\"')\n",
      "(14, '0.439*\"question\" + 0.193*\"answer\" + 0.095*\"answer_question\" + 0.042*\"ask\" + 0.040*\"choice\"')\n",
      "\n",
      "Coherence Score:  0.3252990824714612\n",
      "\n",
      "Coherence Score (umass):  -5.652408160885664\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 100\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.391*\"question\" + 0.172*\"answer\" + 0.085*\"answer_question\" + 0.048*\"right\" + 0.044*\"email\"')\n",
      "(1, '0.218*\"concept\" + 0.068*\"style\" + 0.064*\"english\" + 0.054*\"come\" + 0.051*\"explain_concept\"')\n",
      "(2, '0.305*\"explain\" + 0.187*\"things\" + 0.082*\"highly\" + 0.079*\"clearly\" + 0.075*\"explain_things\"')\n",
      "(3, '0.103*\"first\" + 0.097*\"take\" + 0.063*\"easy\" + 0.053*\"hard\" + 0.044*\"project\"')\n",
      "(4, '0.161*\"class\" + 0.051*\"professor\" + 0.047*\"teacher\" + 0.044*\"really\" + 0.036*\"great\"')\n",
      "(5, '0.119*\"grade\" + 0.054*\"curve\" + 0.052*\"overall\" + 0.049*\"tough\" + 0.045*\"seem\"')\n",
      "(6, '0.194*\"final\" + 0.193*\"midterm\" + 0.157*\"know\" + 0.117*\"stuff\" + 0.048*\"midterm_final\"')\n",
      "(7, '0.102*\"confuse\" + 0.067*\"spend\" + 0.059*\"talking\" + 0.055*\"thing\" + 0.054*\"something\"')\n",
      "(8, '0.154*\"assignment\" + 0.152*\"point\" + 0.107*\"credit\" + 0.098*\"extra\" + 0.058*\"unclear\"')\n",
      "(9, '0.233*\"lecture\" + 0.144*\"test\" + 0.048*\"quiz\" + 0.048*\"note\" + 0.046*\"study\"')\n",
      "(10, '0.103*\"worst\" + 0.090*\"anything\" + 0.078*\"avoid\" + 0.069*\"terrible\" + 0.064*\"horrible\"')\n",
      "(11, '0.436*\"student\" + 0.088*\"want\" + 0.086*\"care\" + 0.080*\"accent\" + 0.061*\"sense\"')\n",
      "(12, '0.209*\"hours\" + 0.200*\"office\" + 0.185*\"willing\" + 0.163*\"office_hours\" + 0.050*\"outside\"')\n",
      "(13, '0.179*\"homework\" + 0.159*\"exam\" + 0.119*\"problem\" + 0.070*\"example\" + 0.062*\"boring\"')\n",
      "(14, '0.254*\"would\" + 0.176*\"recommend\" + 0.171*\"course\" + 0.085*\"taking\" + 0.043*\"would_recommend\"')\n",
      "\n",
      "Coherence Score:  0.36272550108717266\n",
      "\n",
      "Coherence Score (umass):  -5.157025476146178\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 100\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.152*\"boring\" + 0.111*\"sometimes\" + 0.096*\"seem\" + 0.091*\"however\" + 0.079*\"accent\"')\n",
      "(1, '0.147*\"take\" + 0.108*\"physics\" + 0.105*\"write\" + 0.092*\"easy\" + 0.061*\"board\"')\n",
      "(2, '0.072*\"worst\" + 0.064*\"anything\" + 0.055*\"avoid\" + 0.049*\"terrible\" + 0.045*\"horrible\"')\n",
      "(3, '0.452*\"question\" + 0.198*\"answer\" + 0.096*\"answer_question\" + 0.055*\"always_willing\" + 0.042*\"ask\"')\n",
      "(4, '0.279*\"pretty\" + 0.132*\"overall\" + 0.101*\"practice\" + 0.067*\"attend\" + 0.059*\"discussion\"')\n",
      "(5, '0.278*\"explain\" + 0.173*\"things\" + 0.130*\"concept\" + 0.071*\"clearly\" + 0.070*\"explain_things\"')\n",
      "(6, '0.125*\"confuse\" + 0.095*\"grading\" + 0.074*\"impossible\" + 0.071*\"different\" + 0.069*\"often\"')\n",
      "(7, '0.137*\"assignment\" + 0.070*\"project\" + 0.068*\"require\" + 0.064*\"worth\" + 0.062*\"usually\"')\n",
      "(8, '0.156*\"lecture\" + 0.098*\"test\" + 0.085*\"homework\" + 0.075*\"exam\" + 0.055*\"problem\"')\n",
      "(9, '0.139*\"first\" + 0.121*\"expect\" + 0.084*\"semester\" + 0.055*\"straight\" + 0.043*\"someone\"')\n",
      "(10, '0.148*\"class\" + 0.047*\"professor\" + 0.044*\"teacher\" + 0.040*\"really\" + 0.033*\"great\"')\n",
      "(11, '0.423*\"would\" + 0.072*\"would_recommend\" + 0.072*\"another\" + 0.061*\"recommend\" + 0.046*\"recitation\"')\n",
      "(12, '0.206*\"final\" + 0.199*\"midterm\" + 0.150*\"curve\" + 0.083*\"average\" + 0.055*\"style\"')\n",
      "(13, '0.161*\"hours\" + 0.153*\"office\" + 0.124*\"office_hours\" + 0.120*\"know\" + 0.090*\"stuff\"')\n",
      "(14, '0.231*\"course\" + 0.061*\"instructor\" + 0.058*\"quite\" + 0.050*\"level\" + 0.050*\"mistake\"')\n",
      "\n",
      "Coherence Score:  0.3339188669727128\n",
      "\n",
      "Coherence Score (umass):  -5.29144770274953\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.414*\"question\" + 0.181*\"answer\" + 0.088*\"answer_question\" + 0.052*\"mistake\" + 0.043*\"group\"')\n",
      "(1, '0.086*\"spend\" + 0.074*\"different\" + 0.072*\"useless\" + 0.055*\"completely\" + 0.045*\"start\"')\n",
      "(2, '0.125*\"subject\" + 0.103*\"avoid\" + 0.087*\"follow\" + 0.070*\"talking\" + 0.049*\"matter\"')\n",
      "(3, '0.185*\"teaching\" + 0.144*\"always\" + 0.116*\"willing\" + 0.088*\"awesome\" + 0.064*\"physics\"')\n",
      "(4, '0.195*\"final\" + 0.189*\"midterm\" + 0.095*\"accent\" + 0.058*\"straight\" + 0.047*\"midterm_final\"')\n",
      "(5, '0.154*\"teach\" + 0.091*\"would\" + 0.065*\"never\" + 0.055*\"know\" + 0.053*\"could\"')\n",
      "(6, '0.256*\"lecture\" + 0.064*\"clear\" + 0.053*\"example\" + 0.051*\"note\" + 0.049*\"boring\"')\n",
      "(7, '0.189*\"recommend\" + 0.095*\"definitely\" + 0.092*\"taking\" + 0.078*\"would\" + 0.072*\"highly\"')\n",
      "(8, '0.370*\"student\" + 0.095*\"try\" + 0.076*\"want\" + 0.075*\"care\" + 0.064*\"everyone\"')\n",
      "(9, '0.132*\"teacher\" + 0.121*\"really\" + 0.098*\"great\" + 0.076*\"helpful\" + 0.055*\"interest\"')\n",
      "(10, '0.199*\"class\" + 0.063*\"professor\" + 0.046*\"test\" + 0.040*\"homework\" + 0.039*\"material\"')\n",
      "(11, '0.344*\"explain\" + 0.214*\"things\" + 0.161*\"concept\" + 0.088*\"clearly\" + 0.086*\"explain_things\"')\n",
      "(12, '0.289*\"problem\" + 0.129*\"give\" + 0.085*\"practice\" + 0.073*\"credit\" + 0.067*\"extra\"')\n",
      "(13, '0.106*\"confuse\" + 0.098*\"seem\" + 0.088*\"write\" + 0.059*\"often\" + 0.051*\"board\"')\n",
      "(14, '0.285*\"hours\" + 0.271*\"office\" + 0.219*\"office_hours\" + 0.062*\"email\" + 0.038*\"engineering\"')\n",
      "\n",
      "Coherence Score:  0.35075245476144173\n",
      "\n",
      "Coherence Score (umass):  -5.1535157317961025\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance between runs is much lower at 300 passes\n",
    "# now, num_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying num of topics\n",
    "\n",
    "We've got 36k rows. Let's try 1-20 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.068*\"class\" + 0.025*\"lecture\" + 0.022*\"professor\" + 0.020*\"teacher\" + 0.019*\"really\"')\n",
      "\n",
      "Coherence Score:  0.25164761604512853\n",
      "\n",
      "Coherence Score (umass):  -2.097925893967894\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 1\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.074*\"professor\" + 0.048*\"student\" + 0.047*\"material\" + 0.044*\"understand\" + 0.040*\"teach\"')\n",
      "(1, '0.096*\"class\" + 0.035*\"lecture\" + 0.028*\"teacher\" + 0.026*\"really\" + 0.022*\"test\"')\n",
      "\n",
      "Coherence Score:  0.32017374612103366\n",
      "\n",
      "Coherence Score (umass):  -2.6232788076395\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 2\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.110*\"class\" + 0.035*\"professor\" + 0.032*\"teacher\" + 0.030*\"really\" + 0.024*\"great\"')\n",
      "(1, '0.129*\"recommend\" + 0.107*\"hours\" + 0.102*\"office\" + 0.092*\"answer\" + 0.082*\"office_hours\"')\n",
      "(2, '0.077*\"lecture\" + 0.048*\"test\" + 0.042*\"homework\" + 0.037*\"exam\" + 0.027*\"problem\"')\n",
      "\n",
      "Coherence Score:  0.37970532045159056\n",
      "\n",
      "Coherence Score (umass):  -2.999036533923446\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 3\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.058*\"teacher\" + 0.037*\"understand\" + 0.034*\"teach\" + 0.032*\"question\" + 0.030*\"student\"')\n",
      "(1, '0.128*\"class\" + 0.047*\"lecture\" + 0.040*\"professor\" + 0.035*\"really\" + 0.029*\"test\"')\n",
      "(2, '0.159*\"interest\" + 0.093*\"funny\" + 0.078*\"know\" + 0.061*\"subject\" + 0.058*\"stuff\"')\n",
      "(3, '0.106*\"recommend\" + 0.099*\"always\" + 0.079*\"willing\" + 0.060*\"awesome\" + 0.052*\"student\"')\n",
      "\n",
      "Coherence Score:  0.40215908102183867\n",
      "\n",
      "Coherence Score (umass):  -3.1424417655977663\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 4\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.144*\"class\" + 0.053*\"lecture\" + 0.033*\"test\" + 0.025*\"teach\" + 0.021*\"learn\"')\n",
      "(1, '0.191*\"question\" + 0.089*\"final\" + 0.087*\"note\" + 0.086*\"midterm\" + 0.084*\"answer\"')\n",
      "(2, '0.212*\"explain\" + 0.132*\"things\" + 0.099*\"concept\" + 0.054*\"clearly\" + 0.053*\"explain_things\"')\n",
      "(3, '0.106*\"homework\" + 0.095*\"exam\" + 0.062*\"grade\" + 0.044*\"hours\" + 0.041*\"office\"')\n",
      "(4, '0.073*\"professor\" + 0.068*\"teacher\" + 0.063*\"really\" + 0.051*\"great\" + 0.047*\"student\"')\n",
      "\n",
      "Coherence Score:  0.3872450674035093\n",
      "\n",
      "Coherence Score (umass):  -3.4808425320702883\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 5\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.212*\"class\" + 0.036*\"teach\" + 0.032*\"learn\" + 0.030*\"would\" + 0.025*\"teaching\"')\n",
      "(1, '0.077*\"professor\" + 0.072*\"teacher\" + 0.066*\"really\" + 0.054*\"great\" + 0.049*\"student\"')\n",
      "(2, '0.136*\"funny\" + 0.054*\"sense\" + 0.045*\"project\" + 0.045*\"would_recommend\" + 0.038*\"humor\"')\n",
      "(3, '0.091*\"lecture\" + 0.058*\"test\" + 0.050*\"homework\" + 0.044*\"exam\" + 0.032*\"problem\"')\n",
      "(4, '0.191*\"final\" + 0.185*\"midterm\" + 0.084*\"credit\" + 0.078*\"extra\" + 0.046*\"midterm_final\"')\n",
      "(5, '0.184*\"question\" + 0.098*\"things\" + 0.094*\"hours\" + 0.089*\"office\" + 0.080*\"answer\"')\n",
      "\n",
      "Coherence Score:  0.41503753956405115\n",
      "\n",
      "Coherence Score (umass):  -3.5279030953827153\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 6\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.092*\"know\" + 0.070*\"stuff\" + 0.061*\"physics\" + 0.044*\"smart\" + 0.041*\"talking\"')\n",
      "(1, '0.178*\"would\" + 0.123*\"recommend\" + 0.062*\"definitely\" + 0.060*\"taking\" + 0.047*\"highly\"')\n",
      "(2, '0.197*\"answer\" + 0.180*\"concept\" + 0.143*\"question\" + 0.096*\"answer_question\" + 0.081*\"sense\"')\n",
      "(3, '0.133*\"teacher\" + 0.123*\"really\" + 0.099*\"great\" + 0.062*\"explain\" + 0.056*\"interest\"')\n",
      "(4, '0.153*\"hours\" + 0.145*\"office\" + 0.117*\"office_hours\" + 0.096*\"worst\" + 0.073*\"avoid\"')\n",
      "(5, '0.106*\"class\" + 0.039*\"lecture\" + 0.034*\"professor\" + 0.025*\"test\" + 0.021*\"homework\"')\n",
      "(6, '0.311*\"student\" + 0.179*\"teaching\" + 0.112*\"willing\" + 0.064*\"want\" + 0.063*\"care\"')\n",
      "\n",
      "Coherence Score:  0.36236901194236565\n",
      "\n",
      "Coherence Score (umass):  -4.49516265782347\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 7\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.250*\"explain\" + 0.156*\"things\" + 0.117*\"concept\" + 0.064*\"clearly\" + 0.063*\"explain_things\"')\n",
      "(1, '0.139*\"hours\" + 0.132*\"office\" + 0.125*\"willing\" + 0.107*\"office_hours\" + 0.071*\"want\"')\n",
      "(2, '0.109*\"class\" + 0.040*\"lecture\" + 0.034*\"professor\" + 0.032*\"teacher\" + 0.030*\"really\"')\n",
      "(3, '0.054*\"never\" + 0.038*\"worst\" + 0.035*\"confuse\" + 0.034*\"anything\" + 0.029*\"write\"')\n",
      "(4, '0.164*\"homework\" + 0.146*\"exam\" + 0.107*\"problem\" + 0.063*\"example\" + 0.060*\"quiz\"')\n",
      "(5, '0.150*\"final\" + 0.146*\"midterm\" + 0.110*\"curve\" + 0.072*\"grading\" + 0.061*\"average\"')\n",
      "(6, '0.297*\"question\" + 0.130*\"answer\" + 0.113*\"know\" + 0.085*\"stuff\" + 0.063*\"answer_question\"')\n",
      "(7, '0.106*\"note\" + 0.064*\"review\" + 0.063*\"textbook\" + 0.058*\"online\" + 0.049*\"follow\"')\n",
      "\n",
      "Coherence Score:  0.3743433015948686\n",
      "\n",
      "Coherence Score (umass):  -4.352627122550625\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 8\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.107*\"sometimes\" + 0.076*\"accent\" + 0.070*\"follow\" + 0.047*\"board\" + 0.047*\"straight\"')\n",
      "(1, '0.143*\"class\" + 0.045*\"professor\" + 0.042*\"teacher\" + 0.039*\"really\" + 0.032*\"great\"')\n",
      "(2, '0.270*\"explain\" + 0.168*\"things\" + 0.126*\"concept\" + 0.076*\"practice\" + 0.069*\"clearly\"')\n",
      "(3, '0.072*\"worst\" + 0.066*\"confuse\" + 0.055*\"avoid\" + 0.048*\"terrible\" + 0.045*\"horrible\"')\n",
      "(4, '0.240*\"hours\" + 0.228*\"office\" + 0.184*\"office_hours\" + 0.120*\"care\" + 0.063*\"care_student\"')\n",
      "(5, '0.239*\"teaching\" + 0.083*\"physics\" + 0.054*\"different\" + 0.042*\"level\" + 0.041*\"style\"')\n",
      "(6, '0.262*\"recommend\" + 0.100*\"highly\" + 0.082*\"highly_recommend\" + 0.077*\"sense\" + 0.066*\"instructor\"')\n",
      "(7, '0.255*\"question\" + 0.111*\"answer\" + 0.097*\"know\" + 0.073*\"stuff\" + 0.054*\"answer_question\"')\n",
      "(8, '0.089*\"lecture\" + 0.056*\"test\" + 0.048*\"homework\" + 0.043*\"exam\" + 0.032*\"problem\"')\n",
      "\n",
      "Coherence Score:  0.37639189554297026\n",
      "\n",
      "Coherence Score (umass):  -4.402945502316859\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 9\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.243*\"explain\" + 0.151*\"things\" + 0.114*\"concept\" + 0.065*\"accent\" + 0.062*\"clearly\"')\n",
      "(1, '0.205*\"hours\" + 0.195*\"office\" + 0.157*\"office_hours\" + 0.103*\"care\" + 0.054*\"care_student\"')\n",
      "(2, '0.274*\"question\" + 0.156*\"always\" + 0.125*\"willing\" + 0.120*\"answer\" + 0.058*\"answer_question\"')\n",
      "(3, '0.126*\"teacher\" + 0.116*\"really\" + 0.094*\"great\" + 0.073*\"helpful\" + 0.053*\"interest\"')\n",
      "(4, '0.283*\"exam\" + 0.122*\"example\" + 0.116*\"note\" + 0.063*\"write\" + 0.061*\"practice\"')\n",
      "(5, '0.093*\"point\" + 0.067*\"credit\" + 0.063*\"spend\" + 0.062*\"extra\" + 0.050*\"something\"')\n",
      "(6, '0.144*\"test\" + 0.124*\"homework\" + 0.081*\"problem\" + 0.073*\"grade\" + 0.045*\"study\"')\n",
      "(7, '0.175*\"final\" + 0.170*\"midterm\" + 0.128*\"curve\" + 0.084*\"grading\" + 0.071*\"average\"')\n",
      "(8, '0.186*\"lecture\" + 0.053*\"pretty\" + 0.035*\"boring\" + 0.035*\"though\" + 0.033*\"going\"')\n",
      "(9, '0.178*\"class\" + 0.056*\"professor\" + 0.036*\"student\" + 0.035*\"material\" + 0.033*\"understand\"')\n",
      "\n",
      "Coherence Score:  0.38621200673582223\n",
      "\n",
      "Coherence Score (umass):  -4.35386005128006\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 10\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.191*\"teaching\" + 0.084*\"worst\" + 0.056*\"terrible\" + 0.052*\"horrible\" + 0.050*\"spend\"')\n",
      "(1, '0.252*\"hours\" + 0.240*\"office\" + 0.194*\"office_hours\" + 0.048*\"recitation\" + 0.036*\"forward\"')\n",
      "(2, '0.346*\"make\" + 0.104*\"accent\" + 0.083*\"sense\" + 0.059*\"humor\" + 0.058*\"mistake\"')\n",
      "(3, '0.338*\"student\" + 0.152*\"always\" + 0.122*\"willing\" + 0.069*\"want\" + 0.068*\"care\"')\n",
      "(4, '0.278*\"explain\" + 0.173*\"things\" + 0.130*\"concept\" + 0.071*\"clearly\" + 0.070*\"explain_things\"')\n",
      "(5, '0.076*\"lecture\" + 0.048*\"test\" + 0.041*\"homework\" + 0.038*\"understand\" + 0.037*\"exam\"')\n",
      "(6, '0.128*\"know\" + 0.121*\"give\" + 0.098*\"assignment\" + 0.096*\"stuff\" + 0.068*\"super\"')\n",
      "(7, '0.235*\"class\" + 0.074*\"professor\" + 0.069*\"teacher\" + 0.064*\"really\" + 0.052*\"great\"')\n",
      "(8, '0.184*\"final\" + 0.178*\"midterm\" + 0.094*\"practice\" + 0.092*\"highly\" + 0.076*\"highly_recommend\"')\n",
      "(9, '0.112*\"material\" + 0.096*\"helpful\" + 0.069*\"difficult\" + 0.059*\"pretty\" + 0.053*\"course\"')\n",
      "(10, '0.325*\"question\" + 0.142*\"answer\" + 0.069*\"answer_question\" + 0.036*\"email\" + 0.031*\"awful\"')\n",
      "\n",
      "Coherence Score:  0.35859057217370033\n",
      "\n",
      "Coherence Score (umass):  -5.018386459876916\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 11\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.410*\"student\" + 0.084*\"want\" + 0.083*\"care\" + 0.063*\"understanding\" + 0.058*\"sense\"')\n",
      "(1, '0.165*\"final\" + 0.160*\"midterm\" + 0.120*\"curve\" + 0.066*\"average\" + 0.041*\"since\"')\n",
      "(2, '0.085*\"worst\" + 0.075*\"anything\" + 0.065*\"avoid\" + 0.057*\"terrible\" + 0.053*\"horrible\"')\n",
      "(3, '0.270*\"teaching\" + 0.118*\"sometimes\" + 0.101*\"seem\" + 0.062*\"talking\" + 0.047*\"mistake\"')\n",
      "(4, '0.254*\"would\" + 0.175*\"recommend\" + 0.131*\"willing\" + 0.067*\"highly\" + 0.065*\"accent\"')\n",
      "(5, '0.209*\"course\" + 0.132*\"think\" + 0.102*\"point\" + 0.065*\"smart\" + 0.055*\"instructor\"')\n",
      "(6, '0.219*\"homework\" + 0.129*\"grade\" + 0.080*\"quiz\" + 0.064*\"give\" + 0.051*\"assignment\"')\n",
      "(7, '0.225*\"hours\" + 0.214*\"office\" + 0.173*\"office_hours\" + 0.066*\"project\" + 0.056*\"outside\"')\n",
      "(8, '0.260*\"explain\" + 0.162*\"things\" + 0.121*\"concept\" + 0.116*\"know\" + 0.087*\"stuff\"')\n",
      "(9, '0.429*\"question\" + 0.188*\"answer\" + 0.091*\"answer_question\" + 0.053*\"proof\" + 0.040*\"ask\"')\n",
      "(10, '0.159*\"class\" + 0.050*\"professor\" + 0.047*\"teacher\" + 0.043*\"really\" + 0.037*\"test\"')\n",
      "(11, '0.116*\"lecture\" + 0.062*\"material\" + 0.059*\"understand\" + 0.056*\"exam\" + 0.041*\"problem\"')\n",
      "\n",
      "Coherence Score:  0.36460497845614537\n",
      "\n",
      "Coherence Score (umass):  -4.848648009991599\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 12\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.142*\"awesome\" + 0.122*\"subject\" + 0.072*\"excellent\" + 0.053*\"favorite\" + 0.051*\"style\"')\n",
      "(1, '0.309*\"great\" + 0.102*\"funny\" + 0.056*\"love\" + 0.037*\"talking\" + 0.031*\"brother\"')\n",
      "(2, '0.447*\"student\" + 0.091*\"want\" + 0.090*\"care\" + 0.064*\"sense\" + 0.047*\"care_student\"')\n",
      "(3, '0.237*\"class\" + 0.070*\"teacher\" + 0.041*\"teach\" + 0.035*\"learn\" + 0.031*\"would\"')\n",
      "(4, '0.251*\"course\" + 0.049*\"since\" + 0.047*\"rather\" + 0.041*\"recitation\" + 0.038*\"department\"')\n",
      "(5, '0.143*\"know\" + 0.107*\"stuff\" + 0.095*\"physics\" + 0.092*\"avoid\" + 0.068*\"smart\"')\n",
      "(6, '0.201*\"explain\" + 0.125*\"things\" + 0.120*\"hours\" + 0.114*\"office\" + 0.108*\"willing\"')\n",
      "(7, '0.191*\"problem\" + 0.113*\"example\" + 0.051*\"terrible\" + 0.047*\"horrible\" + 0.045*\"spend\"')\n",
      "(8, '0.076*\"lecture\" + 0.065*\"professor\" + 0.056*\"really\" + 0.048*\"test\" + 0.041*\"homework\"')\n",
      "(9, '0.385*\"question\" + 0.168*\"answer\" + 0.082*\"answer_question\" + 0.043*\"email\" + 0.042*\"speak\"')\n",
      "(10, '0.302*\"recommend\" + 0.197*\"concept\" + 0.115*\"highly\" + 0.094*\"highly_recommend\" + 0.074*\"would_recommend\"')\n",
      "(11, '0.126*\"note\" + 0.075*\"textbook\" + 0.068*\"online\" + 0.068*\"write\" + 0.055*\"cover\"')\n",
      "(12, '0.144*\"final\" + 0.139*\"midterm\" + 0.064*\"credit\" + 0.059*\"extra\" + 0.058*\"average\"')\n",
      "\n",
      "Coherence Score:  0.37484675664713296\n",
      "\n",
      "Coherence Score (umass):  -4.585492594494054\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 13\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.127*\"credit\" + 0.117*\"extra\" + 0.103*\"talking\" + 0.077*\"style\" + 0.050*\"extra_credit\"')\n",
      "(1, '0.197*\"exam\" + 0.144*\"problem\" + 0.082*\"final\" + 0.081*\"quiz\" + 0.080*\"midterm\"')\n",
      "(2, '0.178*\"note\" + 0.106*\"textbook\" + 0.096*\"online\" + 0.078*\"cover\" + 0.075*\"topic\"')\n",
      "(3, '0.433*\"question\" + 0.189*\"answer\" + 0.092*\"answer_question\" + 0.055*\"mistake\" + 0.040*\"ask\"')\n",
      "(4, '0.272*\"student\" + 0.131*\"recommend\" + 0.056*\"want\" + 0.055*\"care\" + 0.050*\"highly\"')\n",
      "(5, '0.156*\"class\" + 0.046*\"teacher\" + 0.042*\"really\" + 0.036*\"test\" + 0.034*\"great\"')\n",
      "(6, '0.281*\"explain\" + 0.175*\"things\" + 0.151*\"willing\" + 0.131*\"concept\" + 0.072*\"clearly\"')\n",
      "(7, '0.159*\"lecture\" + 0.137*\"professor\" + 0.061*\"would\" + 0.051*\"teaching\" + 0.033*\"example\"')\n",
      "(8, '0.239*\"grade\" + 0.111*\"curve\" + 0.073*\"grading\" + 0.061*\"average\" + 0.058*\"challenge\"')\n",
      "(9, '0.148*\"difficult\" + 0.128*\"pretty\" + 0.112*\"clear\" + 0.086*\"extremely\" + 0.062*\"sometimes\"')\n",
      "(10, '0.183*\"boring\" + 0.120*\"point\" + 0.056*\"usually\" + 0.052*\"right\" + 0.040*\"assign\"')\n",
      "(11, '0.301*\"hours\" + 0.287*\"office\" + 0.232*\"office_hours\" + 0.049*\"show\" + 0.038*\"keep\"')\n",
      "(12, '0.227*\"know\" + 0.171*\"stuff\" + 0.083*\"straight\" + 0.063*\"know_stuff\" + 0.055*\"choice\"')\n",
      "(13, '0.187*\"course\" + 0.096*\"subject\" + 0.058*\"sense\" + 0.049*\"instructor\" + 0.041*\"humor\"')\n",
      "\n",
      "Coherence Score:  0.3558428695627904\n",
      "\n",
      "Coherence Score (umass):  -5.38563257407202\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 14\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.171*\"final\" + 0.166*\"midterm\" + 0.105*\"stuff\" + 0.051*\"discussion\" + 0.042*\"section\"')\n",
      "(1, '0.112*\"sense\" + 0.095*\"instructor\" + 0.091*\"quite\" + 0.079*\"humor\" + 0.079*\"experience\"')\n",
      "(2, '0.377*\"really\" + 0.126*\"always\" + 0.101*\"willing\" + 0.057*\"want\" + 0.046*\"enjoy\"')\n",
      "(3, '0.190*\"class\" + 0.060*\"professor\" + 0.036*\"understand\" + 0.033*\"teach\" + 0.028*\"learn\"')\n",
      "(4, '0.183*\"boring\" + 0.068*\"useless\" + 0.063*\"project\" + 0.052*\"proof\" + 0.049*\"matter\"')\n",
      "(5, '0.227*\"exam\" + 0.156*\"difficult\" + 0.072*\"little\" + 0.069*\"curve\" + 0.061*\"tough\"')\n",
      "(6, '0.185*\"lecture\" + 0.117*\"test\" + 0.101*\"homework\" + 0.066*\"problem\" + 0.039*\"example\"')\n",
      "(7, '0.263*\"hours\" + 0.250*\"office\" + 0.202*\"office_hours\" + 0.072*\"straight\" + 0.065*\"mistake\"')\n",
      "(8, '0.185*\"concept\" + 0.148*\"sometimes\" + 0.105*\"accent\" + 0.076*\"often\" + 0.059*\"level\"')\n",
      "(9, '0.469*\"student\" + 0.095*\"care\" + 0.091*\"avoid\" + 0.050*\"care_student\" + 0.041*\"email\"')\n",
      "(10, '0.304*\"explain\" + 0.189*\"things\" + 0.136*\"know\" + 0.078*\"clearly\" + 0.076*\"explain_things\"')\n",
      "(11, '0.423*\"question\" + 0.185*\"answer\" + 0.090*\"answer_question\" + 0.073*\"slide\" + 0.040*\"ask\"')\n",
      "(12, '0.344*\"recommend\" + 0.131*\"highly\" + 0.108*\"highly_recommend\" + 0.085*\"would_recommend\" + 0.084*\"anyone\"')\n",
      "(13, '0.433*\"material\" + 0.073*\"follow\" + 0.070*\"cover\" + 0.044*\"style\" + 0.037*\"organize\"')\n",
      "(14, '0.138*\"teacher\" + 0.103*\"great\" + 0.080*\"helpful\" + 0.058*\"interest\" + 0.056*\"make\"')\n",
      "\n",
      "Coherence Score:  0.31756490858774383\n",
      "\n",
      "Coherence Score (umass):  -5.692525448722116\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.199*\"know\" + 0.150*\"stuff\" + 0.143*\"review\" + 0.125*\"practice\" + 0.055*\"know_stuff\"')\n",
      "(1, '0.296*\"hours\" + 0.282*\"office\" + 0.228*\"office_hours\" + 0.041*\"guide\" + 0.029*\"study_guide\"')\n",
      "(2, '0.210*\"concept\" + 0.095*\"sense\" + 0.088*\"talking\" + 0.073*\"absolutely\" + 0.068*\"humor\"')\n",
      "(3, '0.276*\"would\" + 0.191*\"recommend\" + 0.093*\"taking\" + 0.076*\"avoid\" + 0.047*\"would_recommend\"')\n",
      "(4, '0.321*\"teacher\" + 0.240*\"great\" + 0.032*\"learning\" + 0.032*\"probably\" + 0.031*\"amaze\"')\n",
      "(5, '0.169*\"grade\" + 0.108*\"final\" + 0.105*\"midterm\" + 0.079*\"curve\" + 0.066*\"point\"')\n",
      "(6, '0.238*\"course\" + 0.180*\"extremely\" + 0.126*\"expect\" + 0.057*\"effort\" + 0.052*\"level\"')\n",
      "(7, '0.318*\"explain\" + 0.198*\"things\" + 0.081*\"clearly\" + 0.080*\"explain_things\" + 0.066*\"excellent\"')\n",
      "(8, '0.315*\"question\" + 0.138*\"answer\" + 0.067*\"answer_question\" + 0.065*\"follow\" + 0.039*\"right\"')\n",
      "(9, '0.464*\"student\" + 0.094*\"care\" + 0.071*\"understanding\" + 0.049*\"care_student\" + 0.031*\"succeed\"')\n",
      "(10, '0.117*\"lecture\" + 0.073*\"test\" + 0.063*\"homework\" + 0.063*\"material\" + 0.056*\"exam\"')\n",
      "(11, '0.313*\"problem\" + 0.185*\"example\" + 0.063*\"often\" + 0.049*\"mistake\" + 0.041*\"unclear\"')\n",
      "(12, '0.136*\"teach\" + 0.058*\"never\" + 0.047*\"could\" + 0.043*\"take\" + 0.041*\"worst\"')\n",
      "(13, '0.114*\"think\" + 0.109*\"first\" + 0.103*\"better\" + 0.084*\"seem\" + 0.066*\"semester\"')\n",
      "(14, '0.198*\"clear\" + 0.197*\"always\" + 0.158*\"willing\" + 0.081*\"highly\" + 0.066*\"highly_recommend\"')\n",
      "(15, '0.250*\"class\" + 0.079*\"professor\" + 0.068*\"really\" + 0.047*\"understand\" + 0.043*\"helpful\"')\n",
      "\n",
      "Coherence Score:  0.32517878141358003\n",
      "\n",
      "Coherence Score (umass):  -5.367757220250896\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 16\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.145*\"definitely\" + 0.085*\"smart\" + 0.083*\"challenge\" + 0.081*\"person\" + 0.079*\"talking\"')\n",
      "(1, '0.104*\"lecture\" + 0.089*\"professor\" + 0.065*\"test\" + 0.062*\"great\" + 0.056*\"material\"')\n",
      "(2, '0.143*\"example\" + 0.137*\"note\" + 0.081*\"textbook\" + 0.074*\"online\" + 0.062*\"follow\"')\n",
      "(3, '0.177*\"point\" + 0.107*\"slide\" + 0.079*\"mistake\" + 0.077*\"style\" + 0.046*\"teaching_style\"')\n",
      "(4, '0.175*\"homework\" + 0.156*\"exam\" + 0.114*\"problem\" + 0.065*\"final\" + 0.064*\"study\"')\n",
      "(5, '0.326*\"really\" + 0.242*\"student\" + 0.050*\"want\" + 0.049*\"care\" + 0.048*\"love\"')\n",
      "(6, '0.201*\"clear\" + 0.199*\"always\" + 0.160*\"willing\" + 0.063*\"amaze\" + 0.042*\"always_willing\"')\n",
      "(7, '0.117*\"physics\" + 0.099*\"terrible\" + 0.092*\"horrible\" + 0.083*\"sense\" + 0.059*\"without\"')\n",
      "(8, '0.248*\"grade\" + 0.115*\"curve\" + 0.083*\"avoid\" + 0.076*\"grading\" + 0.064*\"average\"')\n",
      "(9, '0.256*\"explain\" + 0.159*\"things\" + 0.120*\"concept\" + 0.114*\"know\" + 0.086*\"stuff\"')\n",
      "(10, '0.116*\"expect\" + 0.092*\"write\" + 0.081*\"easy\" + 0.058*\"instructor\" + 0.057*\"something\"')\n",
      "(11, '0.275*\"class\" + 0.051*\"understand\" + 0.047*\"teach\" + 0.041*\"learn\" + 0.039*\"would\"')\n",
      "(12, '0.440*\"question\" + 0.192*\"answer\" + 0.093*\"answer_question\" + 0.039*\"explanation\" + 0.038*\"suck\"')\n",
      "(13, '0.434*\"teacher\" + 0.144*\"recommend\" + 0.082*\"awesome\" + 0.070*\"taking\" + 0.055*\"highly\"')\n",
      "(14, '0.293*\"hours\" + 0.278*\"office\" + 0.225*\"office_hours\" + 0.067*\"matter\" + 0.034*\"trouble\"')\n",
      "(15, '0.143*\"think\" + 0.112*\"people\" + 0.071*\"like\" + 0.069*\"thought\" + 0.049*\"experience\"')\n",
      "(16, '0.146*\"assignment\" + 0.102*\"credit\" + 0.094*\"extra\" + 0.075*\"project\" + 0.075*\"would_recommend\"')\n",
      "\n",
      "Coherence Score:  0.3319179560434367\n",
      "\n",
      "Coherence Score (umass):  -5.243660988085706\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 17\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.145*\"professor\" + 0.093*\"student\" + 0.091*\"material\" + 0.086*\"understand\" + 0.078*\"helpful\"')\n",
      "(1, '0.231*\"funny\" + 0.092*\"sense\" + 0.065*\"humor\" + 0.062*\"joke\" + 0.061*\"entertain\"')\n",
      "(2, '0.255*\"know\" + 0.192*\"stuff\" + 0.071*\"know_stuff\" + 0.061*\"attendance\" + 0.059*\"suck\"')\n",
      "(3, '0.308*\"question\" + 0.157*\"hours\" + 0.149*\"office\" + 0.135*\"answer\" + 0.121*\"office_hours\"')\n",
      "(4, '0.373*\"recommend\" + 0.142*\"highly\" + 0.117*\"highly_recommend\" + 0.092*\"would_recommend\" + 0.091*\"anyone\"')\n",
      "(5, '0.331*\"explain\" + 0.206*\"things\" + 0.085*\"clearly\" + 0.083*\"explain_things\" + 0.080*\"enjoy\"')\n",
      "(6, '0.136*\"test\" + 0.117*\"homework\" + 0.104*\"exam\" + 0.068*\"grade\" + 0.062*\"pretty\"')\n",
      "(7, '0.171*\"subject\" + 0.067*\"matter\" + 0.066*\"found\" + 0.048*\"talks\" + 0.047*\"world\"')\n",
      "(8, '0.160*\"confuse\" + 0.117*\"easy\" + 0.090*\"different\" + 0.088*\"often\" + 0.069*\"level\"')\n",
      "(9, '0.396*\"great\" + 0.164*\"always\" + 0.132*\"willing\" + 0.074*\"care\" + 0.040*\"brother\"')\n",
      "(10, '0.300*\"problem\" + 0.177*\"example\" + 0.091*\"write\" + 0.088*\"practice\" + 0.052*\"board\"')\n",
      "(11, '0.131*\"follow\" + 0.100*\"attend\" + 0.087*\"straight\" + 0.061*\"decent\" + 0.048*\"friendly\"')\n",
      "(12, '0.211*\"class\" + 0.077*\"lecture\" + 0.062*\"teacher\" + 0.036*\"teach\" + 0.031*\"learn\"')\n",
      "(13, '0.191*\"concept\" + 0.072*\"fairly\" + 0.060*\"proof\" + 0.052*\"rather\" + 0.051*\"grader\"')\n",
      "(14, '0.236*\"boring\" + 0.111*\"credit\" + 0.102*\"extra\" + 0.050*\"choice\" + 0.044*\"extra_credit\"')\n",
      "(15, '0.251*\"really\" + 0.115*\"interest\" + 0.111*\"make\" + 0.051*\"awesome\" + 0.046*\"definitely\"')\n",
      "(16, '0.195*\"note\" + 0.116*\"textbook\" + 0.105*\"online\" + 0.086*\"reading\" + 0.085*\"cover\"')\n",
      "(17, '0.260*\"final\" + 0.252*\"midterm\" + 0.125*\"grading\" + 0.084*\"project\" + 0.062*\"midterm_final\"')\n",
      "\n",
      "Coherence Score:  0.3237626055905015\n",
      "\n",
      "Coherence Score (umass):  -5.648519255926635\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 18\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.174*\"confuse\" + 0.145*\"avoid\" + 0.082*\"possible\" + 0.066*\"email\" + 0.064*\"speak\"')\n",
      "(1, '0.219*\"subject\" + 0.122*\"talking\" + 0.096*\"calculus\" + 0.086*\"matter\" + 0.069*\"assign\"')\n",
      "(2, '0.294*\"material\" + 0.278*\"understand\" + 0.181*\"difficult\" + 0.042*\"challenge\" + 0.038*\"enough\"')\n",
      "(3, '0.156*\"test\" + 0.135*\"homework\" + 0.079*\"grade\" + 0.049*\"study\" + 0.049*\"quiz\"')\n",
      "(4, '0.345*\"lecture\" + 0.086*\"clear\" + 0.072*\"example\" + 0.069*\"note\" + 0.065*\"boring\"')\n",
      "(5, '0.201*\"hours\" + 0.191*\"office\" + 0.183*\"final\" + 0.177*\"midterm\" + 0.154*\"office_hours\"')\n",
      "(6, '0.365*\"exam\" + 0.267*\"problem\" + 0.078*\"practice\" + 0.038*\"since\" + 0.035*\"exactly\"')\n",
      "(7, '0.201*\"awesome\" + 0.104*\"sense\" + 0.102*\"excellent\" + 0.074*\"humor\" + 0.069*\"entertain\"')\n",
      "(8, '0.250*\"recommend\" + 0.126*\"definitely\" + 0.122*\"taking\" + 0.095*\"highly\" + 0.078*\"highly_recommend\"')\n",
      "(9, '0.135*\"write\" + 0.093*\"need\" + 0.084*\"instructor\" + 0.078*\"board\" + 0.077*\"straight\"')\n",
      "(10, '0.425*\"question\" + 0.186*\"answer\" + 0.090*\"answer_question\" + 0.044*\"information\" + 0.040*\"ask\"')\n",
      "(11, '0.114*\"pretty\" + 0.075*\"though\" + 0.061*\"little\" + 0.055*\"sometimes\" + 0.054*\"overall\"')\n",
      "(12, '0.283*\"always\" + 0.227*\"willing\" + 0.102*\"credit\" + 0.094*\"extra\" + 0.060*\"always_willing\"')\n",
      "(13, '0.325*\"explain\" + 0.202*\"things\" + 0.152*\"concept\" + 0.083*\"clearly\" + 0.081*\"explain_things\"')\n",
      "(14, '0.449*\"student\" + 0.092*\"want\" + 0.091*\"care\" + 0.047*\"care_student\" + 0.032*\"choice\"')\n",
      "(15, '0.199*\"really\" + 0.161*\"great\" + 0.124*\"helpful\" + 0.091*\"interest\" + 0.053*\"funny\"')\n",
      "(16, '0.223*\"class\" + 0.070*\"professor\" + 0.066*\"teacher\" + 0.038*\"teach\" + 0.033*\"learn\"')\n",
      "(17, '0.393*\"make\" + 0.066*\"mistake\" + 0.064*\"joke\" + 0.049*\"hilarious\" + 0.047*\"incredibly\"')\n",
      "(18, '0.170*\"know\" + 0.145*\"try\" + 0.128*\"stuff\" + 0.086*\"spend\" + 0.083*\"learning\"')\n",
      "\n",
      "Coherence Score:  0.31667137395534994\n",
      "\n",
      "Coherence Score (umass):  -5.80772521289222\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 19\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.288*\"example\" + 0.274*\"study\" + 0.069*\"found\" + 0.058*\"provide\" + 0.042*\"guide\"')\n",
      "(1, '0.186*\"could\" + 0.137*\"review\" + 0.084*\"talking\" + 0.064*\"without\" + 0.058*\"around\"')\n",
      "(2, '0.245*\"grade\" + 0.156*\"final\" + 0.151*\"midterm\" + 0.114*\"curve\" + 0.063*\"average\"')\n",
      "(3, '0.349*\"explain\" + 0.217*\"things\" + 0.089*\"clearly\" + 0.087*\"explain_things\" + 0.063*\"instructor\"')\n",
      "(4, '0.168*\"lecture\" + 0.106*\"test\" + 0.091*\"homework\" + 0.081*\"exam\" + 0.059*\"problem\"')\n",
      "(5, '0.376*\"question\" + 0.164*\"answer\" + 0.080*\"answer_question\" + 0.075*\"cover\" + 0.057*\"project\"')\n",
      "(6, '0.106*\"write\" + 0.106*\"avoid\" + 0.093*\"terrible\" + 0.086*\"horrible\" + 0.075*\"impossible\"')\n",
      "(7, '0.182*\"awesome\" + 0.105*\"super\" + 0.073*\"straight\" + 0.056*\"exactly\" + 0.047*\"tell\"')\n",
      "(8, '0.263*\"would\" + 0.182*\"recommend\" + 0.174*\"course\" + 0.089*\"subject\" + 0.053*\"thought\"')\n",
      "(9, '0.113*\"going\" + 0.097*\"first\" + 0.075*\"seem\" + 0.059*\"semester\" + 0.038*\"worth\"')\n",
      "(10, '0.105*\"point\" + 0.100*\"textbook\" + 0.077*\"follow\" + 0.074*\"reading\" + 0.063*\"slide\"')\n",
      "(11, '0.466*\"student\" + 0.146*\"concept\" + 0.095*\"want\" + 0.094*\"care\" + 0.049*\"care_student\"')\n",
      "(12, '0.164*\"tough\" + 0.131*\"help\" + 0.117*\"lecturer\" + 0.113*\"credit\" + 0.104*\"extra\"')\n",
      "(13, '0.120*\"teach\" + 0.104*\"learn\" + 0.051*\"never\" + 0.041*\"think\" + 0.038*\"better\"')\n",
      "(14, '0.264*\"always\" + 0.211*\"willing\" + 0.083*\"sense\" + 0.059*\"humor\" + 0.056*\"always_willing\"')\n",
      "(15, '0.229*\"class\" + 0.072*\"professor\" + 0.068*\"teacher\" + 0.062*\"really\" + 0.051*\"great\"')\n",
      "(16, '0.279*\"hours\" + 0.265*\"office\" + 0.215*\"office_hours\" + 0.050*\"choice\" + 0.043*\"multiple\"')\n",
      "(17, '0.271*\"pretty\" + 0.188*\"note\" + 0.179*\"boring\" + 0.102*\"online\" + 0.061*\"quite\"')\n",
      "(18, '0.131*\"worst\" + 0.076*\"probably\" + 0.074*\"smart\" + 0.057*\"discussion\" + 0.052*\"school\"')\n",
      "(19, '0.177*\"know\" + 0.149*\"sometimes\" + 0.134*\"stuff\" + 0.104*\"grading\" + 0.080*\"person\"')\n",
      "\n",
      "Coherence Score:  0.3011022577047723\n",
      "\n",
      "Coherence Score (umass):  -5.665075424046583\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 20\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, '0.324*\"hours\" + 0.308*\"office\" + 0.249*\"office_hours\" + 0.032*\"saying\" + 0.029*\"along\"')\n",
      "(17, '0.132*\"grading\" + 0.121*\"credit\" + 0.112*\"extra\" + 0.073*\"right\" + 0.052*\"suck\"')\n",
      "(7, '0.210*\"know\" + 0.158*\"stuff\" + 0.078*\"board\" + 0.060*\"speak\" + 0.059*\"unclear\"')\n",
      "(5, '0.383*\"teaching\" + 0.157*\"subject\" + 0.065*\"style\" + 0.062*\"matter\" + 0.045*\"present\"')\n",
      "(9, '0.403*\"explain\" + 0.251*\"things\" + 0.103*\"clearly\" + 0.101*\"explain_things\" + 0.024*\"paper\"')\n",
      "(19, '0.105*\"lecturer\" + 0.090*\"like\" + 0.089*\"smart\" + 0.089*\"sense\" + 0.063*\"humor\"')\n",
      "(15, '0.413*\"question\" + 0.181*\"answer\" + 0.087*\"answer_question\" + 0.039*\"ask\" + 0.035*\"talks\"')\n",
      "(4, '0.276*\"course\" + 0.081*\"slide\" + 0.077*\"often\" + 0.060*\"level\" + 0.054*\"making\"')\n",
      "(1, '0.340*\"problem\" + 0.151*\"give\" + 0.100*\"practice\" + 0.058*\"straight\" + 0.045*\"exactly\"')\n",
      "(3, '0.334*\"make\" + 0.202*\"funny\" + 0.074*\"talking\" + 0.056*\"mistake\" + 0.054*\"joke\"')\n",
      "(11, '0.461*\"student\" + 0.094*\"want\" + 0.093*\"care\" + 0.085*\"highly\" + 0.070*\"highly_recommend\"')\n",
      "(20, '0.129*\"worst\" + 0.114*\"anything\" + 0.099*\"avoid\" + 0.087*\"terrible\" + 0.080*\"horrible\"')\n",
      "(16, '0.452*\"understand\" + 0.154*\"concept\" + 0.053*\"absolutely\" + 0.051*\"calculus\" + 0.040*\"simple\"')\n",
      "(10, '0.251*\"grade\" + 0.160*\"final\" + 0.155*\"midterm\" + 0.117*\"curve\" + 0.101*\"assignment\"')\n",
      "(8, '0.220*\"pretty\" + 0.146*\"boring\" + 0.118*\"little\" + 0.107*\"sometimes\" + 0.060*\"attention\"')\n",
      "(6, '0.329*\"teacher\" + 0.246*\"great\" + 0.102*\"always\" + 0.081*\"willing\" + 0.062*\"awesome\"')\n",
      "(14, '0.304*\"professor\" + 0.136*\"would\" + 0.094*\"recommend\" + 0.048*\"definitely\" + 0.046*\"taking\"')\n",
      "(13, '0.061*\"never\" + 0.058*\"everything\" + 0.055*\"going\" + 0.051*\"every\" + 0.050*\"could\"')\n",
      "(0, '0.144*\"lecture\" + 0.091*\"test\" + 0.078*\"homework\" + 0.078*\"material\" + 0.070*\"exam\"')\n",
      "(12, '0.325*\"class\" + 0.088*\"really\" + 0.056*\"teach\" + 0.048*\"learn\" + 0.040*\"interest\"')\n",
      "\n",
      "Coherence Score:  0.3058007677102926\n",
      "\n",
      "Coherence Score (umass):  -5.802315050392868\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 21\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, '0.116*\"average\" + 0.101*\"often\" + 0.079*\"mistake\" + 0.072*\"around\" + 0.061*\"decent\"')\n",
      "(15, '0.215*\"hours\" + 0.205*\"office\" + 0.166*\"office_hours\" + 0.108*\"care\" + 0.057*\"care_student\"')\n",
      "(21, '0.618*\"exam\" + 0.133*\"practice\" + 0.078*\"discussion\" + 0.038*\"practice_exam\" + 0.033*\"focus\"')\n",
      "(1, '0.445*\"would\" + 0.103*\"credit\" + 0.095*\"extra\" + 0.076*\"would_recommend\" + 0.075*\"anyone\"')\n",
      "(0, '0.240*\"example\" + 0.123*\"write\" + 0.071*\"board\" + 0.049*\"provide\" + 0.041*\"entire\"')\n",
      "(8, '0.157*\"expect\" + 0.139*\"review\" + 0.101*\"cover\" + 0.055*\"exactly\" + 0.052*\"least\"')\n",
      "(6, '0.330*\"pretty\" + 0.155*\"definitely\" + 0.090*\"thought\" + 0.077*\"instructor\" + 0.058*\"found\"')\n",
      "(18, '0.280*\"recommend\" + 0.115*\"physics\" + 0.107*\"highly\" + 0.087*\"highly_recommend\" + 0.083*\"smart\"')\n",
      "(19, '0.395*\"question\" + 0.178*\"midterm\" + 0.173*\"answer\" + 0.084*\"answer_question\" + 0.049*\"right\"')\n",
      "(3, '0.307*\"teaching\" + 0.149*\"first\" + 0.115*\"seem\" + 0.052*\"style\" + 0.039*\"ask\"')\n",
      "(11, '0.308*\"interest\" + 0.128*\"try\" + 0.076*\"topic\" + 0.073*\"like\" + 0.061*\"thing\"')\n",
      "(14, '0.161*\"going\" + 0.106*\"textbook\" + 0.079*\"reading\" + 0.070*\"attention\" + 0.067*\"slide\"')\n",
      "(5, '0.200*\"always\" + 0.160*\"willing\" + 0.133*\"know\" + 0.105*\"subject\" + 0.100*\"stuff\"')\n",
      "(9, '0.280*\"make\" + 0.130*\"awesome\" + 0.075*\"super\" + 0.056*\"project\" + 0.052*\"straight\"')\n",
      "(20, '0.497*\"lecture\" + 0.099*\"note\" + 0.094*\"boring\" + 0.069*\"sometimes\" + 0.053*\"online\"')\n",
      "(4, '0.329*\"teacher\" + 0.245*\"great\" + 0.189*\"helpful\" + 0.035*\"understanding\" + 0.032*\"sense\"')\n",
      "(13, '0.156*\"teach\" + 0.066*\"never\" + 0.062*\"everything\" + 0.047*\"worst\" + 0.043*\"confuse\"')\n",
      "(16, '0.192*\"professor\" + 0.123*\"student\" + 0.120*\"material\" + 0.074*\"difficult\" + 0.057*\"course\"')\n",
      "(10, '0.124*\"test\" + 0.107*\"homework\" + 0.063*\"grade\" + 0.040*\"final\" + 0.039*\"study\"')\n",
      "(17, '0.406*\"class\" + 0.111*\"really\" + 0.076*\"understand\" + 0.060*\"learn\" + 0.029*\"funny\"')\n",
      "\n",
      "Coherence Score:  0.3091860283023365\n",
      "\n",
      "Coherence Score (umass):  -5.6261901649356\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 22\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, '0.184*\"lecturer\" + 0.129*\"another\" + 0.083*\"recitation\" + 0.071*\"world\" + 0.070*\"entire\"')\n",
      "(16, '0.543*\"question\" + 0.237*\"answer\" + 0.115*\"answer_question\" + 0.051*\"ask\" + 0.031*\"asking\"')\n",
      "(22, '0.188*\"assignment\" + 0.132*\"credit\" + 0.122*\"extra\" + 0.061*\"assign\" + 0.052*\"extra_credit\"')\n",
      "(4, '0.214*\"know\" + 0.161*\"stuff\" + 0.094*\"talking\" + 0.078*\"discussion\" + 0.064*\"section\"')\n",
      "(17, '0.192*\"worst\" + 0.147*\"avoid\" + 0.099*\"different\" + 0.084*\"straight\" + 0.083*\"possible\"')\n",
      "(10, '0.136*\"want\" + 0.134*\"care\" + 0.122*\"highly\" + 0.100*\"highly_recommend\" + 0.094*\"sense\"')\n",
      "(7, '0.181*\"subject\" + 0.153*\"physics\" + 0.071*\"matter\" + 0.057*\"awful\" + 0.045*\"theory\"')\n",
      "(14, '0.168*\"point\" + 0.100*\"need\" + 0.090*\"instructor\" + 0.075*\"mistake\" + 0.064*\"speak\"')\n",
      "(19, '0.099*\"nothing\" + 0.084*\"require\" + 0.081*\"effort\" + 0.079*\"worth\" + 0.072*\"proof\"')\n",
      "(1, '0.225*\"concept\" + 0.123*\"clearly\" + 0.086*\"something\" + 0.080*\"board\" + 0.065*\"since\"')\n",
      "(12, '0.364*\"would\" + 0.252*\"recommend\" + 0.062*\"would_recommend\" + 0.061*\"anyone\" + 0.054*\"calculus\"')\n",
      "(0, '0.202*\"never\" + 0.137*\"expect\" + 0.126*\"anything\" + 0.084*\"hard\" + 0.076*\"slide\"')\n",
      "(9, '0.341*\"interest\" + 0.153*\"awesome\" + 0.054*\"joke\" + 0.053*\"entertain\" + 0.047*\"english\"')\n",
      "(11, '0.171*\"final\" + 0.166*\"midterm\" + 0.130*\"first\" + 0.069*\"average\" + 0.046*\"right\"')\n",
      "(2, '0.242*\"exam\" + 0.177*\"problem\" + 0.105*\"example\" + 0.079*\"give\" + 0.060*\"review\"')\n",
      "(13, '0.453*\"professor\" + 0.101*\"extremely\" + 0.041*\"excellent\" + 0.040*\"challenge\" + 0.029*\"level\"')\n",
      "(18, '0.198*\"student\" + 0.193*\"material\" + 0.114*\"teaching\" + 0.058*\"could\" + 0.051*\"try\"')\n",
      "(8, '0.100*\"difficult\" + 0.096*\"grade\" + 0.086*\"pretty\" + 0.057*\"boring\" + 0.046*\"little\"')\n",
      "(3, '0.243*\"lecture\" + 0.153*\"test\" + 0.132*\"homework\" + 0.048*\"study\" + 0.048*\"note\"')\n",
      "(6, '0.245*\"class\" + 0.072*\"teacher\" + 0.067*\"really\" + 0.054*\"great\" + 0.046*\"understand\"')\n",
      "\n",
      "Coherence Score:  0.3072478377953021\n",
      "\n",
      "Coherence Score (umass):  -5.65463743156535\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 23\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, '0.310*\"hours\" + 0.295*\"office\" + 0.238*\"office_hours\" + 0.067*\"email\" + 0.040*\"quickly\"')\n",
      "(20, '0.286*\"boring\" + 0.197*\"subject\" + 0.105*\"attend\" + 0.077*\"matter\" + 0.063*\"recitation\"')\n",
      "(3, '0.332*\"always\" + 0.266*\"willing\" + 0.098*\"need\" + 0.074*\"mistake\" + 0.070*\"always_willing\"')\n",
      "(18, '0.108*\"sense\" + 0.097*\"useless\" + 0.077*\"humor\" + 0.073*\"completely\" + 0.057*\"come\"')\n",
      "(17, '0.326*\"recommend\" + 0.159*\"taking\" + 0.124*\"highly\" + 0.102*\"highly_recommend\" + 0.057*\"unclear\"')\n",
      "(9, '0.255*\"study\" + 0.159*\"point\" + 0.060*\"base\" + 0.051*\"choice\" + 0.044*\"multiple\"')\n",
      "(8, '0.452*\"question\" + 0.197*\"answer\" + 0.096*\"answer_question\" + 0.090*\"cover\" + 0.042*\"ask\"')\n",
      "(19, '0.224*\"note\" + 0.121*\"online\" + 0.084*\"slide\" + 0.082*\"talking\" + 0.068*\"straight\"')\n",
      "(11, '0.215*\"going\" + 0.081*\"instructor\" + 0.079*\"fairly\" + 0.073*\"discussion\" + 0.069*\"calculus\"')\n",
      "(21, '0.212*\"everything\" + 0.185*\"could\" + 0.122*\"write\" + 0.071*\"board\" + 0.064*\"without\"')\n",
      "(14, '0.335*\"explain\" + 0.208*\"things\" + 0.157*\"concept\" + 0.084*\"explain_things\" + 0.059*\"would_recommend\"')\n",
      "(13, '0.290*\"teaching\" + 0.140*\"first\" + 0.103*\"want\" + 0.073*\"like\" + 0.072*\"smart\"')\n",
      "(12, '0.253*\"pretty\" + 0.147*\"know\" + 0.112*\"assignment\" + 0.110*\"stuff\" + 0.056*\"require\"')\n",
      "(2, '0.236*\"grade\" + 0.150*\"final\" + 0.146*\"midterm\" + 0.109*\"curve\" + 0.066*\"credit\"')\n",
      "(23, '0.126*\"take\" + 0.093*\"physics\" + 0.093*\"still\" + 0.082*\"grading\" + 0.069*\"hard\"')\n",
      "(16, '0.316*\"learn\" + 0.105*\"actually\" + 0.096*\"anything\" + 0.070*\"enjoy\" + 0.063*\"learning\"')\n",
      "(10, '0.085*\"though\" + 0.073*\"think\" + 0.069*\"little\" + 0.064*\"try\" + 0.063*\"sometimes\"')\n",
      "(6, '0.188*\"homework\" + 0.168*\"exam\" + 0.123*\"problem\" + 0.072*\"example\" + 0.069*\"quiz\"')\n",
      "(7, '0.189*\"lecture\" + 0.162*\"professor\" + 0.102*\"material\" + 0.073*\"would\" + 0.063*\"difficult\"')\n",
      "(22, '0.261*\"class\" + 0.077*\"teacher\" + 0.071*\"really\" + 0.060*\"test\" + 0.058*\"great\"')\n",
      "\n",
      "Coherence Score:  0.30493757305396074\n",
      "\n",
      "Coherence Score (umass):  -5.930841687805176\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 24\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, '0.347*\"hours\" + 0.330*\"office\" + 0.267*\"office_hours\" + 0.053*\"friendly\" + 0.000*\"accent\"')\n",
      "(13, '0.184*\"highly\" + 0.151*\"highly_recommend\" + 0.142*\"sense\" + 0.103*\"recommend\" + 0.101*\"humor\"')\n",
      "(20, '0.315*\"concept\" + 0.074*\"explain_concept\" + 0.072*\"choice\" + 0.062*\"multiple\" + 0.042*\"practice_problem\"')\n",
      "(18, '0.199*\"physics\" + 0.187*\"help\" + 0.176*\"grading\" + 0.115*\"require\" + 0.110*\"effort\"')\n",
      "(0, '0.224*\"know\" + 0.169*\"stuff\" + 0.098*\"talking\" + 0.064*\"speak\" + 0.062*\"know_stuff\"')\n",
      "(21, '0.184*\"subject\" + 0.168*\"review\" + 0.072*\"matter\" + 0.066*\"unclear\" + 0.058*\"come\"')\n",
      "(22, '0.168*\"assignment\" + 0.118*\"credit\" + 0.109*\"extra\" + 0.101*\"challenge\" + 0.087*\"project\"')\n",
      "(15, '0.474*\"question\" + 0.207*\"answer\" + 0.100*\"answer_question\" + 0.059*\"right\" + 0.050*\"grader\"')\n",
      "(8, '0.107*\"hard\" + 0.102*\"attention\" + 0.098*\"slide\" + 0.080*\"straight\" + 0.059*\"information\"')\n",
      "(23, '0.220*\"final\" + 0.213*\"midterm\" + 0.167*\"first\" + 0.053*\"midterm_final\" + 0.039*\"entire\"')\n",
      "(10, '0.215*\"example\" + 0.132*\"confuse\" + 0.110*\"write\" + 0.082*\"like\" + 0.081*\"smart\"')\n",
      "(1, '0.292*\"would\" + 0.188*\"always\" + 0.159*\"recommend\" + 0.151*\"willing\" + 0.050*\"would_recommend\"')\n",
      "(11, '0.363*\"student\" + 0.209*\"teaching\" + 0.073*\"care\" + 0.070*\"avoid\" + 0.038*\"care_student\"')\n",
      "(24, '0.484*\"teacher\" + 0.361*\"great\" + 0.045*\"person\" + 0.037*\"brother\" + 0.015*\"sister\"')\n",
      "(19, '0.253*\"exam\" + 0.104*\"study\" + 0.104*\"note\" + 0.062*\"textbook\" + 0.056*\"online\"')\n",
      "(7, '0.143*\"pretty\" + 0.099*\"quiz\" + 0.095*\"boring\" + 0.094*\"though\" + 0.077*\"little\"')\n",
      "(9, '0.276*\"really\" + 0.126*\"interest\" + 0.121*\"make\" + 0.074*\"funny\" + 0.056*\"awesome\"')\n",
      "(3, '0.213*\"test\" + 0.183*\"homework\" + 0.120*\"problem\" + 0.108*\"grade\" + 0.053*\"give\"')\n",
      "(17, '0.160*\"material\" + 0.151*\"understand\" + 0.138*\"helpful\" + 0.098*\"difficult\" + 0.074*\"clear\"')\n",
      "(12, '0.287*\"class\" + 0.105*\"lecture\" + 0.090*\"professor\" + 0.049*\"teach\" + 0.043*\"learn\"')\n",
      "\n",
      "Coherence Score:  0.29964380550212455\n",
      "\n",
      "Coherence Score (umass):  -5.925492038969445\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 25\n",
    "NUM_PASSES = 300\n",
    "NUM_WORDS = 5\n",
    "dataset_id = \"sciences\"\n",
    "\n",
    "# dictionary, corpus = load_dictionary_corpus(dataset_id)\n",
    "model = generate_lda(dataset_id, corpus, dictionary, NUM_TOPICS, NUM_PASSES, NUM_WORDS)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=feedback_text, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (umass): ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
