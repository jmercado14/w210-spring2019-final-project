{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat labeling pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest raw chat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chats = pd.read_csv('data_inputs/test_export.csv')\n",
    "# chats_df = pd.read_json('data_inputs/export1.json', lines=True)\n",
    "\n",
    "chats = []\n",
    "for line in open('data_inputs/chat_export1.json', 'r'):\n",
    "    chats.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': {'$oid': '5c7acb202f46c1066e31fd5b'},\n",
       "  'student_id': 'UFR6C3N5B',\n",
       "  'time': 'Sat Mar 02 2019 18:27:10 GMT+0000 (Coordinated Universal Time)',\n",
       "  'topic': 'live session',\n",
       "  'course': 'a',\n",
       "  'prof_name': 'a',\n",
       "  'instr_wk': 'a',\n",
       "  'emoji_sentiment': 'pos1',\n",
       "  'topic_response': 'a'},\n",
       " {'_id': {'$oid': '5c7ae81e2f46c1066e31fd5c'},\n",
       "  'student_id': 'UFR6C3N5B',\n",
       "  'time': 'Sat Mar 02 2019 18:27:10 GMT+0000 (Coordinated Universal Time)',\n",
       "  'topic': 'office hours',\n",
       "  'course': '203',\n",
       "  'prof_name': 'john do',\n",
       "  'instr_wk': '2',\n",
       "  'emoji_sentiment': 'neg',\n",
       "  'topic_response': 'not much'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_transform(x):\n",
    "    return {\n",
    "        'neg1':1,\n",
    "        'neg' :2,\n",
    "        'neu' :3,\n",
    "        'pos' :4,\n",
    "        'pos1':5\n",
    "    }[x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': {'$oid': '5c7acb202f46c1066e31fd5b'},\n",
       " 'student_id': 'UFR6C3N5B',\n",
       " 'time': 'Sat Mar 02 2019 18:27:10 GMT+0000 (Coordinated Universal Time)',\n",
       " 'topic': 'live session',\n",
       " 'course': 'a',\n",
       " 'prof_name': 'a',\n",
       " 'instr_wk': 'a',\n",
       " 'emoji_sentiment': 'pos1',\n",
       " 'topic_response': 'a'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chat in chats:\n",
    "    chat['emoji_sentiment_int']= sentiment_transform(chat['emoji_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': {'$oid': '5c7acb202f46c1066e31fd5b'},\n",
       " 'student_id': 'UFR6C3N5B',\n",
       " 'time': 'Sat Mar 02 2019 18:27:10 GMT+0000 (Coordinated Universal Time)',\n",
       " 'topic': 'live session',\n",
       " 'course': 'a',\n",
       " 'prof_name': 'a',\n",
       " 'instr_wk': 'a',\n",
       " 'emoji_sentiment': 'pos1',\n",
       " 'topic_response': 'a',\n",
       " 'emoji_sentiment_int': 5}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply topic models to chat data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_topic(text):\n",
    "    return text\n",
    "\n",
    "NUM_TOPICS = 3\n",
    "NUM_PASSES = 15\n",
    "\n",
    "def pred_sub_topic(text, topic):\n",
    "    # load dictionary\n",
    "    dictionary_filename = 'topic_dictionaries/%s_dictionary_feedback.gensim' % (str(topic))\n",
    "    if not Path(dictionary_filename).exists():\n",
    "        return None\n",
    "    dictionary = corpora.Dictionary.load(dictionary_filename)\n",
    "    \n",
    "    # load model\n",
    "    ldamodel_filename = 'topic_models/%s_model%st_%sp.gensim' % (str(topic), str(NUM_TOPICS), str(NUM_PASSES))\n",
    "    if not Path(ldamodel_filename).exists():\n",
    "        return None\n",
    "    model = LdaModel.load(ldamodel_filename)\n",
    "    \n",
    "    # predict subtopic\n",
    "    tokens = prepare_text_for_lda(text)\n",
    "    print(tokens)\n",
    "    bow_tokens = dictionary.doc2bow(tokens)\n",
    "    vector = model[bow_tokens]\n",
    "    print(vector)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['testing', 'feedback', 'responsive', 'slack']\n",
      "[(0, 0.758591), (1, 0.12270975), (2, 0.1186993)]\n"
     ]
    }
   ],
   "source": [
    "pred_sub_topic('testing feedback responsive slack', 'instructors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)]\n",
      "[]\n",
      "[(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)]\n",
      "[]\n",
      "[(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)]\n",
      "[]\n",
      "[(0, 0.33333334), (1, 0.33333334), (2, 0.33333334)]\n"
     ]
    }
   ],
   "source": [
    "for chat in chats:\n",
    "    # chat['pred_topic'] = pred_topic(chat['topic_response'])\n",
    "    chat['pred_topic'] = chat['topic']\n",
    "    chat['pred_sub_topic'] = pred_sub_topic(chat['topic_response'], chat['topic'])\n",
    "    # chat['pred_sub_topic'] = chat['topic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export appended data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_outputs/updated_chatdata.csv', 'w') as f:  # Just use 'w' mode in 3.x\n",
    "    w = csv.DictWriter(f, chats[1].keys())\n",
    "    w.writeheader()\n",
    "    for chat in chats:\n",
    "        w = csv.DictWriter(f, chat.keys())\n",
    "        w.writerow(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat summaries by topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate topic summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = set(chats[topic])\n",
    "\n",
    "for topic in topics:\n",
    "    print (\"Processing\", topic)\n",
    "    topic_subset = training_feedback[training_feedback.topic==topic]\n",
    "    topic_text = topic_subset.feedback_text\n",
    "    \n",
    "    s = '. '\n",
    "    text = s.join(topic_text)\n",
    "    text = re.sub(\"\\.+\", \".\", text)\n",
    "    text = re.sub(\"\\n\", \"\", text)\n",
    "    # print(text)\n",
    "    print(summarize(text))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assignment', 'instructor', 'live session', 'miscellaneous', 'office hours'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = set()\n",
    "\n",
    "for chat in chats:\n",
    "    topics.add(chat['topic'])\n",
    "    \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing miscellaneous\n",
      "['I think the bridge course is so fun! wanted to compliment paul, the course creators, and admins for doing such a great job in designing such a helpful course', 'nothing']\n",
      "\n",
      "\n",
      "\n",
      "Processing live session\n",
      "['a', 'a']\n",
      "\n",
      "\n",
      "\n",
      "Processing office hours\n",
      "['not much']\n",
      "\n",
      "\n",
      "\n",
      "Processing instructor\n",
      "['a']\n",
      "\n",
      "\n",
      "\n",
      "Processing assignment\n",
      "['a']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print (\"Processing\", topic)\n",
    "    topic_subset = [d for d in chats if d['topic'] == topic]\n",
    "    topic_text = []\n",
    "    for chat in topic_subset:\n",
    "        topic_text.append(chat['topic_response'])\n",
    "    print(topic_text)\n",
    "    \n",
    "    \n",
    "    s = '. '\n",
    "    text = s.join(topic_text)\n",
    "    text = re.sub(\"\\.+\", \".\", text)\n",
    "    text = re.sub(\"\\n\", \"\", text)\n",
    "    # print(text)\n",
    "    print(summarize(text))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
