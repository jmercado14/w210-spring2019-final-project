{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat labeling pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import Phrases\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest raw chat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chats = pd.read_csv('data_inputs/test_export.csv')\n",
    "# chats_df = pd.read_json('data_inputs/export1.json', lines=True)\n",
    "\n",
    "chats = []\n",
    "for line in open('data_inputs/chat_export_2.json', 'r'):\n",
    "    chats.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': {'$oid': '5c874ee5fb2cfe24a30f806e'},\n",
       "  'student_id': 'anon',\n",
       "  'time': 'Tue Mar 12 2019 05:52:53 GMT+0000 (Coordinated Universal Time)',\n",
       "  'topic': 'technology',\n",
       "  'course_content': '201',\n",
       "  'prof_name': 'Jane Doe',\n",
       "  'emoji_sentiment': 'pos',\n",
       "  'response_good': 'I personally am a huge fan of Zoom, and I am so glad Zoom has officially replaced Adobe Connect in ISVC. Adobe Connect audio and video quality was my major concern and I am excited that I can have a great online classroom experience with the transition to Zoom.',\n",
       "  'response_bad': \"It's not 100% clear to me when the assignments are due and where to submit them. I understand Jane's motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC. If Jane can make sure everything is aligned and in agreement, that would be a huge help!\",\n",
       "  'response_add_feedback': \"Office hour Zoom recordings are incredibly helpful. I particularly like that I can benefit from a different instructors' office hours as well. Please continue to record office hours!\",\n",
       "  'reponse_full': \"I personally am a huge fan of Zoom, and I am so glad Zoom has officially replaced Adobe Connect in ISVC. Adobe Connect audio and video quality was my major concern and I am excited that I can have a great online classroom experience with the transition to Zoom. It's not 100% clear to me when the assignments are due and where to submit them. I understand Jane's motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC. If Jane can make sure everything is aligned and in agreement, that would be a huge help! Office hour Zoom recordings are incredibly helpful. I particularly like that I can benefit from a different instructors' office hours as well. Please continue to record office hours!\",\n",
       "  'scale': '6',\n",
       "  'emoji_sentiment_int': 4,\n",
       "  'pred_topic': None,\n",
       "  'pred_sub_topic': 0}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json file\n",
    "chats = []\n",
    "for line in open('data_inputs/chat_export_2.json', 'r'):\n",
    "    chats.append(json.loads(line))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file\n",
    "chats = pd.read_csv('training_data/feedback_data_for_training.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>feedback_text</th>\n",
       "      <th>topic</th>\n",
       "      <th>sub_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team_generated</td>\n",
       "      <td>i’d ask for more time from the TAs, or try to ...</td>\n",
       "      <td>assignments</td>\n",
       "      <td>slow turnaround</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>team_generated</td>\n",
       "      <td>the way that they encourage lots of class disc...</td>\n",
       "      <td>live session</td>\n",
       "      <td>good discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>team_generated</td>\n",
       "      <td>async is going pretty well, but not super appl...</td>\n",
       "      <td>async</td>\n",
       "      <td>disconnected from live session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>team_generated</td>\n",
       "      <td>abe lincoln is the best professor i’ve ever had</td>\n",
       "      <td>instructors</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>team_generated</td>\n",
       "      <td>tech is bad</td>\n",
       "      <td>technology</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>team_generated</td>\n",
       "      <td>this is a great bot</td>\n",
       "      <td>technology</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>team_generated</td>\n",
       "      <td>the breakout sessions were very engaging, and ...</td>\n",
       "      <td>live session</td>\n",
       "      <td>good discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>team_generated</td>\n",
       "      <td>one person dominated the full-class discussion...</td>\n",
       "      <td>live session</td>\n",
       "      <td>unbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>team_generated</td>\n",
       "      <td>they’re fine. problem sets are really helpful,...</td>\n",
       "      <td>assignments</td>\n",
       "      <td>slow turnaround</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                      feedback_text  \\\n",
       "1  team_generated  i’d ask for more time from the TAs, or try to ...   \n",
       "2  team_generated  the way that they encourage lots of class disc...   \n",
       "3  team_generated  async is going pretty well, but not super appl...   \n",
       "4  team_generated    abe lincoln is the best professor i’ve ever had   \n",
       "5  team_generated                                        tech is bad   \n",
       "6  team_generated                                this is a great bot   \n",
       "7  team_generated  the breakout sessions were very engaging, and ...   \n",
       "8  team_generated  one person dominated the full-class discussion...   \n",
       "9  team_generated  they’re fine. problem sets are really helpful,...   \n",
       "\n",
       "          topic                       sub_topic  \n",
       "1   assignments                 slow turnaround  \n",
       "2  live session                 good discussion  \n",
       "3         async  disconnected from live session  \n",
       "4   instructors                             NaN  \n",
       "5    technology                        negative  \n",
       "6    technology                        positive  \n",
       "7  live session                 good discussion  \n",
       "8  live session                      unbalanced  \n",
       "9   assignments                 slow turnaround  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_transform(x):\n",
    "    return {\n",
    "        'neg1':1,\n",
    "        'neg' :2,\n",
    "        'neu' :3,\n",
    "        'pos' :4,\n",
    "        'pos1':5\n",
    "    }[x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': {'$oid': '5c874ee5fb2cfe24a30f806e'},\n",
       " 'student_id': 'anon',\n",
       " 'time': 'Tue Mar 12 2019 05:52:53 GMT+0000 (Coordinated Universal Time)',\n",
       " 'topic': 'technology',\n",
       " 'course_content': '201',\n",
       " 'prof_name': 'Jane Doe',\n",
       " 'emoji_sentiment': 'pos',\n",
       " 'response_good': 'I personally am a huge fan of Zoom, and I am so glad Zoom has officially replaced Adobe Connect in ISVC. Adobe Connect audio and video quality was my major concern and I am excited that I can have a great online classroom experience with the transition to Zoom.',\n",
       " 'response_bad': \"It's not 100% clear to me when the assignments are due and where to submit them. I understand Jane's motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC. If Jane can make sure everything is aligned and in agreement, that would be a huge help!\",\n",
       " 'response_add_feedback': \"Office hour Zoom recordings are incredibly helpful. I particularly like that I can benefit from a different instructors' office hours as well. Please continue to record office hours!\",\n",
       " 'reponse_full': \"I personally am a huge fan of Zoom, and I am so glad Zoom has officially replaced Adobe Connect in ISVC. Adobe Connect audio and video quality was my major concern and I am excited that I can have a great online classroom experience with the transition to Zoom. It's not 100% clear to me when the assignments are due and where to submit them. I understand Jane's motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC. If Jane can make sure everything is aligned and in agreement, that would be a huge help! Office hour Zoom recordings are incredibly helpful. I particularly like that I can benefit from a different instructors' office hours as well. Please continue to record office hours!\",\n",
       " 'scale': '6'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chat in chats:\n",
    "    chat['emoji_sentiment_int']= sentiment_transform(chat['emoji_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': {'$oid': '5c874ee5fb2cfe24a30f806e'},\n",
       " 'student_id': 'anon',\n",
       " 'time': 'Tue Mar 12 2019 05:52:53 GMT+0000 (Coordinated Universal Time)',\n",
       " 'topic': 'technology',\n",
       " 'course_content': '201',\n",
       " 'prof_name': 'Jane Doe',\n",
       " 'emoji_sentiment': 'pos',\n",
       " 'response_good': 'I personally am a huge fan of Zoom, and I am so glad Zoom has officially replaced Adobe Connect in ISVC. Adobe Connect audio and video quality was my major concern and I am excited that I can have a great online classroom experience with the transition to Zoom.',\n",
       " 'response_bad': \"It's not 100% clear to me when the assignments are due and where to submit them. I understand Jane's motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC. If Jane can make sure everything is aligned and in agreement, that would be a huge help!\",\n",
       " 'response_add_feedback': \"Office hour Zoom recordings are incredibly helpful. I particularly like that I can benefit from a different instructors' office hours as well. Please continue to record office hours!\",\n",
       " 'reponse_full': \"I personally am a huge fan of Zoom, and I am so glad Zoom has officially replaced Adobe Connect in ISVC. Adobe Connect audio and video quality was my major concern and I am excited that I can have a great online classroom experience with the transition to Zoom. It's not 100% clear to me when the assignments are due and where to submit them. I understand Jane's motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC. If Jane can make sure everything is aligned and in agreement, that would be a huge help! Office hour Zoom recordings are incredibly helpful. I particularly like that I can benefit from a different instructors' office hours as well. Please continue to record office hours!\",\n",
       " 'scale': '6',\n",
       " 'emoji_sentiment_int': 4}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply topic models to chat data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def prepare_document(doc):\n",
    "    \n",
    "    tokenized = []\n",
    "    \n",
    "    tokens = prepare_text_for_lda(str(doc))\n",
    "    tokenized.append(tokens)\n",
    "\n",
    "    # Add bigrams to docs (only ones that appear 20 times or more).\n",
    "    bigram = Phrases(tokenized, min_count=20)\n",
    "    for idx in range(len(tokenized)):\n",
    "        for token in bigram[tokenized[idx]]:\n",
    "            if '_' in token:\n",
    "                # Token is a bigram, add to document.\n",
    "                tokenized[idx].append(token)\n",
    "        \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_topic(text):\n",
    "    model_filename = 'topic_models/full_topic_model.sav'\n",
    "    topic_model = pickle.load(open(model_filename, 'rb'))\n",
    "    result = topic_model.predict([text])[0]\n",
    "    # print(result)\n",
    "    return result\n",
    "\n",
    "def pred_sub_topic(text, dictionary, model):\n",
    "    \n",
    "    # predict subtopic\n",
    "    tokens = prepare_document(text)\n",
    "    \n",
    "    print(tokens)\n",
    "    bow_tokens = dictionary.doc2bow(tokens[0])\n",
    "    vector = model[bow_tokens]\n",
    "    print(vector)\n",
    "    most_likely = max(vector,key=itemgetter(1))\n",
    "    vector = sorted(((v,k) for k,v in vector))\n",
    "    # print (vector)\n",
    "    \n",
    "    if (vector[-1][1] == 5):\n",
    "        return vector[-2][1]\n",
    "    return vector[-1][1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 14\n",
    "NUM_PASSES = 300\n",
    "\n",
    "# load dictionary\n",
    "dictionary_filename = \"topic_dictionaries/%s_dictionary_feedback.gensim\" % (\"sciences\")\n",
    "dictionary = corpora.Dictionary.load(dictionary_filename)\n",
    "    \n",
    "# load model\n",
    "ldamodel_filename = 'topic_models/%s_model%st_%sp.gensim' % (\"sciences\", str(NUM_TOPICS), str(NUM_PASSES))\n",
    "model = LdaModel.load(ldamodel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['come', 'office', 'hours', 'office', 'hours']]\n",
      "[(0, 0.013133085), (1, 0.047014322), (2, 0.022961633), (3, 0.017972628), (4, 0.03811367), (5, 0.39596027), (6, 0.024542574), (7, 0.1266452), (8, 0.028104296), (9, 0.047045887), (10, 0.023035506), (11, 0.17412157), (12, 0.013958988), (13, 0.027390378)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sub_topic('this is a test to see what comes back office hours office hours', dictionary, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['exam', 'quiz', 'test', 'midterm', 'exam', 'test']]\n",
      "[(0, 0.012616726), (1, 0.20241839), (2, 0.02205884), (3, 0.017265989), (4, 0.036615137), (5, 0.41970998), (6, 0.023577621), (7, 0.12166584), (8, 0.026999306), (9, 0.04519616), (10, 0.022129808), (11, 0.01002254), (12, 0.013410156), (13, 0.026313458)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sub_topic('exams, quizzes, tests, midterms, this should all come back as exams and tests', dictionary, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n",
      "[(0, 0.016511416), (1, 0.0591082), (2, 0.028868241), (3, 0.022595871), (4, 0.04791796), (5, 0.446374), (6, 0.030855859), (7, 0.15922318), (8, 0.035333794), (9, 0.059147883), (10, 0.028961116), (11, 0.013116423), (12, 0.017549772), (13, 0.034436226)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sub_topic('this is a test', dictionary, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chat in chats:\n",
    "    # chat['pred_topic'] = pred_topic(chat['topic']) if chat['topic'] == 'miscellaneous' else None\n",
    "    chat['pred_sub_topic'] = pred_sub_topic(chat['reponse_full'], dictionary, model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export appended data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_outputs/updated_chatdata.csv', 'w') as f:  # Just use 'w' mode in 3.x\n",
    "    w = csv.DictWriter(f, chats[1].keys())\n",
    "    w.writeheader()\n",
    "    for chat in chats:\n",
    "        w = csv.DictWriter(f, chat.keys())\n",
    "        w.writerow(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat summaries by topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate topic summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assignment', 'live session', 'technology'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = set()\n",
    "\n",
    "for chat in chats:\n",
    "    topics.add(chat['topic'])\n",
    "    \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing live session\n",
      "[\"Groups keep going over their alotted time to present and the instructors don't interceed. I'd ask them to be more strict and maybe tell the students when they have 5 and 1 minute left I'd ask them to cut the groups off when they exceed their time\"]\n",
      "\n",
      "\n",
      "\n",
      "Processing technology\n",
      "[\"I personally am a huge fan of Zoom, and I am so glad Zoom has officially replaced Adobe Connect in ISVC. Adobe Connect audio and video quality was my major concern and I am excited that I can have a great online classroom experience with the transition to Zoom. It's not 100% clear to me when the assignments are due and where to submit them. I understand Jane's motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC. If Jane can make sure everything is aligned and in agreement, that would be a huge help! Office hour Zoom recordings are incredibly helpful. I particularly like that I can benefit from a different instructors' office hours as well. Please continue to record office hours!\", 'I personally am a huge fan of Zoom, and I am so glad Zoom has officially replaced Adobe connect in ISVC. Adobe connect audio and video quality was my major concern and I am excited that I can have a great online classroom experience with the transition to Zoom. It’s not 100% clear to me when the assignments are due and where to submit them. I understand Jane’s motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC. If jane can make sure everything is aligned and in agreement, that would be a huge help! Office hour Zoom recordings are incredibly helpful! I particularly like that I can benefit from a different instructors’ office hours as well. Please continue to record office hours.', 'I personally am a huge fan of Zoom, and I am so glad Zoom has officially replaced Adobe Connect in ISVC. Adobe Connect audio and video quality was my major concern and I am excited that I can have a great online classroom experience with the transition to Zoom. It’s not 100% clear to me when the assignments are due and where to submit them. I understand Jane’s motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC. If Jane can make sure everything is aligned and in agreement, that would be a huge help! Office hour Zoom recordings are incredibly helpful. I particularly like that I can benefit from different instructors’ office hours as well. Please continue to record office hours']\n",
      "I understand Jane's motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC.\n",
      "I particularly like that I can benefit from a different instructors' office hours as well.\n",
      "I understand Jane’s motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC.\n",
      "I understand Jane’s motivation to want to use GitHub but the information on GitHub is not in sync with the information on ISVC.\n",
      "\n",
      "\n",
      "Processing assignment\n",
      "['The instructions for each assignment have been very clear, which has helped keep me on the right track as I worked through each one.It would be great to get feedback on assignments sooner, so I could learn from my mistakes and apply that to future assignments before they’re due.The links to assignments in ISVC are broken.']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "input must have more than one sentence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-1420744b7aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# print(text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/summarization/summarizer.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, ratio, word_count, split)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;31m# If only one sentence is present, the function raises an error (Avoids ZeroDivisionError).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input must have more than one sentence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;31m# Warns if the text is too short.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: input must have more than one sentence"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print (\"Processing\", topic)\n",
    "    topic_subset = [d for d in chats if d['topic'] == topic]\n",
    "    topic_text = []\n",
    "    for chat in topic_subset:\n",
    "        topic_text.append(chat['reponse_full'])\n",
    "    print(topic_text)\n",
    "    \n",
    "    \n",
    "    s = '. '\n",
    "    text = s.join(topic_text)\n",
    "    text = re.sub(\"\\.+\", \".\", text)\n",
    "    text = re.sub(\"\\n\", \"\", text)\n",
    "    # print(text)\n",
    "    print(summarize(text))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
